{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wangls/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from skip_gram import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypath = '../../毕设/joycity_shop_list2_key.npy'\n",
    "datapath  ='../../毕设/joycity_shop_list2.npy'\n",
    "n_embedding = 20\n",
    "n_sampled = 5\n",
    "epochs = 10\n",
    "batch_size = 1000\n",
    "window_size = 10\n",
    "ch_save = \"checkpoints_close/text8.ckpt\"\n",
    "savename='../data/w2v_mat_shop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tdl = Train_data_load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Iteration: 200 Avg. Training loss: 2.4540 0.0032 sec/batch\n",
      "Epoch 1/10 Iteration: 400 Avg. Training loss: 2.5191 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 600 Avg. Training loss: 2.5444 0.0023 sec/batch\n",
      "Epoch 1/10 Iteration: 800 Avg. Training loss: 2.4283 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 1000 Avg. Training loss: 2.3613 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 1200 Avg. Training loss: 2.3781 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 1400 Avg. Training loss: 2.2595 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 1600 Avg. Training loss: 2.2601 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 1800 Avg. Training loss: 2.2436 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 2000 Avg. Training loss: 2.2515 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 2200 Avg. Training loss: 2.1904 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 2400 Avg. Training loss: 2.0642 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 2600 Avg. Training loss: 2.0713 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 2800 Avg. Training loss: 2.0388 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 3000 Avg. Training loss: 1.9807 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 3200 Avg. Training loss: 1.9886 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 3400 Avg. Training loss: 2.0336 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 3600 Avg. Training loss: 1.8975 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 3800 Avg. Training loss: 2.0419 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 4000 Avg. Training loss: 2.0355 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 4200 Avg. Training loss: 2.0962 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 4400 Avg. Training loss: 1.9291 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 4600 Avg. Training loss: 1.9632 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 4800 Avg. Training loss: 1.9835 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 5000 Avg. Training loss: 1.8270 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 5200 Avg. Training loss: 1.7611 0.0020 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 5400 Avg. Training loss: 1.7694 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 5600 Avg. Training loss: 1.8330 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 5800 Avg. Training loss: 1.8502 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 6000 Avg. Training loss: 1.9507 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 6200 Avg. Training loss: 1.7444 0.0021 sec/batch\n",
      "Epoch 1/10 Iteration: 6400 Avg. Training loss: 1.8053 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 6600 Avg. Training loss: 1.8104 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 6800 Avg. Training loss: 1.8564 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 7000 Avg. Training loss: 1.7797 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 7200 Avg. Training loss: 1.9125 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 7400 Avg. Training loss: 1.7668 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 7600 Avg. Training loss: 1.8556 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 7800 Avg. Training loss: 1.6915 0.0022 sec/batch\n",
      "Epoch 1/10 Iteration: 8000 Avg. Training loss: 1.9015 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 8200 Avg. Training loss: 1.7687 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 8400 Avg. Training loss: 1.8298 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 8600 Avg. Training loss: 1.7955 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 8800 Avg. Training loss: 1.7130 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 9000 Avg. Training loss: 1.7980 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 9200 Avg. Training loss: 1.6607 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 9400 Avg. Training loss: 1.8096 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 9600 Avg. Training loss: 1.7600 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 9800 Avg. Training loss: 1.8499 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 10000 Avg. Training loss: 1.7125 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 10200 Avg. Training loss: 1.7772 0.0021 sec/batch\n",
      "Epoch 1/10 Iteration: 10400 Avg. Training loss: 1.7918 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 10600 Avg. Training loss: 1.6695 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 10800 Avg. Training loss: 1.8092 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 11000 Avg. Training loss: 1.5019 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 11200 Avg. Training loss: 1.5672 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 11400 Avg. Training loss: 1.6414 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 11600 Avg. Training loss: 1.7779 0.0015 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 11800 Avg. Training loss: 1.6819 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 12000 Avg. Training loss: 1.6685 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 12200 Avg. Training loss: 1.5736 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 12400 Avg. Training loss: 1.7025 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 12600 Avg. Training loss: 1.7551 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 12800 Avg. Training loss: 1.6406 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 13000 Avg. Training loss: 1.7256 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 13200 Avg. Training loss: 1.7128 0.0020 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 13400 Avg. Training loss: 1.8691 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 13600 Avg. Training loss: 1.6336 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 13800 Avg. Training loss: 1.6666 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 14000 Avg. Training loss: 1.7545 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 14200 Avg. Training loss: 1.6499 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 14400 Avg. Training loss: 1.7293 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 14600 Avg. Training loss: 1.5903 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 14800 Avg. Training loss: 1.5696 0.0021 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 15000 Avg. Training loss: 1.6789 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 15200 Avg. Training loss: 1.5874 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 15400 Avg. Training loss: 1.7635 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 15600 Avg. Training loss: 1.7337 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 15800 Avg. Training loss: 1.7248 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 16000 Avg. Training loss: 1.7164 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 16200 Avg. Training loss: 1.7390 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 16400 Avg. Training loss: 1.7156 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 16600 Avg. Training loss: 1.6881 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 16800 Avg. Training loss: 1.6385 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 17000 Avg. Training loss: 1.7527 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 17200 Avg. Training loss: 1.5958 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 17400 Avg. Training loss: 1.7407 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 17600 Avg. Training loss: 1.5647 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 17800 Avg. Training loss: 1.6643 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 18000 Avg. Training loss: 1.6628 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 18200 Avg. Training loss: 1.7323 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 18400 Avg. Training loss: 1.6722 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 18600 Avg. Training loss: 1.5589 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 18800 Avg. Training loss: 1.5365 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 19000 Avg. Training loss: 1.8009 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 19200 Avg. Training loss: 1.6166 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 19400 Avg. Training loss: 1.6643 0.0021 sec/batch\n",
      "Epoch 1/10 Iteration: 19600 Avg. Training loss: 1.7775 0.0021 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 19800 Avg. Training loss: 1.6935 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 20000 Avg. Training loss: 1.6295 0.0020 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 20200 Avg. Training loss: 1.6849 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 20400 Avg. Training loss: 1.7345 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 20600 Avg. Training loss: 1.4865 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 20800 Avg. Training loss: 1.8242 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 21000 Avg. Training loss: 1.7116 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 21200 Avg. Training loss: 1.5646 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 21400 Avg. Training loss: 1.7541 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 21600 Avg. Training loss: 1.6883 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 21800 Avg. Training loss: 1.7274 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 22000 Avg. Training loss: 1.8092 0.0018 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Iteration: 22200 Avg. Training loss: 1.6611 0.0021 sec/batch\n",
      "Epoch 1/10 Iteration: 22400 Avg. Training loss: 1.7475 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 22600 Avg. Training loss: 1.5538 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 22800 Avg. Training loss: 1.8175 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 23000 Avg. Training loss: 1.7134 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 23200 Avg. Training loss: 1.6482 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 23400 Avg. Training loss: 1.7284 0.0021 sec/batch\n",
      "Epoch 1/10 Iteration: 23600 Avg. Training loss: 1.6822 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 23800 Avg. Training loss: 1.6519 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 24000 Avg. Training loss: 1.7729 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 24200 Avg. Training loss: 1.5568 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 24400 Avg. Training loss: 1.6088 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 24600 Avg. Training loss: 1.6481 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 24800 Avg. Training loss: 1.6680 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 25000 Avg. Training loss: 1.5664 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 25200 Avg. Training loss: 1.6318 0.0020 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 25400 Avg. Training loss: 1.5768 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 25600 Avg. Training loss: 1.8347 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 25800 Avg. Training loss: 1.5689 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 26000 Avg. Training loss: 1.5935 0.0020 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 26200 Avg. Training loss: 1.5725 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 26400 Avg. Training loss: 1.5592 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 26600 Avg. Training loss: 1.5112 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 26800 Avg. Training loss: 1.6082 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 27000 Avg. Training loss: 1.6464 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 27200 Avg. Training loss: 1.5817 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 27400 Avg. Training loss: 1.6905 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 27600 Avg. Training loss: 1.6924 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 27800 Avg. Training loss: 1.7503 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 28000 Avg. Training loss: 1.6839 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 28200 Avg. Training loss: 1.6889 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 28400 Avg. Training loss: 1.6624 0.0021 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 28600 Avg. Training loss: 1.6753 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 28800 Avg. Training loss: 1.8375 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 29000 Avg. Training loss: 1.4924 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 29200 Avg. Training loss: 1.5573 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 29400 Avg. Training loss: 1.6784 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 29600 Avg. Training loss: 1.5987 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 29800 Avg. Training loss: 1.6843 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 30000 Avg. Training loss: 1.6579 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 30200 Avg. Training loss: 1.5348 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 30400 Avg. Training loss: 1.5491 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 30600 Avg. Training loss: 1.6759 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 30800 Avg. Training loss: 1.5907 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 31000 Avg. Training loss: 1.6844 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 31200 Avg. Training loss: 1.7583 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 31400 Avg. Training loss: 1.5540 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 31600 Avg. Training loss: 1.6639 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 31800 Avg. Training loss: 1.6472 0.0015 sec/batch\n",
      "Epoch 1/10 Iteration: 32000 Avg. Training loss: 1.4970 0.0015 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 32200 Avg. Training loss: 1.7363 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 32400 Avg. Training loss: 1.6309 0.0015 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 32600 Avg. Training loss: 1.6431 0.0015 sec/batch\n",
      "Epoch 1/10 Iteration: 32800 Avg. Training loss: 1.6876 0.0015 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 33000 Avg. Training loss: 1.6932 0.0015 sec/batch\n",
      "Epoch 1/10 Iteration: 33200 Avg. Training loss: 1.7104 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 33400 Avg. Training loss: 1.6290 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 33600 Avg. Training loss: 1.6133 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 33800 Avg. Training loss: 1.6040 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 34000 Avg. Training loss: 1.5481 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 34200 Avg. Training loss: 1.6182 0.0015 sec/batch\n",
      "Epoch 1/10 Iteration: 34400 Avg. Training loss: 1.5380 0.0015 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 34600 Avg. Training loss: 1.6707 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 34800 Avg. Training loss: 1.7090 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 35000 Avg. Training loss: 1.5252 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 35200 Avg. Training loss: 1.7107 0.0015 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 35400 Avg. Training loss: 1.7201 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 35600 Avg. Training loss: 1.7619 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 35800 Avg. Training loss: 1.5762 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 36000 Avg. Training loss: 1.7279 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 36200 Avg. Training loss: 1.7680 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 36400 Avg. Training loss: 1.6783 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 36600 Avg. Training loss: 1.5370 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 36800 Avg. Training loss: 1.6844 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 37000 Avg. Training loss: 1.7492 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 37200 Avg. Training loss: 1.6248 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 37400 Avg. Training loss: 1.5580 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 37600 Avg. Training loss: 1.5561 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 37800 Avg. Training loss: 1.6704 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 38000 Avg. Training loss: 1.6229 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 38200 Avg. Training loss: 1.5750 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 38400 Avg. Training loss: 1.6006 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 38600 Avg. Training loss: 1.5353 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 38800 Avg. Training loss: 1.6922 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 39000 Avg. Training loss: 1.6272 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 39200 Avg. Training loss: 1.5712 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 39400 Avg. Training loss: 1.5660 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 39600 Avg. Training loss: 1.6245 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 39800 Avg. Training loss: 1.6464 0.0015 sec/batch\n",
      "Epoch 1/10 Iteration: 40000 Avg. Training loss: 1.6535 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 40200 Avg. Training loss: 1.5909 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 40400 Avg. Training loss: 1.6013 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 40600 Avg. Training loss: 1.5697 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 40800 Avg. Training loss: 1.5677 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 41000 Avg. Training loss: 1.6609 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 41200 Avg. Training loss: 1.5603 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 41400 Avg. Training loss: 1.5433 0.0021 sec/batch\n",
      "Epoch 1/10 Iteration: 41600 Avg. Training loss: 1.5886 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 41800 Avg. Training loss: 1.7885 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 42000 Avg. Training loss: 1.5358 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 42200 Avg. Training loss: 1.7788 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 42400 Avg. Training loss: 1.4807 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 42600 Avg. Training loss: 1.6494 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 42800 Avg. Training loss: 1.7608 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 43000 Avg. Training loss: 1.7549 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 43200 Avg. Training loss: 1.5623 0.0020 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 43400 Avg. Training loss: 1.7629 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 43600 Avg. Training loss: 1.6691 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 43800 Avg. Training loss: 1.5722 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 44000 Avg. Training loss: 1.5952 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 44200 Avg. Training loss: 1.5707 0.0015 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Iteration: 44400 Avg. Training loss: 1.5443 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 44600 Avg. Training loss: 1.6030 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 44800 Avg. Training loss: 1.6099 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 45000 Avg. Training loss: 1.5347 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 45200 Avg. Training loss: 1.7349 0.0020 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 45400 Avg. Training loss: 1.6721 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 45600 Avg. Training loss: 1.5922 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 45800 Avg. Training loss: 1.5834 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 46000 Avg. Training loss: 1.6516 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 46200 Avg. Training loss: 1.5989 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 46400 Avg. Training loss: 1.5888 0.0016 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 46600 Avg. Training loss: 1.6238 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 46800 Avg. Training loss: 1.6035 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 47000 Avg. Training loss: 1.7638 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 47200 Avg. Training loss: 1.6593 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 47400 Avg. Training loss: 1.7554 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 47600 Avg. Training loss: 1.5994 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 47800 Avg. Training loss: 1.7475 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 48000 Avg. Training loss: 1.6448 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 48200 Avg. Training loss: 1.6367 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 48400 Avg. Training loss: 1.6525 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 48600 Avg. Training loss: 1.6770 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 48800 Avg. Training loss: 1.6490 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 49000 Avg. Training loss: 1.6681 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 49200 Avg. Training loss: 1.6814 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 49400 Avg. Training loss: 1.8011 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 49600 Avg. Training loss: 1.5670 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 49800 Avg. Training loss: 1.5409 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 50000 Avg. Training loss: 1.6338 0.0020 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 50200 Avg. Training loss: 1.6719 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 50400 Avg. Training loss: 1.5425 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 50600 Avg. Training loss: 1.5606 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 50800 Avg. Training loss: 1.5643 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 51000 Avg. Training loss: 1.5253 0.0022 sec/batch\n",
      "Epoch 1/10 Iteration: 51200 Avg. Training loss: 1.5420 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 51400 Avg. Training loss: 1.6452 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 51600 Avg. Training loss: 1.7688 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 51800 Avg. Training loss: 1.5442 0.0020 sec/batch\n",
      "Epoch 1/10 Iteration: 52000 Avg. Training loss: 1.6630 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 52200 Avg. Training loss: 1.6998 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 52400 Avg. Training loss: 1.6014 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 52600 Avg. Training loss: 1.7200 0.0016 sec/batch\n",
      "Epoch 1/10 Iteration: 52800 Avg. Training loss: 1.5274 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 53000 Avg. Training loss: 1.6090 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 53200 Avg. Training loss: 1.5830 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 53400 Avg. Training loss: 1.5285 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 53600 Avg. Training loss: 1.4438 0.0018 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 53800 Avg. Training loss: 1.6659 0.0018 sec/batch\n",
      "Epoch 1/10 Iteration: 54000 Avg. Training loss: 1.5218 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 54200 Avg. Training loss: 1.4158 0.0017 sec/batch\n",
      "Epoch 1/10 Iteration: 54400 Avg. Training loss: 1.7419 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 54600 Avg. Training loss: 1.5506 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 54800 Avg. Training loss: 1.6716 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 55000 Avg. Training loss: 1.5356 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 55200 Avg. Training loss: 1.4902 0.0019 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 55400 Avg. Training loss: 1.6519 0.0019 sec/batch\n",
      "Epoch 1/10 Iteration: 55600 Avg. Training loss: 1.6880 0.0017 sec/batch\n",
      "error\n",
      "Epoch 1/10 Iteration: 55800 Avg. Training loss: 1.5790 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 56000 Avg. Training loss: 1.7305 0.0002 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 56200 Avg. Training loss: 1.5894 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 56400 Avg. Training loss: 1.5279 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 56600 Avg. Training loss: 1.5786 0.0021 sec/batch\n",
      "Epoch 2/10 Iteration: 56800 Avg. Training loss: 1.6764 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 57000 Avg. Training loss: 1.6414 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 57200 Avg. Training loss: 1.5710 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 57400 Avg. Training loss: 1.5667 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 57600 Avg. Training loss: 1.7199 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 57800 Avg. Training loss: 1.6285 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 58000 Avg. Training loss: 1.5472 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 58200 Avg. Training loss: 1.5970 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 58400 Avg. Training loss: 1.6267 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 58600 Avg. Training loss: 1.6724 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 58800 Avg. Training loss: 1.5133 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 59000 Avg. Training loss: 1.6289 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 59200 Avg. Training loss: 1.5488 0.0015 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 59400 Avg. Training loss: 1.6640 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 59600 Avg. Training loss: 1.5548 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 59800 Avg. Training loss: 1.6392 0.0015 sec/batch\n",
      "Epoch 2/10 Iteration: 60000 Avg. Training loss: 1.6275 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 60200 Avg. Training loss: 1.6138 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 60400 Avg. Training loss: 1.6199 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 60600 Avg. Training loss: 1.6213 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 60800 Avg. Training loss: 1.6801 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 61000 Avg. Training loss: 1.6587 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 61200 Avg. Training loss: 1.5847 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 61400 Avg. Training loss: 1.5896 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 61600 Avg. Training loss: 1.6301 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 61800 Avg. Training loss: 1.5964 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 62000 Avg. Training loss: 1.4369 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 62200 Avg. Training loss: 1.6129 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 62400 Avg. Training loss: 1.6257 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 62600 Avg. Training loss: 1.6408 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 62800 Avg. Training loss: 1.6785 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 63000 Avg. Training loss: 1.6555 0.0021 sec/batch\n",
      "Epoch 2/10 Iteration: 63200 Avg. Training loss: 1.6252 0.0021 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 63400 Avg. Training loss: 1.6009 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 63600 Avg. Training loss: 1.5992 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 63800 Avg. Training loss: 1.5302 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 64000 Avg. Training loss: 1.7197 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 64200 Avg. Training loss: 1.5447 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 64400 Avg. Training loss: 1.5637 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 64600 Avg. Training loss: 1.4413 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 64800 Avg. Training loss: 1.6480 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 65000 Avg. Training loss: 1.5290 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 65200 Avg. Training loss: 1.6199 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 65400 Avg. Training loss: 1.6983 0.0016 sec/batch\n",
      "Epoch 2/10 Iteration: 65600 Avg. Training loss: 1.6111 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 65800 Avg. Training loss: 1.5904 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 66000 Avg. Training loss: 1.5769 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 66200 Avg. Training loss: 1.6948 0.0016 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Iteration: 66400 Avg. Training loss: 1.6958 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 66600 Avg. Training loss: 1.6264 0.0021 sec/batch\n",
      "Epoch 2/10 Iteration: 66800 Avg. Training loss: 1.6577 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 67000 Avg. Training loss: 1.5463 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 67200 Avg. Training loss: 1.6796 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 67400 Avg. Training loss: 1.5486 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 67600 Avg. Training loss: 1.5427 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 67800 Avg. Training loss: 1.5229 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 68000 Avg. Training loss: 1.4915 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 68200 Avg. Training loss: 1.6835 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 68400 Avg. Training loss: 1.7696 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 68600 Avg. Training loss: 1.7281 0.0021 sec/batch\n",
      "Epoch 2/10 Iteration: 68800 Avg. Training loss: 1.6434 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 69000 Avg. Training loss: 1.5167 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 69200 Avg. Training loss: 1.6495 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 69400 Avg. Training loss: 1.6694 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 69600 Avg. Training loss: 1.6044 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 69800 Avg. Training loss: 1.5985 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 70000 Avg. Training loss: 1.6767 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 70200 Avg. Training loss: 1.4629 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 70400 Avg. Training loss: 1.5526 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 70600 Avg. Training loss: 1.7029 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 70800 Avg. Training loss: 1.5852 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 71000 Avg. Training loss: 1.5239 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 71200 Avg. Training loss: 1.6549 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 71400 Avg. Training loss: 1.7451 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 71600 Avg. Training loss: 1.6301 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 71800 Avg. Training loss: 1.6029 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 72000 Avg. Training loss: 1.4997 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 72200 Avg. Training loss: 1.7090 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 72400 Avg. Training loss: 1.5377 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 72600 Avg. Training loss: 1.5088 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 72800 Avg. Training loss: 1.6135 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 73000 Avg. Training loss: 1.4706 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 73200 Avg. Training loss: 1.5421 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 73400 Avg. Training loss: 1.6296 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 73600 Avg. Training loss: 1.5944 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 73800 Avg. Training loss: 1.5913 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 74000 Avg. Training loss: 1.6112 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 74200 Avg. Training loss: 1.5515 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 74400 Avg. Training loss: 1.3415 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 74600 Avg. Training loss: 1.6427 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 74800 Avg. Training loss: 1.4951 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 75000 Avg. Training loss: 1.5475 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 75200 Avg. Training loss: 1.6302 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 75400 Avg. Training loss: 1.5236 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 75600 Avg. Training loss: 1.7026 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 75800 Avg. Training loss: 1.6432 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 76000 Avg. Training loss: 1.5076 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 76200 Avg. Training loss: 1.5892 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 76400 Avg. Training loss: 1.5367 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 76600 Avg. Training loss: 1.5101 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 76800 Avg. Training loss: 1.6830 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 77000 Avg. Training loss: 1.6376 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 77200 Avg. Training loss: 1.7047 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 77400 Avg. Training loss: 1.5057 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 77600 Avg. Training loss: 1.6379 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 77800 Avg. Training loss: 1.6728 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 78000 Avg. Training loss: 1.7885 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 78200 Avg. Training loss: 1.5897 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 78400 Avg. Training loss: 1.5964 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 78600 Avg. Training loss: 1.6343 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 78800 Avg. Training loss: 1.5460 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 79000 Avg. Training loss: 1.5402 0.0016 sec/batch\n",
      "Epoch 2/10 Iteration: 79200 Avg. Training loss: 1.5483 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 79400 Avg. Training loss: 1.6555 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 79600 Avg. Training loss: 1.6375 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 79800 Avg. Training loss: 1.6051 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 80000 Avg. Training loss: 1.5283 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 80200 Avg. Training loss: 1.6855 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 80400 Avg. Training loss: 1.5752 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 80600 Avg. Training loss: 1.5700 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 80800 Avg. Training loss: 1.7094 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 81000 Avg. Training loss: 1.6055 0.0021 sec/batch\n",
      "Epoch 2/10 Iteration: 81200 Avg. Training loss: 1.6620 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 81400 Avg. Training loss: 1.5801 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 81600 Avg. Training loss: 1.6338 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 81800 Avg. Training loss: 1.6176 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 82000 Avg. Training loss: 1.3780 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 82200 Avg. Training loss: 1.6587 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 82400 Avg. Training loss: 1.6253 0.0021 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 82600 Avg. Training loss: 1.5383 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 82800 Avg. Training loss: 1.5268 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 83000 Avg. Training loss: 1.5470 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 83200 Avg. Training loss: 1.6134 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 83400 Avg. Training loss: 1.6539 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 83600 Avg. Training loss: 1.6459 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 83800 Avg. Training loss: 1.6627 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 84000 Avg. Training loss: 1.5870 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 84200 Avg. Training loss: 1.7003 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 84400 Avg. Training loss: 1.6762 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 84600 Avg. Training loss: 1.6339 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 84800 Avg. Training loss: 1.7106 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 85000 Avg. Training loss: 1.4510 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 85200 Avg. Training loss: 1.5371 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 85400 Avg. Training loss: 1.5889 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 85600 Avg. Training loss: 1.5664 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 85800 Avg. Training loss: 1.5597 0.0021 sec/batch\n",
      "Epoch 2/10 Iteration: 86000 Avg. Training loss: 1.6742 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 86200 Avg. Training loss: 1.4771 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 86400 Avg. Training loss: 1.6157 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 86600 Avg. Training loss: 1.7051 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 86800 Avg. Training loss: 1.6067 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 87000 Avg. Training loss: 1.5175 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 87200 Avg. Training loss: 1.6024 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 87400 Avg. Training loss: 1.5102 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 87600 Avg. Training loss: 1.6556 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 87800 Avg. Training loss: 1.5774 0.0016 sec/batch\n",
      "Epoch 2/10 Iteration: 88000 Avg. Training loss: 1.5923 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 88200 Avg. Training loss: 1.7691 0.0019 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Iteration: 88400 Avg. Training loss: 1.5755 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 88600 Avg. Training loss: 1.6007 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 88800 Avg. Training loss: 1.7009 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 89000 Avg. Training loss: 1.7063 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 89200 Avg. Training loss: 1.6552 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 89400 Avg. Training loss: 1.4741 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 89600 Avg. Training loss: 1.6876 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 89800 Avg. Training loss: 1.5068 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 90000 Avg. Training loss: 1.5712 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 90200 Avg. Training loss: 1.4964 0.0016 sec/batch\n",
      "Epoch 2/10 Iteration: 90400 Avg. Training loss: 1.5218 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 90600 Avg. Training loss: 1.6697 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 90800 Avg. Training loss: 1.6880 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 91000 Avg. Training loss: 1.5251 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 91200 Avg. Training loss: 1.7395 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 91400 Avg. Training loss: 1.6818 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 91600 Avg. Training loss: 1.5709 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 91800 Avg. Training loss: 1.5367 0.0016 sec/batch\n",
      "Epoch 2/10 Iteration: 92000 Avg. Training loss: 1.6484 0.0015 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 92200 Avg. Training loss: 1.5022 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 92400 Avg. Training loss: 1.7087 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 92600 Avg. Training loss: 1.5564 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 92800 Avg. Training loss: 1.6980 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 93000 Avg. Training loss: 1.5175 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 93200 Avg. Training loss: 1.7072 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 93400 Avg. Training loss: 1.6863 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 93600 Avg. Training loss: 1.6618 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 93800 Avg. Training loss: 1.6091 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 94000 Avg. Training loss: 1.6382 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 94200 Avg. Training loss: 1.5297 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 94400 Avg. Training loss: 1.4360 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 94600 Avg. Training loss: 1.5057 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 94800 Avg. Training loss: 1.7479 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 95000 Avg. Training loss: 1.6134 0.0021 sec/batch\n",
      "Epoch 2/10 Iteration: 95200 Avg. Training loss: 1.6308 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 95400 Avg. Training loss: 1.4627 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 95600 Avg. Training loss: 1.4954 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 95800 Avg. Training loss: 1.7872 0.0016 sec/batch\n",
      "Epoch 2/10 Iteration: 96000 Avg. Training loss: 1.6759 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 96200 Avg. Training loss: 1.6199 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 96400 Avg. Training loss: 1.6097 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 96600 Avg. Training loss: 1.6580 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 96800 Avg. Training loss: 1.5725 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 97000 Avg. Training loss: 1.5875 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 97200 Avg. Training loss: 1.6689 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 97400 Avg. Training loss: 1.5426 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 97600 Avg. Training loss: 1.6787 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 97800 Avg. Training loss: 1.5821 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 98000 Avg. Training loss: 1.4058 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 98200 Avg. Training loss: 1.7312 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 98400 Avg. Training loss: 1.5740 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 98600 Avg. Training loss: 1.6410 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 98800 Avg. Training loss: 1.5655 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 99000 Avg. Training loss: 1.5465 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 99200 Avg. Training loss: 1.7144 0.0022 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 99400 Avg. Training loss: 1.5764 0.0021 sec/batch\n",
      "Epoch 2/10 Iteration: 99600 Avg. Training loss: 1.6685 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 99800 Avg. Training loss: 1.5624 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 100000 Avg. Training loss: 1.6603 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 100200 Avg. Training loss: 1.6077 0.0016 sec/batch\n",
      "Epoch 2/10 Iteration: 100400 Avg. Training loss: 1.6894 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 100600 Avg. Training loss: 1.6254 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 100800 Avg. Training loss: 1.6497 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 101000 Avg. Training loss: 1.5078 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 101200 Avg. Training loss: 1.6258 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 101400 Avg. Training loss: 1.5969 0.0016 sec/batch\n",
      "Epoch 2/10 Iteration: 101600 Avg. Training loss: 1.5594 0.0015 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 101800 Avg. Training loss: 1.6725 0.0016 sec/batch\n",
      "Epoch 2/10 Iteration: 102000 Avg. Training loss: 1.6230 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 102200 Avg. Training loss: 1.6403 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 102400 Avg. Training loss: 1.5961 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 102600 Avg. Training loss: 1.5123 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 102800 Avg. Training loss: 1.6106 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 103000 Avg. Training loss: 1.6965 0.0016 sec/batch\n",
      "Epoch 2/10 Iteration: 103200 Avg. Training loss: 1.5807 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 103400 Avg. Training loss: 1.6229 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 103600 Avg. Training loss: 1.5776 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 103800 Avg. Training loss: 1.6807 0.0021 sec/batch\n",
      "Epoch 2/10 Iteration: 104000 Avg. Training loss: 1.7164 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 104200 Avg. Training loss: 1.5517 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 104400 Avg. Training loss: 1.6826 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 104600 Avg. Training loss: 1.4760 0.0021 sec/batch\n",
      "Epoch 2/10 Iteration: 104800 Avg. Training loss: 1.6273 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 105000 Avg. Training loss: 1.5523 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 105200 Avg. Training loss: 1.6444 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 105400 Avg. Training loss: 1.4449 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 105600 Avg. Training loss: 1.5908 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 105800 Avg. Training loss: 1.5105 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 106000 Avg. Training loss: 1.5774 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 106200 Avg. Training loss: 1.5566 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 106400 Avg. Training loss: 1.6704 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 106600 Avg. Training loss: 1.5942 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 106800 Avg. Training loss: 1.7091 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 107000 Avg. Training loss: 1.5787 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 107200 Avg. Training loss: 1.4842 0.0017 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 107400 Avg. Training loss: 1.5489 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 107600 Avg. Training loss: 1.7389 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 107800 Avg. Training loss: 1.5412 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 108000 Avg. Training loss: 1.7205 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 108200 Avg. Training loss: 1.6754 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 108400 Avg. Training loss: 1.5155 0.0020 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 108600 Avg. Training loss: 1.5477 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 108800 Avg. Training loss: 1.6466 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 109000 Avg. Training loss: 1.5799 0.0018 sec/batch\n",
      "Epoch 2/10 Iteration: 109200 Avg. Training loss: 1.5960 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 109400 Avg. Training loss: 1.6144 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 109600 Avg. Training loss: 1.5326 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 109800 Avg. Training loss: 1.6788 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 110000 Avg. Training loss: 1.6329 0.0017 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Iteration: 110200 Avg. Training loss: 1.7522 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 110400 Avg. Training loss: 1.5791 0.0019 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 110600 Avg. Training loss: 1.6276 0.0017 sec/batch\n",
      "Epoch 2/10 Iteration: 110800 Avg. Training loss: 1.5943 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 111000 Avg. Training loss: 1.5633 0.0019 sec/batch\n",
      "Epoch 2/10 Iteration: 111200 Avg. Training loss: 1.6695 0.0016 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 111400 Avg. Training loss: 1.4977 0.0020 sec/batch\n",
      "Epoch 2/10 Iteration: 111600 Avg. Training loss: 1.5993 0.0018 sec/batch\n",
      "error\n",
      "Epoch 2/10 Iteration: 111800 Avg. Training loss: 1.5627 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 112000 Avg. Training loss: 1.7080 0.0005 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 112200 Avg. Training loss: 1.5798 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 112400 Avg. Training loss: 1.6325 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 112600 Avg. Training loss: 1.6268 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 112800 Avg. Training loss: 1.5827 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 113000 Avg. Training loss: 1.6384 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 113200 Avg. Training loss: 1.5546 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 113400 Avg. Training loss: 1.5315 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 113600 Avg. Training loss: 1.8129 0.0020 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 113800 Avg. Training loss: 1.6418 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 114000 Avg. Training loss: 1.5149 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 114200 Avg. Training loss: 1.6304 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 114400 Avg. Training loss: 1.6997 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 114600 Avg. Training loss: 1.5237 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 114800 Avg. Training loss: 1.6782 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 115000 Avg. Training loss: 1.5922 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 115200 Avg. Training loss: 1.5203 0.0020 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 115400 Avg. Training loss: 1.6346 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 115600 Avg. Training loss: 1.5638 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 115800 Avg. Training loss: 1.7005 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 116000 Avg. Training loss: 1.6179 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 116200 Avg. Training loss: 1.5047 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 116400 Avg. Training loss: 1.5879 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 116600 Avg. Training loss: 1.5101 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 116800 Avg. Training loss: 1.6052 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 117000 Avg. Training loss: 1.4862 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 117200 Avg. Training loss: 1.4524 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 117400 Avg. Training loss: 1.5128 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 117600 Avg. Training loss: 1.4297 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 117800 Avg. Training loss: 1.4788 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 118000 Avg. Training loss: 1.5479 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 118200 Avg. Training loss: 1.5248 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 118400 Avg. Training loss: 1.6735 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 118600 Avg. Training loss: 1.5797 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 118800 Avg. Training loss: 1.5982 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 119000 Avg. Training loss: 1.5781 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 119200 Avg. Training loss: 1.6130 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 119400 Avg. Training loss: 1.5668 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 119600 Avg. Training loss: 1.5410 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 119800 Avg. Training loss: 1.4907 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 120000 Avg. Training loss: 1.6567 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 120200 Avg. Training loss: 1.5571 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 120400 Avg. Training loss: 1.5062 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 120600 Avg. Training loss: 1.5388 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 120800 Avg. Training loss: 1.6090 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 121000 Avg. Training loss: 1.5278 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 121200 Avg. Training loss: 1.5938 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 121400 Avg. Training loss: 1.6474 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 121600 Avg. Training loss: 1.5803 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 121800 Avg. Training loss: 1.6139 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 122000 Avg. Training loss: 1.6936 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 122200 Avg. Training loss: 1.6544 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 122400 Avg. Training loss: 1.6129 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 122600 Avg. Training loss: 1.5342 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 122800 Avg. Training loss: 1.5210 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 123000 Avg. Training loss: 1.5419 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 123200 Avg. Training loss: 1.4283 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 123400 Avg. Training loss: 1.3437 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 123600 Avg. Training loss: 1.5630 0.0015 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 123800 Avg. Training loss: 1.5424 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 124000 Avg. Training loss: 1.5685 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 124200 Avg. Training loss: 1.5878 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 124400 Avg. Training loss: 1.6587 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 124600 Avg. Training loss: 1.6619 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 124800 Avg. Training loss: 1.5658 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 125000 Avg. Training loss: 1.6444 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 125200 Avg. Training loss: 1.5680 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 125400 Avg. Training loss: 1.7246 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 125600 Avg. Training loss: 1.3902 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 125800 Avg. Training loss: 1.5489 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 126000 Avg. Training loss: 1.6910 0.0020 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 126200 Avg. Training loss: 1.3993 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 126400 Avg. Training loss: 1.5469 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 126600 Avg. Training loss: 1.6987 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 126800 Avg. Training loss: 1.6109 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 127000 Avg. Training loss: 1.5331 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 127200 Avg. Training loss: 1.6168 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 127400 Avg. Training loss: 1.6122 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 127600 Avg. Training loss: 1.6581 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 127800 Avg. Training loss: 1.5151 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 128000 Avg. Training loss: 1.5846 0.0015 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 128200 Avg. Training loss: 1.5266 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 128400 Avg. Training loss: 1.6488 0.0021 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 128600 Avg. Training loss: 1.6067 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 128800 Avg. Training loss: 1.6115 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 129000 Avg. Training loss: 1.4743 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 129200 Avg. Training loss: 1.7046 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 129400 Avg. Training loss: 1.5751 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 129600 Avg. Training loss: 1.5282 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 129800 Avg. Training loss: 1.6896 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 130000 Avg. Training loss: 1.5886 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 130200 Avg. Training loss: 1.4509 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 130400 Avg. Training loss: 1.5766 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 130600 Avg. Training loss: 1.5582 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 130800 Avg. Training loss: 1.5004 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 131000 Avg. Training loss: 1.6093 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 131200 Avg. Training loss: 1.5809 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 131400 Avg. Training loss: 1.6285 0.0015 sec/batch\n",
      "Epoch 3/10 Iteration: 131600 Avg. Training loss: 1.6364 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 131800 Avg. Training loss: 1.5000 0.0018 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Iteration: 132000 Avg. Training loss: 1.6769 0.0020 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 132200 Avg. Training loss: 1.6156 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 132400 Avg. Training loss: 1.6105 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 132600 Avg. Training loss: 1.5187 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 132800 Avg. Training loss: 1.6115 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 133000 Avg. Training loss: 1.5245 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 133200 Avg. Training loss: 1.4700 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 133400 Avg. Training loss: 1.4846 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 133600 Avg. Training loss: 1.6218 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 133800 Avg. Training loss: 1.5760 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 134000 Avg. Training loss: 1.5731 0.0020 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 134200 Avg. Training loss: 1.6220 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 134400 Avg. Training loss: 1.6401 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 134600 Avg. Training loss: 1.5474 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 134800 Avg. Training loss: 1.6106 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 135000 Avg. Training loss: 1.5341 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 135200 Avg. Training loss: 1.5995 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 135400 Avg. Training loss: 1.7672 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 135600 Avg. Training loss: 1.5469 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 135800 Avg. Training loss: 1.5967 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 136000 Avg. Training loss: 1.6293 0.0015 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 136200 Avg. Training loss: 1.6792 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 136400 Avg. Training loss: 1.5353 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 136600 Avg. Training loss: 1.5149 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 136800 Avg. Training loss: 1.6872 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 137000 Avg. Training loss: 1.5749 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 137200 Avg. Training loss: 1.5487 0.0020 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 137400 Avg. Training loss: 1.6504 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 137600 Avg. Training loss: 1.5466 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 137800 Avg. Training loss: 1.6190 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 138000 Avg. Training loss: 1.4606 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 138200 Avg. Training loss: 1.5361 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 138400 Avg. Training loss: 1.5005 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 138600 Avg. Training loss: 1.4810 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 138800 Avg. Training loss: 1.4243 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 139000 Avg. Training loss: 1.5572 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 139200 Avg. Training loss: 1.6181 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 139400 Avg. Training loss: 1.4688 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 139600 Avg. Training loss: 1.6268 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 139800 Avg. Training loss: 1.6728 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 140000 Avg. Training loss: 1.6291 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 140200 Avg. Training loss: 1.6600 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 140400 Avg. Training loss: 1.6077 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 140600 Avg. Training loss: 1.6887 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 140800 Avg. Training loss: 1.6881 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 141000 Avg. Training loss: 1.5455 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 141200 Avg. Training loss: 1.5186 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 141400 Avg. Training loss: 1.7739 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 141600 Avg. Training loss: 1.4884 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 141800 Avg. Training loss: 1.5888 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 142000 Avg. Training loss: 1.5976 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 142200 Avg. Training loss: 1.6276 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 142400 Avg. Training loss: 1.6507 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 142600 Avg. Training loss: 1.6611 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 142800 Avg. Training loss: 1.6193 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 143000 Avg. Training loss: 1.6153 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 143200 Avg. Training loss: 1.6509 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 143400 Avg. Training loss: 1.4742 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 143600 Avg. Training loss: 1.5611 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 143800 Avg. Training loss: 1.5634 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 144000 Avg. Training loss: 1.5038 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 144200 Avg. Training loss: 1.7936 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 144400 Avg. Training loss: 1.6746 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 144600 Avg. Training loss: 1.5552 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 144800 Avg. Training loss: 1.4847 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 145000 Avg. Training loss: 1.6131 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 145200 Avg. Training loss: 1.5660 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 145400 Avg. Training loss: 1.6334 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 145600 Avg. Training loss: 1.5515 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 145800 Avg. Training loss: 1.4796 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 146000 Avg. Training loss: 1.7111 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 146200 Avg. Training loss: 1.5506 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 146400 Avg. Training loss: 1.6479 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 146600 Avg. Training loss: 1.4123 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 146800 Avg. Training loss: 1.4977 0.0020 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 147000 Avg. Training loss: 1.5612 0.0021 sec/batch\n",
      "Epoch 3/10 Iteration: 147200 Avg. Training loss: 1.6424 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 147400 Avg. Training loss: 1.7374 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 147600 Avg. Training loss: 1.4078 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 147800 Avg. Training loss: 1.6890 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 148000 Avg. Training loss: 1.6054 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 148200 Avg. Training loss: 1.6452 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 148400 Avg. Training loss: 1.5426 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 148600 Avg. Training loss: 1.5897 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 148800 Avg. Training loss: 1.6920 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 149000 Avg. Training loss: 1.5557 0.0021 sec/batch\n",
      "Epoch 3/10 Iteration: 149200 Avg. Training loss: 1.7634 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 149400 Avg. Training loss: 1.6655 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 149600 Avg. Training loss: 1.6151 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 149800 Avg. Training loss: 1.6791 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 150000 Avg. Training loss: 1.6231 0.0020 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 150200 Avg. Training loss: 1.6003 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 150400 Avg. Training loss: 1.5021 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 150600 Avg. Training loss: 1.4800 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 150800 Avg. Training loss: 1.7355 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 151000 Avg. Training loss: 1.6098 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 151200 Avg. Training loss: 1.6312 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 151400 Avg. Training loss: 1.5032 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 151600 Avg. Training loss: 1.5133 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 151800 Avg. Training loss: 1.6352 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 152000 Avg. Training loss: 1.6862 0.0020 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 152200 Avg. Training loss: 1.5197 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 152400 Avg. Training loss: 1.5948 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 152600 Avg. Training loss: 1.6044 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 152800 Avg. Training loss: 1.5953 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 153000 Avg. Training loss: 1.6148 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 153200 Avg. Training loss: 1.5660 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 153400 Avg. Training loss: 1.5583 0.0017 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Iteration: 153600 Avg. Training loss: 1.6338 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 153800 Avg. Training loss: 1.6171 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 154000 Avg. Training loss: 1.6470 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 154200 Avg. Training loss: 1.6229 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 154400 Avg. Training loss: 1.4578 0.0015 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 154600 Avg. Training loss: 1.5288 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 154800 Avg. Training loss: 1.5995 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 155000 Avg. Training loss: 1.5098 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 155200 Avg. Training loss: 1.5390 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 155400 Avg. Training loss: 1.6005 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 155600 Avg. Training loss: 1.6027 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 155800 Avg. Training loss: 1.6942 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 156000 Avg. Training loss: 1.5839 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 156200 Avg. Training loss: 1.5231 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 156400 Avg. Training loss: 1.5684 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 156600 Avg. Training loss: 1.5416 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 156800 Avg. Training loss: 1.5881 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 157000 Avg. Training loss: 1.5911 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 157200 Avg. Training loss: 1.6041 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 157400 Avg. Training loss: 1.6419 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 157600 Avg. Training loss: 1.5632 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 157800 Avg. Training loss: 1.6177 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 158000 Avg. Training loss: 1.6188 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 158200 Avg. Training loss: 1.6474 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 158400 Avg. Training loss: 1.5461 0.0015 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 158600 Avg. Training loss: 1.4925 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 158800 Avg. Training loss: 1.6100 0.0015 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 159000 Avg. Training loss: 1.6081 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 159200 Avg. Training loss: 1.6386 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 159400 Avg. Training loss: 1.5324 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 159600 Avg. Training loss: 1.5028 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 159800 Avg. Training loss: 1.6365 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 160000 Avg. Training loss: 1.6702 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 160200 Avg. Training loss: 1.4853 0.0016 sec/batch\n",
      "Epoch 3/10 Iteration: 160400 Avg. Training loss: 1.5425 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 160600 Avg. Training loss: 1.5482 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 160800 Avg. Training loss: 1.5474 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 161000 Avg. Training loss: 1.6706 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 161200 Avg. Training loss: 1.6748 0.0020 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 161400 Avg. Training loss: 1.5454 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 161600 Avg. Training loss: 1.5523 0.0020 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 161800 Avg. Training loss: 1.4251 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 162000 Avg. Training loss: 1.6062 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 162200 Avg. Training loss: 1.4542 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 162400 Avg. Training loss: 1.6065 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 162600 Avg. Training loss: 1.5628 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 162800 Avg. Training loss: 1.5688 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 163000 Avg. Training loss: 1.4556 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 163200 Avg. Training loss: 1.5329 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 163400 Avg. Training loss: 1.6732 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 163600 Avg. Training loss: 1.6719 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 163800 Avg. Training loss: 1.4840 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 164000 Avg. Training loss: 1.7029 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 164200 Avg. Training loss: 1.4693 0.0020 sec/batch\n",
      "Epoch 3/10 Iteration: 164400 Avg. Training loss: 1.6189 0.0017 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 164600 Avg. Training loss: 1.6070 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 164800 Avg. Training loss: 1.5745 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 165000 Avg. Training loss: 1.4814 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 165200 Avg. Training loss: 1.5163 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 165400 Avg. Training loss: 1.5374 0.0019 sec/batch\n",
      "Epoch 3/10 Iteration: 165600 Avg. Training loss: 1.6139 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 165800 Avg. Training loss: 1.6345 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 166000 Avg. Training loss: 1.6456 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 166200 Avg. Training loss: 1.5872 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 166400 Avg. Training loss: 1.6154 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 166600 Avg. Training loss: 1.5971 0.0017 sec/batch\n",
      "Epoch 3/10 Iteration: 166800 Avg. Training loss: 1.6604 0.0018 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 167000 Avg. Training loss: 1.5476 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 167200 Avg. Training loss: 1.5344 0.0019 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 167400 Avg. Training loss: 1.5157 0.0018 sec/batch\n",
      "Epoch 3/10 Iteration: 167600 Avg. Training loss: 1.5471 0.0016 sec/batch\n",
      "error\n",
      "Epoch 3/10 Iteration: 167800 Avg. Training loss: 1.4449 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 168000 Avg. Training loss: 1.6267 0.0006 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 168200 Avg. Training loss: 1.5175 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 168400 Avg. Training loss: 1.5426 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 168600 Avg. Training loss: 1.5525 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 168800 Avg. Training loss: 1.6959 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 169000 Avg. Training loss: 1.3829 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 169200 Avg. Training loss: 1.7194 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 169400 Avg. Training loss: 1.6060 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 169600 Avg. Training loss: 1.5863 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 169800 Avg. Training loss: 1.5430 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 170000 Avg. Training loss: 1.5114 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 170200 Avg. Training loss: 1.5887 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 170400 Avg. Training loss: 1.7824 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 170600 Avg. Training loss: 1.5963 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 170800 Avg. Training loss: 1.5180 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 171000 Avg. Training loss: 1.5432 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 171200 Avg. Training loss: 1.6233 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 171400 Avg. Training loss: 1.4943 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 171600 Avg. Training loss: 1.4478 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 171800 Avg. Training loss: 1.5124 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 172000 Avg. Training loss: 1.5506 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 172200 Avg. Training loss: 1.5922 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 172400 Avg. Training loss: 1.6891 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 172600 Avg. Training loss: 1.5193 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 172800 Avg. Training loss: 1.6481 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 173000 Avg. Training loss: 1.3807 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 173200 Avg. Training loss: 1.5348 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 173400 Avg. Training loss: 1.5059 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 173600 Avg. Training loss: 1.5284 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 173800 Avg. Training loss: 1.4944 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 174000 Avg. Training loss: 1.5701 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 174200 Avg. Training loss: 1.5487 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 174400 Avg. Training loss: 1.6813 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 174600 Avg. Training loss: 1.5476 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 174800 Avg. Training loss: 1.5257 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 175000 Avg. Training loss: 1.6806 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 175200 Avg. Training loss: 1.6822 0.0018 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Iteration: 175400 Avg. Training loss: 1.5563 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 175600 Avg. Training loss: 1.4623 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 175800 Avg. Training loss: 1.5548 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 176000 Avg. Training loss: 1.5973 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 176200 Avg. Training loss: 1.7106 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 176400 Avg. Training loss: 1.6529 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 176600 Avg. Training loss: 1.6155 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 176800 Avg. Training loss: 1.5714 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 177000 Avg. Training loss: 1.4442 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 177200 Avg. Training loss: 1.5900 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 177400 Avg. Training loss: 1.7238 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 177600 Avg. Training loss: 1.5301 0.0015 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 177800 Avg. Training loss: 1.5889 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 178000 Avg. Training loss: 1.6446 0.0014 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 178200 Avg. Training loss: 1.6812 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 178400 Avg. Training loss: 1.5517 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 178600 Avg. Training loss: 1.5080 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 178800 Avg. Training loss: 1.5824 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 179000 Avg. Training loss: 1.5151 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 179200 Avg. Training loss: 1.4854 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 179400 Avg. Training loss: 1.4445 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 179600 Avg. Training loss: 1.4918 0.0015 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 179800 Avg. Training loss: 1.6618 0.0015 sec/batch\n",
      "Epoch 4/10 Iteration: 180000 Avg. Training loss: 1.4714 0.0015 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 180200 Avg. Training loss: 1.5173 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 180400 Avg. Training loss: 1.7055 0.0015 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 180600 Avg. Training loss: 1.5630 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 180800 Avg. Training loss: 1.5366 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 181000 Avg. Training loss: 1.5278 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 181200 Avg. Training loss: 1.6317 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 181400 Avg. Training loss: 1.6915 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 181600 Avg. Training loss: 1.6434 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 181800 Avg. Training loss: 1.5811 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 182000 Avg. Training loss: 1.5156 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 182200 Avg. Training loss: 1.4058 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 182400 Avg. Training loss: 1.6133 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 182600 Avg. Training loss: 1.6676 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 182800 Avg. Training loss: 1.5637 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 183000 Avg. Training loss: 1.5762 0.0021 sec/batch\n",
      "Epoch 4/10 Iteration: 183200 Avg. Training loss: 1.4286 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 183400 Avg. Training loss: 1.5194 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 183600 Avg. Training loss: 1.4799 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 183800 Avg. Training loss: 1.5188 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 184000 Avg. Training loss: 1.6087 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 184200 Avg. Training loss: 1.4739 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 184400 Avg. Training loss: 1.5597 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 184600 Avg. Training loss: 1.5244 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 184800 Avg. Training loss: 1.5468 0.0020 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 185000 Avg. Training loss: 1.5157 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 185200 Avg. Training loss: 1.6989 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 185400 Avg. Training loss: 1.5556 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 185600 Avg. Training loss: 1.5324 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 185800 Avg. Training loss: 1.5797 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 186000 Avg. Training loss: 1.6419 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 186200 Avg. Training loss: 1.4436 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 186400 Avg. Training loss: 1.5193 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 186600 Avg. Training loss: 1.5986 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 186800 Avg. Training loss: 1.6724 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 187000 Avg. Training loss: 1.5893 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 187200 Avg. Training loss: 1.4538 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 187400 Avg. Training loss: 1.5257 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 187600 Avg. Training loss: 1.7067 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 187800 Avg. Training loss: 1.4490 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 188000 Avg. Training loss: 1.5291 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 188200 Avg. Training loss: 1.6123 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 188400 Avg. Training loss: 1.4427 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 188600 Avg. Training loss: 1.5312 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 188800 Avg. Training loss: 1.6369 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 189000 Avg. Training loss: 1.4775 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 189200 Avg. Training loss: 1.5193 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 189400 Avg. Training loss: 1.5484 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 189600 Avg. Training loss: 1.6811 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 189800 Avg. Training loss: 1.6571 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 190000 Avg. Training loss: 1.6382 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 190200 Avg. Training loss: 1.5402 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 190400 Avg. Training loss: 1.5841 0.0020 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 190600 Avg. Training loss: 1.5086 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 190800 Avg. Training loss: 1.4835 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 191000 Avg. Training loss: 1.5217 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 191200 Avg. Training loss: 1.5207 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 191400 Avg. Training loss: 1.6574 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 191600 Avg. Training loss: 1.6028 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 191800 Avg. Training loss: 1.6604 0.0021 sec/batch\n",
      "Epoch 4/10 Iteration: 192000 Avg. Training loss: 1.6393 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 192200 Avg. Training loss: 1.6232 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 192400 Avg. Training loss: 1.5380 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 192600 Avg. Training loss: 1.5852 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 192800 Avg. Training loss: 1.5400 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 193000 Avg. Training loss: 1.5447 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 193200 Avg. Training loss: 1.7103 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 193400 Avg. Training loss: 1.5125 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 193600 Avg. Training loss: 1.5496 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 193800 Avg. Training loss: 1.4721 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 194000 Avg. Training loss: 1.5475 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 194200 Avg. Training loss: 1.5858 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 194400 Avg. Training loss: 1.4661 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 194600 Avg. Training loss: 1.5365 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 194800 Avg. Training loss: 1.5778 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 195000 Avg. Training loss: 1.4932 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 195200 Avg. Training loss: 1.7417 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 195400 Avg. Training loss: 1.5088 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 195600 Avg. Training loss: 1.5525 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 195800 Avg. Training loss: 1.4794 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 196000 Avg. Training loss: 1.6358 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 196200 Avg. Training loss: 1.5630 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 196400 Avg. Training loss: 1.6436 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 196600 Avg. Training loss: 1.6801 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 196800 Avg. Training loss: 1.5375 0.0018 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Iteration: 197000 Avg. Training loss: 1.4740 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 197200 Avg. Training loss: 1.5193 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 197400 Avg. Training loss: 1.6370 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 197600 Avg. Training loss: 1.5290 0.0015 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 197800 Avg. Training loss: 1.5657 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 198000 Avg. Training loss: 1.6040 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 198200 Avg. Training loss: 1.5746 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 198400 Avg. Training loss: 1.5420 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 198600 Avg. Training loss: 1.6049 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 198800 Avg. Training loss: 1.5271 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 199000 Avg. Training loss: 1.5845 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 199200 Avg. Training loss: 1.5698 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 199400 Avg. Training loss: 1.5098 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 199600 Avg. Training loss: 1.7525 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 199800 Avg. Training loss: 1.5911 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 200000 Avg. Training loss: 1.5361 0.0015 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 200200 Avg. Training loss: 1.6672 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 200400 Avg. Training loss: 1.6315 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 200600 Avg. Training loss: 1.5553 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 200800 Avg. Training loss: 1.4438 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 201000 Avg. Training loss: 1.5609 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 201200 Avg. Training loss: 1.6912 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 201400 Avg. Training loss: 1.5653 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 201600 Avg. Training loss: 1.6170 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 201800 Avg. Training loss: 1.6075 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 202000 Avg. Training loss: 1.6462 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 202200 Avg. Training loss: 1.5899 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 202400 Avg. Training loss: 1.6444 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 202600 Avg. Training loss: 1.6140 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 202800 Avg. Training loss: 1.5026 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 203000 Avg. Training loss: 1.4844 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 203200 Avg. Training loss: 1.5745 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 203400 Avg. Training loss: 1.6580 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 203600 Avg. Training loss: 1.4481 0.0020 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 203800 Avg. Training loss: 1.5727 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 204000 Avg. Training loss: 1.6079 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 204200 Avg. Training loss: 1.5668 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 204400 Avg. Training loss: 1.7007 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 204600 Avg. Training loss: 1.6425 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 204800 Avg. Training loss: 1.6098 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 205000 Avg. Training loss: 1.4979 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 205200 Avg. Training loss: 1.7040 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 205400 Avg. Training loss: 1.5369 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 205600 Avg. Training loss: 1.4737 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 205800 Avg. Training loss: 1.6732 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 206000 Avg. Training loss: 1.5762 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 206200 Avg. Training loss: 1.6368 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 206400 Avg. Training loss: 1.6365 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 206600 Avg. Training loss: 1.6706 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 206800 Avg. Training loss: 1.6663 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 207000 Avg. Training loss: 1.4730 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 207200 Avg. Training loss: 1.6186 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 207400 Avg. Training loss: 1.4770 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 207600 Avg. Training loss: 1.6068 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 207800 Avg. Training loss: 1.5954 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 208000 Avg. Training loss: 1.6200 0.0020 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 208200 Avg. Training loss: 1.4220 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 208400 Avg. Training loss: 1.5629 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 208600 Avg. Training loss: 1.5699 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 208800 Avg. Training loss: 1.6278 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 209000 Avg. Training loss: 1.5226 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 209200 Avg. Training loss: 1.5558 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 209400 Avg. Training loss: 1.6227 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 209600 Avg. Training loss: 1.5250 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 209800 Avg. Training loss: 1.5304 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 210000 Avg. Training loss: 1.6042 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 210200 Avg. Training loss: 1.6985 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 210400 Avg. Training loss: 1.5731 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 210600 Avg. Training loss: 1.4353 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 210800 Avg. Training loss: 1.5147 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 211000 Avg. Training loss: 1.5168 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 211200 Avg. Training loss: 1.5684 0.0014 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 211400 Avg. Training loss: 1.5582 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 211600 Avg. Training loss: 1.5913 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 211800 Avg. Training loss: 1.4662 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 212000 Avg. Training loss: 1.4976 0.0015 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 212200 Avg. Training loss: 1.3939 0.0015 sec/batch\n",
      "Epoch 4/10 Iteration: 212400 Avg. Training loss: 1.5686 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 212600 Avg. Training loss: 1.3671 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 212800 Avg. Training loss: 1.5972 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 213000 Avg. Training loss: 1.5954 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 213200 Avg. Training loss: 1.4863 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 213400 Avg. Training loss: 1.5857 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 213600 Avg. Training loss: 1.5065 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 213800 Avg. Training loss: 1.5198 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 214000 Avg. Training loss: 1.5296 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 214200 Avg. Training loss: 1.7834 0.0021 sec/batch\n",
      "Epoch 4/10 Iteration: 214400 Avg. Training loss: 1.5300 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 214600 Avg. Training loss: 1.5788 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 214800 Avg. Training loss: 1.7628 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 215000 Avg. Training loss: 1.7018 0.0019 sec/batch\n",
      "Epoch 4/10 Iteration: 215200 Avg. Training loss: 1.6057 0.0015 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 215400 Avg. Training loss: 1.5559 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 215600 Avg. Training loss: 1.4599 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 215800 Avg. Training loss: 1.5134 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 216000 Avg. Training loss: 1.5905 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 216200 Avg. Training loss: 1.5235 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 216400 Avg. Training loss: 1.6124 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 216600 Avg. Training loss: 1.5854 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 216800 Avg. Training loss: 1.5612 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 217000 Avg. Training loss: 1.5511 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 217200 Avg. Training loss: 1.6304 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 217400 Avg. Training loss: 1.6018 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 217600 Avg. Training loss: 1.5034 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 217800 Avg. Training loss: 1.5776 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 218000 Avg. Training loss: 1.5014 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 218200 Avg. Training loss: 1.4848 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 218400 Avg. Training loss: 1.6100 0.0019 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Iteration: 218600 Avg. Training loss: 1.5031 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 218800 Avg. Training loss: 1.5860 0.0021 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 219000 Avg. Training loss: 1.5224 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 219200 Avg. Training loss: 1.4899 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 219400 Avg. Training loss: 1.6291 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 219600 Avg. Training loss: 1.7359 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 219800 Avg. Training loss: 1.5635 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 220000 Avg. Training loss: 1.6899 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 220200 Avg. Training loss: 1.5378 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 220400 Avg. Training loss: 1.7131 0.0015 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 220600 Avg. Training loss: 1.5782 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 220800 Avg. Training loss: 1.6502 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 221000 Avg. Training loss: 1.6561 0.0017 sec/batch\n",
      "Epoch 4/10 Iteration: 221200 Avg. Training loss: 1.5913 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 221400 Avg. Training loss: 1.5838 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 221600 Avg. Training loss: 1.3174 0.0018 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 221800 Avg. Training loss: 1.5951 0.0020 sec/batch\n",
      "Epoch 4/10 Iteration: 222000 Avg. Training loss: 1.4158 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 222200 Avg. Training loss: 1.6336 0.0015 sec/batch\n",
      "Epoch 4/10 Iteration: 222400 Avg. Training loss: 1.7251 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 222600 Avg. Training loss: 1.5866 0.0016 sec/batch\n",
      "Epoch 4/10 Iteration: 222800 Avg. Training loss: 1.6219 0.0016 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 223000 Avg. Training loss: 1.5973 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 223200 Avg. Training loss: 1.4848 0.0019 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 223400 Avg. Training loss: 1.5540 0.0018 sec/batch\n",
      "Epoch 4/10 Iteration: 223600 Avg. Training loss: 1.7551 0.0017 sec/batch\n",
      "error\n",
      "Epoch 4/10 Iteration: 223800 Avg. Training loss: 1.4093 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 224000 Avg. Training loss: 1.5999 0.0009 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 224200 Avg. Training loss: 1.6388 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 224400 Avg. Training loss: 1.4518 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 224600 Avg. Training loss: 1.5988 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 224800 Avg. Training loss: 1.5686 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 225000 Avg. Training loss: 1.5964 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 225200 Avg. Training loss: 1.6243 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 225400 Avg. Training loss: 1.7672 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 225600 Avg. Training loss: 1.6378 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 225800 Avg. Training loss: 1.5145 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 226000 Avg. Training loss: 1.3247 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 226200 Avg. Training loss: 1.5661 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 226400 Avg. Training loss: 1.5342 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 226600 Avg. Training loss: 1.5282 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 226800 Avg. Training loss: 1.5151 0.0015 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 227000 Avg. Training loss: 1.6061 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 227200 Avg. Training loss: 1.5298 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 227400 Avg. Training loss: 1.6024 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 227600 Avg. Training loss: 1.5206 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 227800 Avg. Training loss: 1.6742 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 228000 Avg. Training loss: 1.5911 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 228200 Avg. Training loss: 1.5778 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 228400 Avg. Training loss: 1.5250 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 228600 Avg. Training loss: 1.4882 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 228800 Avg. Training loss: 1.6591 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 229000 Avg. Training loss: 1.4676 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 229200 Avg. Training loss: 1.4410 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 229400 Avg. Training loss: 1.4592 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 229600 Avg. Training loss: 1.5796 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 229800 Avg. Training loss: 1.4706 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 230000 Avg. Training loss: 1.5961 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 230200 Avg. Training loss: 1.6015 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 230400 Avg. Training loss: 1.6292 0.0020 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 230600 Avg. Training loss: 1.6282 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 230800 Avg. Training loss: 1.6962 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 231000 Avg. Training loss: 1.6133 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 231200 Avg. Training loss: 1.5857 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 231400 Avg. Training loss: 1.6846 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 231600 Avg. Training loss: 1.5099 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 231800 Avg. Training loss: 1.5266 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 232000 Avg. Training loss: 1.5764 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 232200 Avg. Training loss: 1.5439 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 232400 Avg. Training loss: 1.5288 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 232600 Avg. Training loss: 1.6338 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 232800 Avg. Training loss: 1.5678 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 233000 Avg. Training loss: 1.4879 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 233200 Avg. Training loss: 1.5418 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 233400 Avg. Training loss: 1.7657 0.0020 sec/batch\n",
      "Epoch 5/10 Iteration: 233600 Avg. Training loss: 1.6374 0.0015 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 233800 Avg. Training loss: 1.5158 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 234000 Avg. Training loss: 1.7188 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 234200 Avg. Training loss: 1.4952 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 234400 Avg. Training loss: 1.4797 0.0015 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 234600 Avg. Training loss: 1.6170 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 234800 Avg. Training loss: 1.4795 0.0015 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 235000 Avg. Training loss: 1.6181 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 235200 Avg. Training loss: 1.5495 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 235400 Avg. Training loss: 1.5748 0.0015 sec/batch\n",
      "Epoch 5/10 Iteration: 235600 Avg. Training loss: 1.5221 0.0015 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 235800 Avg. Training loss: 1.5359 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 236000 Avg. Training loss: 1.4509 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 236200 Avg. Training loss: 1.6476 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 236400 Avg. Training loss: 1.6209 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 236600 Avg. Training loss: 1.4349 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 236800 Avg. Training loss: 1.6807 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 237000 Avg. Training loss: 1.4730 0.0021 sec/batch\n",
      "Epoch 5/10 Iteration: 237200 Avg. Training loss: 1.6703 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 237400 Avg. Training loss: 1.6437 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 237600 Avg. Training loss: 1.5458 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 237800 Avg. Training loss: 1.5161 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 238000 Avg. Training loss: 1.5046 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 238200 Avg. Training loss: 1.5258 0.0020 sec/batch\n",
      "Epoch 5/10 Iteration: 238400 Avg. Training loss: 1.5036 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 238600 Avg. Training loss: 1.5428 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 238800 Avg. Training loss: 1.4435 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 239000 Avg. Training loss: 1.5404 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 239200 Avg. Training loss: 1.5776 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 239400 Avg. Training loss: 1.5671 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 239600 Avg. Training loss: 1.6516 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 239800 Avg. Training loss: 1.5342 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 240000 Avg. Training loss: 1.5991 0.0017 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Iteration: 240200 Avg. Training loss: 1.5290 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 240400 Avg. Training loss: 1.6825 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 240600 Avg. Training loss: 1.5252 0.0020 sec/batch\n",
      "Epoch 5/10 Iteration: 240800 Avg. Training loss: 1.5549 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 241000 Avg. Training loss: 1.5489 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 241200 Avg. Training loss: 1.5757 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 241400 Avg. Training loss: 1.5379 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 241600 Avg. Training loss: 1.4981 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 241800 Avg. Training loss: 1.5308 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 242000 Avg. Training loss: 1.4166 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 242200 Avg. Training loss: 1.3743 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 242400 Avg. Training loss: 1.4595 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 242600 Avg. Training loss: 1.5410 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 242800 Avg. Training loss: 1.6159 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 243000 Avg. Training loss: 1.6222 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 243200 Avg. Training loss: 1.6687 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 243400 Avg. Training loss: 1.5473 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 243600 Avg. Training loss: 1.6679 0.0014 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 243800 Avg. Training loss: 1.5545 0.0015 sec/batch\n",
      "Epoch 5/10 Iteration: 244000 Avg. Training loss: 1.5725 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 244200 Avg. Training loss: 1.6407 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 244400 Avg. Training loss: 1.4869 0.0015 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 244600 Avg. Training loss: 1.6141 0.0015 sec/batch\n",
      "Epoch 5/10 Iteration: 244800 Avg. Training loss: 1.5718 0.0014 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 245000 Avg. Training loss: 1.6214 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 245200 Avg. Training loss: 1.5472 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 245400 Avg. Training loss: 1.6570 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 245600 Avg. Training loss: 1.5649 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 245800 Avg. Training loss: 1.6470 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 246000 Avg. Training loss: 1.6007 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 246200 Avg. Training loss: 1.5574 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 246400 Avg. Training loss: 1.6207 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 246600 Avg. Training loss: 1.6202 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 246800 Avg. Training loss: 1.4944 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 247000 Avg. Training loss: 1.4654 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 247200 Avg. Training loss: 1.6298 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 247400 Avg. Training loss: 1.6797 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 247600 Avg. Training loss: 1.5090 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 247800 Avg. Training loss: 1.6484 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 248000 Avg. Training loss: 1.6791 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 248200 Avg. Training loss: 1.6444 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 248400 Avg. Training loss: 1.4744 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 248600 Avg. Training loss: 1.5576 0.0015 sec/batch\n",
      "Epoch 5/10 Iteration: 248800 Avg. Training loss: 1.6559 0.0015 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 249000 Avg. Training loss: 1.5783 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 249200 Avg. Training loss: 1.6046 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 249400 Avg. Training loss: 1.6001 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 249600 Avg. Training loss: 1.5215 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 249800 Avg. Training loss: 1.6182 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 250000 Avg. Training loss: 1.4916 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 250200 Avg. Training loss: 1.4277 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 250400 Avg. Training loss: 1.6102 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 250600 Avg. Training loss: 1.5967 0.0020 sec/batch\n",
      "Epoch 5/10 Iteration: 250800 Avg. Training loss: 1.5331 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 251000 Avg. Training loss: 1.6315 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 251200 Avg. Training loss: 1.5454 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 251400 Avg. Training loss: 1.6157 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 251600 Avg. Training loss: 1.6887 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 251800 Avg. Training loss: 1.6712 0.0020 sec/batch\n",
      "Epoch 5/10 Iteration: 252000 Avg. Training loss: 1.6444 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 252200 Avg. Training loss: 1.6045 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 252400 Avg. Training loss: 1.6504 0.0015 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 252600 Avg. Training loss: 1.6985 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 252800 Avg. Training loss: 1.5959 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 253000 Avg. Training loss: 1.4581 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 253200 Avg. Training loss: 1.6264 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 253400 Avg. Training loss: 1.5959 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 253600 Avg. Training loss: 1.5059 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 253800 Avg. Training loss: 1.4181 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 254000 Avg. Training loss: 1.5558 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 254200 Avg. Training loss: 1.6399 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 254400 Avg. Training loss: 1.4750 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 254600 Avg. Training loss: 1.6330 0.0020 sec/batch\n",
      "Epoch 5/10 Iteration: 254800 Avg. Training loss: 1.6394 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 255000 Avg. Training loss: 1.5625 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 255200 Avg. Training loss: 1.5984 0.0015 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 255400 Avg. Training loss: 1.6313 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 255600 Avg. Training loss: 1.5451 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 255800 Avg. Training loss: 1.4253 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 256000 Avg. Training loss: 1.4284 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 256200 Avg. Training loss: 1.6904 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 256400 Avg. Training loss: 1.5984 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 256600 Avg. Training loss: 1.6160 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 256800 Avg. Training loss: 1.5605 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 257000 Avg. Training loss: 1.5792 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 257200 Avg. Training loss: 1.6743 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 257400 Avg. Training loss: 1.6962 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 257600 Avg. Training loss: 1.5568 0.0014 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 257800 Avg. Training loss: 1.5415 0.0015 sec/batch\n",
      "Epoch 5/10 Iteration: 258000 Avg. Training loss: 1.6846 0.0015 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 258200 Avg. Training loss: 1.5609 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 258400 Avg. Training loss: 1.5841 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 258600 Avg. Training loss: 1.4313 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 258800 Avg. Training loss: 1.6365 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 259000 Avg. Training loss: 1.5954 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 259200 Avg. Training loss: 1.6114 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 259400 Avg. Training loss: 1.6121 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 259600 Avg. Training loss: 1.5589 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 259800 Avg. Training loss: 1.5722 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 260000 Avg. Training loss: 1.5667 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 260200 Avg. Training loss: 1.6524 0.0020 sec/batch\n",
      "Epoch 5/10 Iteration: 260400 Avg. Training loss: 1.6084 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 260600 Avg. Training loss: 1.6395 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 260800 Avg. Training loss: 1.6064 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 261000 Avg. Training loss: 1.5814 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 261200 Avg. Training loss: 1.6186 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 261400 Avg. Training loss: 1.5514 0.0021 sec/batch\n",
      "Epoch 5/10 Iteration: 261600 Avg. Training loss: 1.5928 0.0018 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Iteration: 261800 Avg. Training loss: 1.5512 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 262000 Avg. Training loss: 1.4793 0.0021 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 262200 Avg. Training loss: 1.5699 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 262400 Avg. Training loss: 1.3736 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 262600 Avg. Training loss: 1.5320 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 262800 Avg. Training loss: 1.6285 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 263000 Avg. Training loss: 1.4799 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 263200 Avg. Training loss: 1.5172 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 263400 Avg. Training loss: 1.6293 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 263600 Avg. Training loss: 1.4945 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 263800 Avg. Training loss: 1.6180 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 264000 Avg. Training loss: 1.5312 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 264200 Avg. Training loss: 1.6516 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 264400 Avg. Training loss: 1.5055 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 264600 Avg. Training loss: 1.5929 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 264800 Avg. Training loss: 1.4783 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 265000 Avg. Training loss: 1.6266 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 265200 Avg. Training loss: 1.4384 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 265400 Avg. Training loss: 1.5594 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 265600 Avg. Training loss: 1.4703 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 265800 Avg. Training loss: 1.6854 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 266000 Avg. Training loss: 1.5511 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 266200 Avg. Training loss: 1.5721 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 266400 Avg. Training loss: 1.6255 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 266600 Avg. Training loss: 1.5470 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 266800 Avg. Training loss: 1.5251 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 267000 Avg. Training loss: 1.4748 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 267200 Avg. Training loss: 1.5591 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 267400 Avg. Training loss: 1.6545 0.0015 sec/batch\n",
      "Epoch 5/10 Iteration: 267600 Avg. Training loss: 1.7123 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 267800 Avg. Training loss: 1.4883 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 268000 Avg. Training loss: 1.5427 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 268200 Avg. Training loss: 1.6308 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 268400 Avg. Training loss: 1.4930 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 268600 Avg. Training loss: 1.5054 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 268800 Avg. Training loss: 1.4873 0.0015 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 269000 Avg. Training loss: 1.4154 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 269200 Avg. Training loss: 1.5802 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 269400 Avg. Training loss: 1.4219 0.0015 sec/batch\n",
      "Epoch 5/10 Iteration: 269600 Avg. Training loss: 1.5423 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 269800 Avg. Training loss: 1.4850 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 270000 Avg. Training loss: 1.5216 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 270200 Avg. Training loss: 1.4474 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 270400 Avg. Training loss: 1.6704 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 270600 Avg. Training loss: 1.6674 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 270800 Avg. Training loss: 1.5272 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 271000 Avg. Training loss: 1.6224 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 271200 Avg. Training loss: 1.6242 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 271400 Avg. Training loss: 1.6149 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 271600 Avg. Training loss: 1.6953 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 271800 Avg. Training loss: 1.5259 0.0020 sec/batch\n",
      "Epoch 5/10 Iteration: 272000 Avg. Training loss: 1.5723 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 272200 Avg. Training loss: 1.5135 0.0020 sec/batch\n",
      "Epoch 5/10 Iteration: 272400 Avg. Training loss: 1.6045 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 272600 Avg. Training loss: 1.5877 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 272800 Avg. Training loss: 1.6442 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 273000 Avg. Training loss: 1.6092 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 273200 Avg. Training loss: 1.5017 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 273400 Avg. Training loss: 1.5935 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 273600 Avg. Training loss: 1.5458 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 273800 Avg. Training loss: 1.5682 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 274000 Avg. Training loss: 1.5565 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 274200 Avg. Training loss: 1.6175 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 274400 Avg. Training loss: 1.6705 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 274600 Avg. Training loss: 1.6234 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 274800 Avg. Training loss: 1.5556 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 275000 Avg. Training loss: 1.4922 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 275200 Avg. Training loss: 1.5276 0.0015 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 275400 Avg. Training loss: 1.6432 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 275600 Avg. Training loss: 1.6879 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 275800 Avg. Training loss: 1.5489 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 276000 Avg. Training loss: 1.6359 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 276200 Avg. Training loss: 1.7373 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 276400 Avg. Training loss: 1.5627 0.0020 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 276600 Avg. Training loss: 1.5258 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 276800 Avg. Training loss: 1.5290 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 277000 Avg. Training loss: 1.6226 0.0016 sec/batch\n",
      "Epoch 5/10 Iteration: 277200 Avg. Training loss: 1.5869 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 277400 Avg. Training loss: 1.5336 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 277600 Avg. Training loss: 1.4422 0.0019 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 277800 Avg. Training loss: 1.6662 0.0019 sec/batch\n",
      "Epoch 5/10 Iteration: 278000 Avg. Training loss: 1.6992 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 278200 Avg. Training loss: 1.5385 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 278400 Avg. Training loss: 1.6228 0.0017 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 278600 Avg. Training loss: 1.6019 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 278800 Avg. Training loss: 1.6628 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 279000 Avg. Training loss: 1.6059 0.0017 sec/batch\n",
      "Epoch 5/10 Iteration: 279200 Avg. Training loss: 1.5859 0.0018 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 279400 Avg. Training loss: 1.5383 0.0018 sec/batch\n",
      "Epoch 5/10 Iteration: 279600 Avg. Training loss: 1.6594 0.0016 sec/batch\n",
      "error\n",
      "Epoch 5/10 Iteration: 279800 Avg. Training loss: 1.5056 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 280000 Avg. Training loss: 1.6505 0.0010 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 280200 Avg. Training loss: 1.5493 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 280400 Avg. Training loss: 1.5259 0.0020 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 280600 Avg. Training loss: 1.6108 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 280800 Avg. Training loss: 1.5922 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 281000 Avg. Training loss: 1.6169 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 281200 Avg. Training loss: 1.6088 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 281400 Avg. Training loss: 1.5931 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 281600 Avg. Training loss: 1.5679 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 281800 Avg. Training loss: 1.5381 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 282000 Avg. Training loss: 1.4627 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 282200 Avg. Training loss: 1.6230 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 282400 Avg. Training loss: 1.6477 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 282600 Avg. Training loss: 1.5592 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 282800 Avg. Training loss: 1.3747 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 283000 Avg. Training loss: 1.6295 0.0020 sec/batch\n",
      "Epoch 6/10 Iteration: 283200 Avg. Training loss: 1.5452 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 283400 Avg. Training loss: 1.5632 0.0017 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Iteration: 283600 Avg. Training loss: 1.5365 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 283800 Avg. Training loss: 1.5954 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 284000 Avg. Training loss: 1.5979 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 284200 Avg. Training loss: 1.6024 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 284400 Avg. Training loss: 1.5331 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 284600 Avg. Training loss: 1.4313 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 284800 Avg. Training loss: 1.7205 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 285000 Avg. Training loss: 1.5089 0.0020 sec/batch\n",
      "Epoch 6/10 Iteration: 285200 Avg. Training loss: 1.5657 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 285400 Avg. Training loss: 1.4980 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 285600 Avg. Training loss: 1.6033 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 285800 Avg. Training loss: 1.6002 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 286000 Avg. Training loss: 1.5774 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 286200 Avg. Training loss: 1.4947 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 286400 Avg. Training loss: 1.7093 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 286600 Avg. Training loss: 1.6556 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 286800 Avg. Training loss: 1.6301 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 287000 Avg. Training loss: 1.4800 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 287200 Avg. Training loss: 1.6498 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 287400 Avg. Training loss: 1.6328 0.0020 sec/batch\n",
      "Epoch 6/10 Iteration: 287600 Avg. Training loss: 1.5680 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 287800 Avg. Training loss: 1.6473 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 288000 Avg. Training loss: 1.4077 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 288200 Avg. Training loss: 1.6127 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 288400 Avg. Training loss: 1.5258 0.0015 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 288600 Avg. Training loss: 1.5407 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 288800 Avg. Training loss: 1.5560 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 289000 Avg. Training loss: 1.3994 0.0020 sec/batch\n",
      "Epoch 6/10 Iteration: 289200 Avg. Training loss: 1.6840 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 289400 Avg. Training loss: 1.6027 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 289600 Avg. Training loss: 1.4702 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 289800 Avg. Training loss: 1.6164 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 290000 Avg. Training loss: 1.7072 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 290200 Avg. Training loss: 1.7003 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 290400 Avg. Training loss: 1.4536 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 290600 Avg. Training loss: 1.6537 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 290800 Avg. Training loss: 1.5181 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 291000 Avg. Training loss: 1.6167 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 291200 Avg. Training loss: 1.5431 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 291400 Avg. Training loss: 1.5145 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 291600 Avg. Training loss: 1.6248 0.0015 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 291800 Avg. Training loss: 1.4539 0.0015 sec/batch\n",
      "Epoch 6/10 Iteration: 292000 Avg. Training loss: 1.5347 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 292200 Avg. Training loss: 1.5374 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 292400 Avg. Training loss: 1.6493 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 292600 Avg. Training loss: 1.5985 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 292800 Avg. Training loss: 1.5433 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 293000 Avg. Training loss: 1.5295 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 293200 Avg. Training loss: 1.6627 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 293400 Avg. Training loss: 1.6812 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 293600 Avg. Training loss: 1.4960 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 293800 Avg. Training loss: 1.4600 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 294000 Avg. Training loss: 1.5713 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 294200 Avg. Training loss: 1.4864 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 294400 Avg. Training loss: 1.6051 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 294600 Avg. Training loss: 1.4815 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 294800 Avg. Training loss: 1.5719 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 295000 Avg. Training loss: 1.4738 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 295200 Avg. Training loss: 1.5206 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 295400 Avg. Training loss: 1.6702 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 295600 Avg. Training loss: 1.5439 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 295800 Avg. Training loss: 1.5464 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 296000 Avg. Training loss: 1.6118 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 296200 Avg. Training loss: 1.5257 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 296400 Avg. Training loss: 1.6504 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 296600 Avg. Training loss: 1.4823 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 296800 Avg. Training loss: 1.5732 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 297000 Avg. Training loss: 1.5937 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 297200 Avg. Training loss: 1.5965 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 297400 Avg. Training loss: 1.5646 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 297600 Avg. Training loss: 1.5722 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 297800 Avg. Training loss: 1.5646 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 298000 Avg. Training loss: 1.5771 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 298200 Avg. Training loss: 1.6170 0.0020 sec/batch\n",
      "Epoch 6/10 Iteration: 298400 Avg. Training loss: 1.4761 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 298600 Avg. Training loss: 1.5676 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 298800 Avg. Training loss: 1.5860 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 299000 Avg. Training loss: 1.5430 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 299200 Avg. Training loss: 1.5487 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 299400 Avg. Training loss: 1.5651 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 299600 Avg. Training loss: 1.5873 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 299800 Avg. Training loss: 1.5796 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 300000 Avg. Training loss: 1.5964 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 300200 Avg. Training loss: 1.6486 0.0021 sec/batch\n",
      "Epoch 6/10 Iteration: 300400 Avg. Training loss: 1.6511 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 300600 Avg. Training loss: 1.5382 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 300800 Avg. Training loss: 1.5125 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 301000 Avg. Training loss: 1.5931 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 301200 Avg. Training loss: 1.4893 0.0020 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 301400 Avg. Training loss: 1.6805 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 301600 Avg. Training loss: 1.5962 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 301800 Avg. Training loss: 1.6236 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 302000 Avg. Training loss: 1.6369 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 302200 Avg. Training loss: 1.5890 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 302400 Avg. Training loss: 1.6489 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 302600 Avg. Training loss: 1.5673 0.0015 sec/batch\n",
      "Epoch 6/10 Iteration: 302800 Avg. Training loss: 1.4700 0.0015 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 303000 Avg. Training loss: 1.5408 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 303200 Avg. Training loss: 1.6439 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 303400 Avg. Training loss: 1.6299 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 303600 Avg. Training loss: 1.6102 0.0015 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 303800 Avg. Training loss: 1.7177 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 304000 Avg. Training loss: 1.4662 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 304200 Avg. Training loss: 1.5490 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 304400 Avg. Training loss: 1.5677 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 304600 Avg. Training loss: 1.5229 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 304800 Avg. Training loss: 1.5923 0.0015 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 305000 Avg. Training loss: 1.5708 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 305200 Avg. Training loss: 1.5418 0.0017 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Iteration: 305400 Avg. Training loss: 1.6680 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 305600 Avg. Training loss: 1.6508 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 305800 Avg. Training loss: 1.5449 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 306000 Avg. Training loss: 1.6174 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 306200 Avg. Training loss: 1.5822 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 306400 Avg. Training loss: 1.5722 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 306600 Avg. Training loss: 1.4338 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 306800 Avg. Training loss: 1.6011 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 307000 Avg. Training loss: 1.6577 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 307200 Avg. Training loss: 1.6078 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 307400 Avg. Training loss: 1.4391 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 307600 Avg. Training loss: 1.4818 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 307800 Avg. Training loss: 1.6243 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 308000 Avg. Training loss: 1.6689 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 308200 Avg. Training loss: 1.8095 0.0020 sec/batch\n",
      "Epoch 6/10 Iteration: 308400 Avg. Training loss: 1.6774 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 308600 Avg. Training loss: 1.5830 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 308800 Avg. Training loss: 1.5438 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 309000 Avg. Training loss: 1.6426 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 309200 Avg. Training loss: 1.6146 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 309400 Avg. Training loss: 1.5233 0.0020 sec/batch\n",
      "Epoch 6/10 Iteration: 309600 Avg. Training loss: 1.5277 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 309800 Avg. Training loss: 1.4937 0.0021 sec/batch\n",
      "Epoch 6/10 Iteration: 310000 Avg. Training loss: 1.3763 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 310200 Avg. Training loss: 1.6036 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 310400 Avg. Training loss: 1.5461 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 310600 Avg. Training loss: 1.4430 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 310800 Avg. Training loss: 1.5579 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 311000 Avg. Training loss: 1.6715 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 311200 Avg. Training loss: 1.4928 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 311400 Avg. Training loss: 1.5290 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 311600 Avg. Training loss: 1.6418 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 311800 Avg. Training loss: 1.4761 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 312000 Avg. Training loss: 1.6301 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 312200 Avg. Training loss: 1.6742 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 312400 Avg. Training loss: 1.6433 0.0014 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 312600 Avg. Training loss: 1.5540 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 312800 Avg. Training loss: 1.5553 0.0015 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 313000 Avg. Training loss: 1.6156 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 313200 Avg. Training loss: 1.6914 0.0014 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 313400 Avg. Training loss: 1.7645 0.0015 sec/batch\n",
      "Epoch 6/10 Iteration: 313600 Avg. Training loss: 1.4955 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 313800 Avg. Training loss: 1.5215 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 314000 Avg. Training loss: 1.4319 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 314200 Avg. Training loss: 1.5893 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 314400 Avg. Training loss: 1.4919 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 314600 Avg. Training loss: 1.4698 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 314800 Avg. Training loss: 1.5027 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 315000 Avg. Training loss: 1.6433 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 315200 Avg. Training loss: 1.6286 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 315400 Avg. Training loss: 1.5419 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 315600 Avg. Training loss: 1.6639 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 315800 Avg. Training loss: 1.4383 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 316000 Avg. Training loss: 1.6173 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 316200 Avg. Training loss: 1.6364 0.0021 sec/batch\n",
      "Epoch 6/10 Iteration: 316400 Avg. Training loss: 1.6157 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 316600 Avg. Training loss: 1.6513 0.0020 sec/batch\n",
      "Epoch 6/10 Iteration: 316800 Avg. Training loss: 1.6153 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 317000 Avg. Training loss: 1.4666 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 317200 Avg. Training loss: 1.6429 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 317400 Avg. Training loss: 1.5232 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 317600 Avg. Training loss: 1.5472 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 317800 Avg. Training loss: 1.5307 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 318000 Avg. Training loss: 1.6331 0.0020 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 318200 Avg. Training loss: 1.4779 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 318400 Avg. Training loss: 1.4687 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 318600 Avg. Training loss: 1.6147 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 318800 Avg. Training loss: 1.7020 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 319000 Avg. Training loss: 1.5630 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 319200 Avg. Training loss: 1.6148 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 319400 Avg. Training loss: 1.4157 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 319600 Avg. Training loss: 1.5102 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 319800 Avg. Training loss: 1.4847 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 320000 Avg. Training loss: 1.5642 0.0021 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 320200 Avg. Training loss: 1.6317 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 320400 Avg. Training loss: 1.5420 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 320600 Avg. Training loss: 1.5141 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 320800 Avg. Training loss: 1.4035 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 321000 Avg. Training loss: 1.6311 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 321200 Avg. Training loss: 1.6226 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 321400 Avg. Training loss: 1.4551 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 321600 Avg. Training loss: 1.4679 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 321800 Avg. Training loss: 1.6244 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 322000 Avg. Training loss: 1.6677 0.0022 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 322200 Avg. Training loss: 1.5523 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 322400 Avg. Training loss: 1.5255 0.0015 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 322600 Avg. Training loss: 1.4757 0.0015 sec/batch\n",
      "Epoch 6/10 Iteration: 322800 Avg. Training loss: 1.6128 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 323000 Avg. Training loss: 1.4821 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 323200 Avg. Training loss: 1.4704 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 323400 Avg. Training loss: 1.7116 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 323600 Avg. Training loss: 1.5878 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 323800 Avg. Training loss: 1.4693 0.0109 sec/batch\n",
      "Epoch 6/10 Iteration: 324000 Avg. Training loss: 1.4805 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 324200 Avg. Training loss: 1.5222 0.0035 sec/batch\n",
      "Epoch 6/10 Iteration: 324400 Avg. Training loss: 1.6147 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 324600 Avg. Training loss: 1.4146 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 324800 Avg. Training loss: 1.5604 0.0015 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 325000 Avg. Training loss: 1.6518 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 325200 Avg. Training loss: 1.5196 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 325400 Avg. Training loss: 1.5000 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 325600 Avg. Training loss: 1.5740 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 325800 Avg. Training loss: 1.4570 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 326000 Avg. Training loss: 1.5284 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 326200 Avg. Training loss: 1.5672 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 326400 Avg. Training loss: 1.5436 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 326600 Avg. Training loss: 1.5369 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 326800 Avg. Training loss: 1.5865 0.0020 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Iteration: 327000 Avg. Training loss: 1.6716 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 327200 Avg. Training loss: 1.6023 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 327400 Avg. Training loss: 1.4925 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 327600 Avg. Training loss: 1.5856 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 327800 Avg. Training loss: 1.6709 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 328000 Avg. Training loss: 1.5626 0.0015 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 328200 Avg. Training loss: 1.5440 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 328400 Avg. Training loss: 1.6172 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 328600 Avg. Training loss: 1.5707 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 328800 Avg. Training loss: 1.5361 0.0015 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 329000 Avg. Training loss: 1.5625 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 329200 Avg. Training loss: 1.6448 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 329400 Avg. Training loss: 1.5466 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 329600 Avg. Training loss: 1.6410 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 329800 Avg. Training loss: 1.5691 0.0015 sec/batch\n",
      "Epoch 6/10 Iteration: 330000 Avg. Training loss: 1.6504 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 330200 Avg. Training loss: 1.4802 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 330400 Avg. Training loss: 1.4335 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 330600 Avg. Training loss: 1.5193 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 330800 Avg. Training loss: 1.5286 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 331000 Avg. Training loss: 1.6115 0.0021 sec/batch\n",
      "Epoch 6/10 Iteration: 331200 Avg. Training loss: 1.6009 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 331400 Avg. Training loss: 1.6082 0.0020 sec/batch\n",
      "Epoch 6/10 Iteration: 331600 Avg. Training loss: 1.5810 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 331800 Avg. Training loss: 1.4486 0.0018 sec/batch\n",
      "Epoch 6/10 Iteration: 332000 Avg. Training loss: 1.7672 0.0019 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 332200 Avg. Training loss: 1.5780 0.0021 sec/batch\n",
      "Epoch 6/10 Iteration: 332400 Avg. Training loss: 1.6494 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 332600 Avg. Training loss: 1.5001 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 332800 Avg. Training loss: 1.6397 0.0018 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 333000 Avg. Training loss: 1.5698 0.0020 sec/batch\n",
      "Epoch 6/10 Iteration: 333200 Avg. Training loss: 1.5710 0.0020 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 333400 Avg. Training loss: 1.5308 0.0019 sec/batch\n",
      "Epoch 6/10 Iteration: 333600 Avg. Training loss: 1.5861 0.0021 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 333800 Avg. Training loss: 1.5009 0.0020 sec/batch\n",
      "Epoch 6/10 Iteration: 334000 Avg. Training loss: 1.5356 0.0017 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 334200 Avg. Training loss: 1.4867 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 334400 Avg. Training loss: 1.6454 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 334600 Avg. Training loss: 1.6628 0.0017 sec/batch\n",
      "Epoch 6/10 Iteration: 334800 Avg. Training loss: 1.4777 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 335000 Avg. Training loss: 1.4987 0.0016 sec/batch\n",
      "Epoch 6/10 Iteration: 335200 Avg. Training loss: 1.6005 0.0016 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 335400 Avg. Training loss: 1.5227 0.0015 sec/batch\n",
      "Epoch 6/10 Iteration: 335600 Avg. Training loss: 1.6226 0.0015 sec/batch\n",
      "error\n",
      "Epoch 6/10 Iteration: 335800 Avg. Training loss: 1.5393 0.0015 sec/batch\n",
      "Epoch 7/10 Iteration: 336000 Avg. Training loss: 1.6461 0.0012 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 336200 Avg. Training loss: 1.6235 0.0015 sec/batch\n",
      "Epoch 7/10 Iteration: 336400 Avg. Training loss: 1.5814 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 336600 Avg. Training loss: 1.5844 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 336800 Avg. Training loss: 1.6468 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 337000 Avg. Training loss: 1.3997 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 337200 Avg. Training loss: 1.6184 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 337400 Avg. Training loss: 1.6377 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 337600 Avg. Training loss: 1.6499 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 337800 Avg. Training loss: 1.7111 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 338000 Avg. Training loss: 1.4194 0.0015 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 338200 Avg. Training loss: 1.6505 0.0015 sec/batch\n",
      "Epoch 7/10 Iteration: 338400 Avg. Training loss: 1.5302 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 338600 Avg. Training loss: 1.7782 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 338800 Avg. Training loss: 1.5375 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 339000 Avg. Training loss: 1.5298 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 339200 Avg. Training loss: 1.4905 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 339400 Avg. Training loss: 1.4657 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 339600 Avg. Training loss: 1.4626 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 339800 Avg. Training loss: 1.5515 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 340000 Avg. Training loss: 1.6676 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 340200 Avg. Training loss: 1.5875 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 340400 Avg. Training loss: 1.6675 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 340600 Avg. Training loss: 1.4849 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 340800 Avg. Training loss: 1.5721 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 341000 Avg. Training loss: 1.3228 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 341200 Avg. Training loss: 1.5197 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 341400 Avg. Training loss: 1.5846 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 341600 Avg. Training loss: 1.5145 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 341800 Avg. Training loss: 1.4473 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 342000 Avg. Training loss: 1.5905 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 342200 Avg. Training loss: 1.5314 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 342400 Avg. Training loss: 1.6746 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 342600 Avg. Training loss: 1.6992 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 342800 Avg. Training loss: 1.5819 0.0020 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 343000 Avg. Training loss: 1.4094 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 343200 Avg. Training loss: 1.5567 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 343400 Avg. Training loss: 1.4829 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 343600 Avg. Training loss: 1.5090 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 343800 Avg. Training loss: 1.5137 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 344000 Avg. Training loss: 1.5703 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 344200 Avg. Training loss: 1.6181 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 344400 Avg. Training loss: 1.5224 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 344600 Avg. Training loss: 1.4581 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 344800 Avg. Training loss: 1.4973 0.0020 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 345000 Avg. Training loss: 1.4626 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 345200 Avg. Training loss: 1.6333 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 345400 Avg. Training loss: 1.5650 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 345600 Avg. Training loss: 1.7095 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 345800 Avg. Training loss: 1.6066 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 346000 Avg. Training loss: 1.6344 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 346200 Avg. Training loss: 1.7168 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 346400 Avg. Training loss: 1.4161 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 346600 Avg. Training loss: 1.6664 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 346800 Avg. Training loss: 1.4135 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 347000 Avg. Training loss: 1.6265 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 347200 Avg. Training loss: 1.4089 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 347400 Avg. Training loss: 1.5180 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 347600 Avg. Training loss: 1.5107 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 347800 Avg. Training loss: 1.4601 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 348000 Avg. Training loss: 1.5518 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 348200 Avg. Training loss: 1.6251 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 348400 Avg. Training loss: 1.8326 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 348600 Avg. Training loss: 1.4583 0.0017 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Iteration: 348800 Avg. Training loss: 1.5810 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 349000 Avg. Training loss: 1.4795 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 349200 Avg. Training loss: 1.7010 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 349400 Avg. Training loss: 1.6185 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 349600 Avg. Training loss: 1.5640 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 349800 Avg. Training loss: 1.5040 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 350000 Avg. Training loss: 1.4789 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 350200 Avg. Training loss: 1.5133 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 350400 Avg. Training loss: 1.5377 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 350600 Avg. Training loss: 1.4978 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 350800 Avg. Training loss: 1.5860 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 351000 Avg. Training loss: 1.5424 0.0021 sec/batch\n",
      "Epoch 7/10 Iteration: 351200 Avg. Training loss: 1.4322 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 351400 Avg. Training loss: 1.4944 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 351600 Avg. Training loss: 1.5505 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 351800 Avg. Training loss: 1.5119 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 352000 Avg. Training loss: 1.4657 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 352200 Avg. Training loss: 1.5519 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 352400 Avg. Training loss: 1.6936 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 352600 Avg. Training loss: 1.5846 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 352800 Avg. Training loss: 1.5041 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 353000 Avg. Training loss: 1.6428 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 353200 Avg. Training loss: 1.6052 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 353400 Avg. Training loss: 1.5847 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 353600 Avg. Training loss: 1.5407 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 353800 Avg. Training loss: 1.5418 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 354000 Avg. Training loss: 1.6834 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 354200 Avg. Training loss: 1.4286 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 354400 Avg. Training loss: 1.4625 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 354600 Avg. Training loss: 1.4543 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 354800 Avg. Training loss: 1.5861 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 355000 Avg. Training loss: 1.5757 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 355200 Avg. Training loss: 1.6583 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 355400 Avg. Training loss: 1.6937 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 355600 Avg. Training loss: 1.4985 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 355800 Avg. Training loss: 1.4308 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 356000 Avg. Training loss: 1.7144 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 356200 Avg. Training loss: 1.7170 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 356400 Avg. Training loss: 1.6302 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 356600 Avg. Training loss: 1.4959 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 356800 Avg. Training loss: 1.5510 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 357000 Avg. Training loss: 1.4274 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 357200 Avg. Training loss: 1.7048 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 357400 Avg. Training loss: 1.6473 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 357600 Avg. Training loss: 1.5392 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 357800 Avg. Training loss: 1.6172 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 358000 Avg. Training loss: 1.4973 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 358200 Avg. Training loss: 1.6716 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 358400 Avg. Training loss: 1.5940 0.0014 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 358600 Avg. Training loss: 1.4776 0.0014 sec/batch\n",
      "Epoch 7/10 Iteration: 358800 Avg. Training loss: 1.5898 0.0014 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 359000 Avg. Training loss: 1.5385 0.0015 sec/batch\n",
      "Epoch 7/10 Iteration: 359200 Avg. Training loss: 1.6172 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 359400 Avg. Training loss: 1.7911 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 359600 Avg. Training loss: 1.7014 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 359800 Avg. Training loss: 1.5705 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 360000 Avg. Training loss: 1.5324 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 360200 Avg. Training loss: 1.5576 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 360400 Avg. Training loss: 1.5074 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 360600 Avg. Training loss: 1.5761 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 360800 Avg. Training loss: 1.5826 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 361000 Avg. Training loss: 1.5775 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 361200 Avg. Training loss: 1.5184 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 361400 Avg. Training loss: 1.6035 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 361600 Avg. Training loss: 1.6673 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 361800 Avg. Training loss: 1.5620 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 362000 Avg. Training loss: 1.6394 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 362200 Avg. Training loss: 1.5381 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 362400 Avg. Training loss: 1.5690 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 362600 Avg. Training loss: 1.4478 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 362800 Avg. Training loss: 1.3953 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 363000 Avg. Training loss: 1.4696 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 363200 Avg. Training loss: 1.5607 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 363400 Avg. Training loss: 1.5445 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 363600 Avg. Training loss: 1.5925 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 363800 Avg. Training loss: 1.5463 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 364000 Avg. Training loss: 1.6449 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 364200 Avg. Training loss: 1.6368 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 364400 Avg. Training loss: 1.6904 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 364600 Avg. Training loss: 1.5968 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 364800 Avg. Training loss: 1.5023 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 365000 Avg. Training loss: 1.6894 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 365200 Avg. Training loss: 1.4664 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 365400 Avg. Training loss: 1.6245 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 365600 Avg. Training loss: 1.4879 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 365800 Avg. Training loss: 1.5699 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 366000 Avg. Training loss: 1.4294 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 366200 Avg. Training loss: 1.4593 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 366400 Avg. Training loss: 1.5974 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 366600 Avg. Training loss: 1.6034 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 366800 Avg. Training loss: 1.4498 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 367000 Avg. Training loss: 1.6578 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 367200 Avg. Training loss: 1.5212 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 367400 Avg. Training loss: 1.5422 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 367600 Avg. Training loss: 1.6827 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 367800 Avg. Training loss: 1.5188 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 368000 Avg. Training loss: 1.5641 0.0015 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 368200 Avg. Training loss: 1.6520 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 368400 Avg. Training loss: 1.5751 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 368600 Avg. Training loss: 1.6448 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 368800 Avg. Training loss: 1.5922 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 369000 Avg. Training loss: 1.6096 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 369200 Avg. Training loss: 1.4904 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 369400 Avg. Training loss: 1.6726 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 369600 Avg. Training loss: 1.4967 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 369800 Avg. Training loss: 1.6837 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 370000 Avg. Training loss: 1.5379 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 370200 Avg. Training loss: 1.5236 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 370400 Avg. Training loss: 1.5780 0.0017 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Iteration: 370600 Avg. Training loss: 1.4897 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 370800 Avg. Training loss: 1.6020 0.0020 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 371000 Avg. Training loss: 1.6796 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 371200 Avg. Training loss: 1.4244 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 371400 Avg. Training loss: 1.7454 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 371600 Avg. Training loss: 1.6084 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 371800 Avg. Training loss: 1.6604 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 372000 Avg. Training loss: 1.6676 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 372200 Avg. Training loss: 1.4930 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 372400 Avg. Training loss: 1.5942 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 372600 Avg. Training loss: 1.6258 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 372800 Avg. Training loss: 1.5736 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 373000 Avg. Training loss: 1.6990 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 373200 Avg. Training loss: 1.6711 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 373400 Avg. Training loss: 1.5113 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 373600 Avg. Training loss: 1.5634 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 373800 Avg. Training loss: 1.4832 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 374000 Avg. Training loss: 1.7489 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 374200 Avg. Training loss: 1.5137 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 374400 Avg. Training loss: 1.5696 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 374600 Avg. Training loss: 1.6217 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 374800 Avg. Training loss: 1.6234 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 375000 Avg. Training loss: 1.6000 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 375200 Avg. Training loss: 1.5611 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 375400 Avg. Training loss: 1.6054 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 375600 Avg. Training loss: 1.5322 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 375800 Avg. Training loss: 1.6525 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 376000 Avg. Training loss: 1.6311 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 376200 Avg. Training loss: 1.5918 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 376400 Avg. Training loss: 1.5266 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 376600 Avg. Training loss: 1.4447 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 376800 Avg. Training loss: 1.6238 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 377000 Avg. Training loss: 1.6171 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 377200 Avg. Training loss: 1.5104 0.0020 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 377400 Avg. Training loss: 1.6777 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 377600 Avg. Training loss: 1.5689 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 377800 Avg. Training loss: 1.6419 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 378000 Avg. Training loss: 1.6330 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 378200 Avg. Training loss: 1.5557 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 378400 Avg. Training loss: 1.4748 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 378600 Avg. Training loss: 1.8298 0.0015 sec/batch\n",
      "Epoch 7/10 Iteration: 378800 Avg. Training loss: 1.6479 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 379000 Avg. Training loss: 1.5009 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 379200 Avg. Training loss: 1.4413 0.0015 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 379400 Avg. Training loss: 1.7182 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 379600 Avg. Training loss: 1.5682 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 379800 Avg. Training loss: 1.6113 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 380000 Avg. Training loss: 1.5662 0.0015 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 380200 Avg. Training loss: 1.4824 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 380400 Avg. Training loss: 1.6543 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 380600 Avg. Training loss: 1.5435 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 380800 Avg. Training loss: 1.5726 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 381000 Avg. Training loss: 1.5735 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 381200 Avg. Training loss: 1.6170 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 381400 Avg. Training loss: 1.5797 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 381600 Avg. Training loss: 1.4865 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 381800 Avg. Training loss: 1.5761 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 382000 Avg. Training loss: 1.5340 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 382200 Avg. Training loss: 1.5926 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 382400 Avg. Training loss: 1.6307 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 382600 Avg. Training loss: 1.6853 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 382800 Avg. Training loss: 1.5996 0.0015 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 383000 Avg. Training loss: 1.5678 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 383200 Avg. Training loss: 1.6035 0.0015 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 383400 Avg. Training loss: 1.4664 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 383600 Avg. Training loss: 1.5813 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 383800 Avg. Training loss: 1.6193 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 384000 Avg. Training loss: 1.3943 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 384200 Avg. Training loss: 1.5525 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 384400 Avg. Training loss: 1.5610 0.0015 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 384600 Avg. Training loss: 1.6719 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 384800 Avg. Training loss: 1.6573 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 385000 Avg. Training loss: 1.5180 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 385200 Avg. Training loss: 1.6434 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 385400 Avg. Training loss: 1.5236 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 385600 Avg. Training loss: 1.6149 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 385800 Avg. Training loss: 1.5612 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 386000 Avg. Training loss: 1.5079 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 386200 Avg. Training loss: 1.5107 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 386400 Avg. Training loss: 1.5438 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 386600 Avg. Training loss: 1.6348 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 386800 Avg. Training loss: 1.5516 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 387000 Avg. Training loss: 1.4680 0.0021 sec/batch\n",
      "Epoch 7/10 Iteration: 387200 Avg. Training loss: 1.6053 0.0018 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 387400 Avg. Training loss: 1.5243 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 387600 Avg. Training loss: 1.5517 0.0019 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 387800 Avg. Training loss: 1.4742 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 388000 Avg. Training loss: 1.6199 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 388200 Avg. Training loss: 1.7094 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 388400 Avg. Training loss: 1.6012 0.0020 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 388600 Avg. Training loss: 1.4928 0.0019 sec/batch\n",
      "Epoch 7/10 Iteration: 388800 Avg. Training loss: 1.5296 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 389000 Avg. Training loss: 1.5702 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 389200 Avg. Training loss: 1.5822 0.0015 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 389400 Avg. Training loss: 1.4502 0.0017 sec/batch\n",
      "Epoch 7/10 Iteration: 389600 Avg. Training loss: 1.5668 0.0020 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 389800 Avg. Training loss: 1.5478 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 390000 Avg. Training loss: 1.5293 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 390200 Avg. Training loss: 1.5700 0.0020 sec/batch\n",
      "Epoch 7/10 Iteration: 390400 Avg. Training loss: 1.5677 0.0016 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 390600 Avg. Training loss: 1.7812 0.0015 sec/batch\n",
      "Epoch 7/10 Iteration: 390800 Avg. Training loss: 1.6393 0.0017 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 391000 Avg. Training loss: 1.6393 0.0016 sec/batch\n",
      "Epoch 7/10 Iteration: 391200 Avg. Training loss: 1.5755 0.0015 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 391400 Avg. Training loss: 1.4876 0.0018 sec/batch\n",
      "Epoch 7/10 Iteration: 391600 Avg. Training loss: 1.6044 0.0014 sec/batch\n",
      "error\n",
      "Epoch 7/10 Iteration: 391800 Avg. Training loss: 1.5163 0.0015 sec/batch\n",
      "Epoch 8/10 Iteration: 392000 Avg. Training loss: 1.5547 0.0015 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 Iteration: 392200 Avg. Training loss: 1.4587 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 392400 Avg. Training loss: 1.6484 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 392600 Avg. Training loss: 1.6285 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 392800 Avg. Training loss: 1.7010 0.0015 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 393000 Avg. Training loss: 1.5943 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 393200 Avg. Training loss: 1.5845 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 393400 Avg. Training loss: 1.5857 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 393600 Avg. Training loss: 1.5869 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 393800 Avg. Training loss: 1.5652 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 394000 Avg. Training loss: 1.4713 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 394200 Avg. Training loss: 1.4692 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 394400 Avg. Training loss: 1.6319 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 394600 Avg. Training loss: 1.6626 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 394800 Avg. Training loss: 1.5995 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 395000 Avg. Training loss: 1.5818 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 395200 Avg. Training loss: 1.6387 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 395400 Avg. Training loss: 1.6315 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 395600 Avg. Training loss: 1.6442 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 395800 Avg. Training loss: 1.6194 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 396000 Avg. Training loss: 1.6537 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 396200 Avg. Training loss: 1.4795 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 396400 Avg. Training loss: 1.6242 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 396600 Avg. Training loss: 1.5714 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 396800 Avg. Training loss: 1.5473 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 397000 Avg. Training loss: 1.3982 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 397200 Avg. Training loss: 1.5300 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 397400 Avg. Training loss: 1.4773 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 397600 Avg. Training loss: 1.5227 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 397800 Avg. Training loss: 1.5318 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 398000 Avg. Training loss: 1.3512 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 398200 Avg. Training loss: 1.5930 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 398400 Avg. Training loss: 1.6252 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 398600 Avg. Training loss: 1.5750 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 398800 Avg. Training loss: 1.5550 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 399000 Avg. Training loss: 1.6081 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 399200 Avg. Training loss: 1.4988 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 399400 Avg. Training loss: 1.5667 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 399600 Avg. Training loss: 1.4973 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 399800 Avg. Training loss: 1.6569 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 400000 Avg. Training loss: 1.5525 0.0020 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 400200 Avg. Training loss: 1.3422 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 400400 Avg. Training loss: 1.4996 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 400600 Avg. Training loss: 1.5245 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 400800 Avg. Training loss: 1.5906 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 401000 Avg. Training loss: 1.4196 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 401200 Avg. Training loss: 1.7157 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 401400 Avg. Training loss: 1.6241 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 401600 Avg. Training loss: 1.6373 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 401800 Avg. Training loss: 1.5996 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 402000 Avg. Training loss: 1.5864 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 402200 Avg. Training loss: 1.5760 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 402400 Avg. Training loss: 1.4160 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 402600 Avg. Training loss: 1.6849 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 402800 Avg. Training loss: 1.4946 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 403000 Avg. Training loss: 1.5819 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 403200 Avg. Training loss: 1.4768 0.0020 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 403400 Avg. Training loss: 1.6065 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 403600 Avg. Training loss: 1.5508 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 403800 Avg. Training loss: 1.5132 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 404000 Avg. Training loss: 1.5748 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 404200 Avg. Training loss: 1.5702 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 404400 Avg. Training loss: 1.7703 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 404600 Avg. Training loss: 1.5218 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 404800 Avg. Training loss: 1.6318 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 405000 Avg. Training loss: 1.4343 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 405200 Avg. Training loss: 1.6142 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 405400 Avg. Training loss: 1.6436 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 405600 Avg. Training loss: 1.5157 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 405800 Avg. Training loss: 1.5436 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 406000 Avg. Training loss: 1.5959 0.0020 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 406200 Avg. Training loss: 1.5060 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 406400 Avg. Training loss: 1.5870 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 406600 Avg. Training loss: 1.5184 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 406800 Avg. Training loss: 1.5142 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 407000 Avg. Training loss: 1.5543 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 407200 Avg. Training loss: 1.5676 0.0015 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 407400 Avg. Training loss: 1.6850 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 407600 Avg. Training loss: 1.4964 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 407800 Avg. Training loss: 1.6055 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 408000 Avg. Training loss: 1.5510 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 408200 Avg. Training loss: 1.5472 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 408400 Avg. Training loss: 1.6392 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 408600 Avg. Training loss: 1.6010 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 408800 Avg. Training loss: 1.4666 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 409000 Avg. Training loss: 1.4733 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 409200 Avg. Training loss: 1.5913 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 409400 Avg. Training loss: 1.5187 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 409600 Avg. Training loss: 1.6002 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 409800 Avg. Training loss: 1.5600 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 410000 Avg. Training loss: 1.6289 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 410200 Avg. Training loss: 1.5492 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 410400 Avg. Training loss: 1.6239 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 410600 Avg. Training loss: 1.4388 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 410800 Avg. Training loss: 1.6212 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 411000 Avg. Training loss: 1.4800 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 411200 Avg. Training loss: 1.5856 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 411400 Avg. Training loss: 1.7626 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 411600 Avg. Training loss: 1.4572 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 411800 Avg. Training loss: 1.6690 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 412000 Avg. Training loss: 1.5398 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 412200 Avg. Training loss: 1.6653 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 412400 Avg. Training loss: 1.5105 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 412600 Avg. Training loss: 1.6930 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 412800 Avg. Training loss: 1.5318 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 413000 Avg. Training loss: 1.4693 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 413200 Avg. Training loss: 1.6390 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 413400 Avg. Training loss: 1.6048 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 413600 Avg. Training loss: 1.6529 0.0015 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 Iteration: 413800 Avg. Training loss: 1.6597 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 414000 Avg. Training loss: 1.6518 0.0014 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 414200 Avg. Training loss: 1.6495 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 414400 Avg. Training loss: 1.5102 0.0015 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 414600 Avg. Training loss: 1.6094 0.0015 sec/batch\n",
      "Epoch 8/10 Iteration: 414800 Avg. Training loss: 1.4722 0.0015 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 415000 Avg. Training loss: 1.5468 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 415200 Avg. Training loss: 1.6084 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 415400 Avg. Training loss: 1.5915 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 415600 Avg. Training loss: 1.5696 0.0015 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 415800 Avg. Training loss: 1.7500 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 416000 Avg. Training loss: 1.3704 0.0015 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 416200 Avg. Training loss: 1.4826 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 416400 Avg. Training loss: 1.5748 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 416600 Avg. Training loss: 1.6521 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 416800 Avg. Training loss: 1.5407 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 417000 Avg. Training loss: 1.4889 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 417200 Avg. Training loss: 1.6359 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 417400 Avg. Training loss: 1.6173 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 417600 Avg. Training loss: 1.5722 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 417800 Avg. Training loss: 1.4924 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 418000 Avg. Training loss: 1.4184 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 418200 Avg. Training loss: 1.4451 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 418400 Avg. Training loss: 1.4518 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 418600 Avg. Training loss: 1.5356 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 418800 Avg. Training loss: 1.5418 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 419000 Avg. Training loss: 1.5540 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 419200 Avg. Training loss: 1.6096 0.0015 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 419400 Avg. Training loss: 1.6116 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 419600 Avg. Training loss: 1.6824 0.0015 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 419800 Avg. Training loss: 1.4599 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 420000 Avg. Training loss: 1.6804 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 420200 Avg. Training loss: 1.6765 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 420400 Avg. Training loss: 1.5567 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 420600 Avg. Training loss: 1.7349 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 420800 Avg. Training loss: 1.4802 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 421000 Avg. Training loss: 1.5620 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 421200 Avg. Training loss: 1.6866 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 421400 Avg. Training loss: 1.4861 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 421600 Avg. Training loss: 1.4835 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 421800 Avg. Training loss: 1.5581 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 422000 Avg. Training loss: 1.4131 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 422200 Avg. Training loss: 1.5355 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 422400 Avg. Training loss: 1.6972 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 422600 Avg. Training loss: 1.5860 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 422800 Avg. Training loss: 1.4741 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 423000 Avg. Training loss: 1.7178 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 423200 Avg. Training loss: 1.4713 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 423400 Avg. Training loss: 1.4846 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 423600 Avg. Training loss: 1.5757 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 423800 Avg. Training loss: 1.5152 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 424000 Avg. Training loss: 1.6236 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 424200 Avg. Training loss: 1.5875 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 424400 Avg. Training loss: 1.6895 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 424600 Avg. Training loss: 1.6186 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 424800 Avg. Training loss: 1.5881 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 425000 Avg. Training loss: 1.5072 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 425200 Avg. Training loss: 1.3699 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 425400 Avg. Training loss: 1.6623 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 425600 Avg. Training loss: 1.5870 0.0020 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 425800 Avg. Training loss: 1.4509 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 426000 Avg. Training loss: 1.5583 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 426200 Avg. Training loss: 1.5679 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 426400 Avg. Training loss: 1.5679 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 426600 Avg. Training loss: 1.4185 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 426800 Avg. Training loss: 1.6698 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 427000 Avg. Training loss: 1.6464 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 427200 Avg. Training loss: 1.4490 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 427400 Avg. Training loss: 1.6683 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 427600 Avg. Training loss: 1.5889 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 427800 Avg. Training loss: 1.5674 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 428000 Avg. Training loss: 1.5421 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 428200 Avg. Training loss: 1.6918 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 428400 Avg. Training loss: 1.6781 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 428600 Avg. Training loss: 1.4777 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 428800 Avg. Training loss: 1.6137 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 429000 Avg. Training loss: 1.5121 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 429200 Avg. Training loss: 1.5766 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 429400 Avg. Training loss: 1.5487 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 429600 Avg. Training loss: 1.5880 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 429800 Avg. Training loss: 1.5200 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 430000 Avg. Training loss: 1.6323 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 430200 Avg. Training loss: 1.6242 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 430400 Avg. Training loss: 1.5760 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 430600 Avg. Training loss: 1.5963 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 430800 Avg. Training loss: 1.6726 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 431000 Avg. Training loss: 1.6240 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 431200 Avg. Training loss: 1.5428 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 431400 Avg. Training loss: 1.5050 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 431600 Avg. Training loss: 1.5219 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 431800 Avg. Training loss: 1.6170 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 432000 Avg. Training loss: 1.4970 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 432200 Avg. Training loss: 1.5365 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 432400 Avg. Training loss: 1.6173 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 432600 Avg. Training loss: 1.5301 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 432800 Avg. Training loss: 1.5513 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 433000 Avg. Training loss: 1.6787 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 433200 Avg. Training loss: 1.4799 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 433400 Avg. Training loss: 1.6202 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 433600 Avg. Training loss: 1.6740 0.0015 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 433800 Avg. Training loss: 1.7022 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 434000 Avg. Training loss: 1.6078 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 434200 Avg. Training loss: 1.5457 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 434400 Avg. Training loss: 1.5125 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 434600 Avg. Training loss: 1.6251 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 434800 Avg. Training loss: 1.6169 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 435000 Avg. Training loss: 1.5046 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 435200 Avg. Training loss: 1.5530 0.0018 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 Iteration: 435400 Avg. Training loss: 1.7463 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 435600 Avg. Training loss: 1.5613 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 435800 Avg. Training loss: 1.5367 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 436000 Avg. Training loss: 1.5170 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 436200 Avg. Training loss: 1.5442 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 436400 Avg. Training loss: 1.6739 0.0020 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 436600 Avg. Training loss: 1.4860 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 436800 Avg. Training loss: 1.4809 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 437000 Avg. Training loss: 1.6014 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 437200 Avg. Training loss: 1.5453 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 437400 Avg. Training loss: 1.5013 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 437600 Avg. Training loss: 1.5264 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 437800 Avg. Training loss: 1.5050 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 438000 Avg. Training loss: 1.5625 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 438200 Avg. Training loss: 1.5834 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 438400 Avg. Training loss: 1.6020 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 438600 Avg. Training loss: 1.5744 0.0016 sec/batch\n",
      "Epoch 8/10 Iteration: 438800 Avg. Training loss: 1.6083 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 439000 Avg. Training loss: 1.4567 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 439200 Avg. Training loss: 1.7278 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 439400 Avg. Training loss: 1.4435 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 439600 Avg. Training loss: 1.5840 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 439800 Avg. Training loss: 1.4971 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 440000 Avg. Training loss: 1.4551 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 440200 Avg. Training loss: 1.6900 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 440400 Avg. Training loss: 1.4953 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 440600 Avg. Training loss: 1.7037 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 440800 Avg. Training loss: 1.5257 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 441000 Avg. Training loss: 1.5484 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 441200 Avg. Training loss: 1.4894 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 441400 Avg. Training loss: 1.6683 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 441600 Avg. Training loss: 1.4792 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 441800 Avg. Training loss: 1.4859 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 442000 Avg. Training loss: 1.5742 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 442200 Avg. Training loss: 1.4926 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 442400 Avg. Training loss: 1.5568 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 442600 Avg. Training loss: 1.6039 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 442800 Avg. Training loss: 1.4338 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 443000 Avg. Training loss: 1.4800 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 443200 Avg. Training loss: 1.5903 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 443400 Avg. Training loss: 1.7034 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 443600 Avg. Training loss: 1.5733 0.0015 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 443800 Avg. Training loss: 1.5577 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 444000 Avg. Training loss: 1.5592 0.0019 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 444200 Avg. Training loss: 1.7748 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 444400 Avg. Training loss: 1.5447 0.0016 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 444600 Avg. Training loss: 1.5874 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 444800 Avg. Training loss: 1.5984 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 445000 Avg. Training loss: 1.4820 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 445200 Avg. Training loss: 1.5709 0.0020 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 445400 Avg. Training loss: 1.4810 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 445600 Avg. Training loss: 1.4150 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 445800 Avg. Training loss: 1.5343 0.0017 sec/batch\n",
      "Epoch 8/10 Iteration: 446000 Avg. Training loss: 1.5283 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 446200 Avg. Training loss: 1.5647 0.0018 sec/batch\n",
      "Epoch 8/10 Iteration: 446400 Avg. Training loss: 1.7051 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 446600 Avg. Training loss: 1.5577 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 446800 Avg. Training loss: 1.4907 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 447000 Avg. Training loss: 1.5331 0.0020 sec/batch\n",
      "Epoch 8/10 Iteration: 447200 Avg. Training loss: 1.5630 0.0018 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 447400 Avg. Training loss: 1.5598 0.0019 sec/batch\n",
      "Epoch 8/10 Iteration: 447600 Avg. Training loss: 1.6172 0.0017 sec/batch\n",
      "error\n",
      "Epoch 8/10 Iteration: 447800 Avg. Training loss: 1.6843 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 448000 Avg. Training loss: 1.5322 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 448200 Avg. Training loss: 1.5419 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 448400 Avg. Training loss: 1.5635 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 448600 Avg. Training loss: 1.5664 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 448800 Avg. Training loss: 1.6342 0.0019 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 449000 Avg. Training loss: 1.6727 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 449200 Avg. Training loss: 1.6246 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 449400 Avg. Training loss: 1.5176 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 449600 Avg. Training loss: 1.5504 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 449800 Avg. Training loss: 1.4603 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 450000 Avg. Training loss: 1.5003 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 450200 Avg. Training loss: 1.5286 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 450400 Avg. Training loss: 1.5656 0.0020 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 450600 Avg. Training loss: 1.7281 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 450800 Avg. Training loss: 1.5941 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 451000 Avg. Training loss: 1.6034 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 451200 Avg. Training loss: 1.6180 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 451400 Avg. Training loss: 1.5214 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 451600 Avg. Training loss: 1.6031 0.0020 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 451800 Avg. Training loss: 1.6294 0.0021 sec/batch\n",
      "Epoch 9/10 Iteration: 452000 Avg. Training loss: 1.5893 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 452200 Avg. Training loss: 1.5315 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 452400 Avg. Training loss: 1.5569 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 452600 Avg. Training loss: 1.6564 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 452800 Avg. Training loss: 1.4819 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 453000 Avg. Training loss: 1.4634 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 453200 Avg. Training loss: 1.5333 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 453400 Avg. Training loss: 1.4795 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 453600 Avg. Training loss: 1.4533 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 453800 Avg. Training loss: 1.5679 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 454000 Avg. Training loss: 1.5535 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 454200 Avg. Training loss: 1.7232 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 454400 Avg. Training loss: 1.5320 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 454600 Avg. Training loss: 1.5363 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 454800 Avg. Training loss: 1.4370 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 455000 Avg. Training loss: 1.6083 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 455200 Avg. Training loss: 1.6173 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 455400 Avg. Training loss: 1.5444 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 455600 Avg. Training loss: 1.5128 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 455800 Avg. Training loss: 1.6530 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 456000 Avg. Training loss: 1.4632 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 456200 Avg. Training loss: 1.6880 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 456400 Avg. Training loss: 1.4706 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 456600 Avg. Training loss: 1.4444 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 456800 Avg. Training loss: 1.5545 0.0019 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 Iteration: 457000 Avg. Training loss: 1.4948 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 457200 Avg. Training loss: 1.5628 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 457400 Avg. Training loss: 1.6430 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 457600 Avg. Training loss: 1.5616 0.0019 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 457800 Avg. Training loss: 1.4950 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 458000 Avg. Training loss: 1.6561 0.0020 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 458200 Avg. Training loss: 1.7708 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 458400 Avg. Training loss: 1.5844 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 458600 Avg. Training loss: 1.6029 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 458800 Avg. Training loss: 1.5326 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 459000 Avg. Training loss: 1.5040 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 459200 Avg. Training loss: 1.5232 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 459400 Avg. Training loss: 1.5262 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 459600 Avg. Training loss: 1.5660 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 459800 Avg. Training loss: 1.5468 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 460000 Avg. Training loss: 1.5092 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 460200 Avg. Training loss: 1.5498 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 460400 Avg. Training loss: 1.6161 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 460600 Avg. Training loss: 1.5926 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 460800 Avg. Training loss: 1.6130 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 461000 Avg. Training loss: 1.6297 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 461200 Avg. Training loss: 1.7065 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 461400 Avg. Training loss: 1.6422 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 461600 Avg. Training loss: 1.6202 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 461800 Avg. Training loss: 1.3683 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 462000 Avg. Training loss: 1.4519 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 462200 Avg. Training loss: 1.5364 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 462400 Avg. Training loss: 1.6258 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 462600 Avg. Training loss: 1.4994 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 462800 Avg. Training loss: 1.5719 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 463000 Avg. Training loss: 1.6173 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 463200 Avg. Training loss: 1.5064 0.0019 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 463400 Avg. Training loss: 1.5916 0.0021 sec/batch\n",
      "Epoch 9/10 Iteration: 463600 Avg. Training loss: 1.5169 0.0020 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 463800 Avg. Training loss: 1.6501 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 464000 Avg. Training loss: 1.4555 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 464200 Avg. Training loss: 1.5846 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 464400 Avg. Training loss: 1.5651 0.0019 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 464600 Avg. Training loss: 1.5823 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 464800 Avg. Training loss: 1.5012 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 465000 Avg. Training loss: 1.6217 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 465200 Avg. Training loss: 1.4821 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 465400 Avg. Training loss: 1.4629 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 465600 Avg. Training loss: 1.6027 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 465800 Avg. Training loss: 1.4717 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 466000 Avg. Training loss: 1.5625 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 466200 Avg. Training loss: 1.5217 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 466400 Avg. Training loss: 1.4133 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 466600 Avg. Training loss: 1.5396 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 466800 Avg. Training loss: 1.6807 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 467000 Avg. Training loss: 1.7070 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 467200 Avg. Training loss: 1.6116 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 467400 Avg. Training loss: 1.7064 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 467600 Avg. Training loss: 1.5278 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 467800 Avg. Training loss: 1.5661 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 468000 Avg. Training loss: 1.6035 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 468200 Avg. Training loss: 1.5685 0.0021 sec/batch\n",
      "Epoch 9/10 Iteration: 468400 Avg. Training loss: 1.4675 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 468600 Avg. Training loss: 1.5084 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 468800 Avg. Training loss: 1.7098 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 469000 Avg. Training loss: 1.5724 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 469200 Avg. Training loss: 1.5668 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 469400 Avg. Training loss: 1.4951 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 469600 Avg. Training loss: 1.6384 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 469800 Avg. Training loss: 1.5032 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 470000 Avg. Training loss: 1.5569 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 470200 Avg. Training loss: 1.4902 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 470400 Avg. Training loss: 1.4525 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 470600 Avg. Training loss: 1.5697 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 470800 Avg. Training loss: 1.5706 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 471000 Avg. Training loss: 1.4852 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 471200 Avg. Training loss: 1.7260 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 471400 Avg. Training loss: 1.7383 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 471600 Avg. Training loss: 1.5480 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 471800 Avg. Training loss: 1.6340 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 472000 Avg. Training loss: 1.6130 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 472200 Avg. Training loss: 1.5806 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 472400 Avg. Training loss: 1.5134 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 472600 Avg. Training loss: 1.6540 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 472800 Avg. Training loss: 1.4863 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 473000 Avg. Training loss: 1.5557 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 473200 Avg. Training loss: 1.6088 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 473400 Avg. Training loss: 1.6099 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 473600 Avg. Training loss: 1.5069 0.0019 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 473800 Avg. Training loss: 1.4764 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 474000 Avg. Training loss: 1.5169 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 474200 Avg. Training loss: 1.4437 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 474400 Avg. Training loss: 1.4996 0.0019 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 474600 Avg. Training loss: 1.5084 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 474800 Avg. Training loss: 1.3897 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 475000 Avg. Training loss: 1.5636 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 475200 Avg. Training loss: 1.7090 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 475400 Avg. Training loss: 1.3634 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 475600 Avg. Training loss: 1.5453 0.0019 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 475800 Avg. Training loss: 1.6561 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 476000 Avg. Training loss: 1.6041 0.0019 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 476200 Avg. Training loss: 1.5874 0.0021 sec/batch\n",
      "Epoch 9/10 Iteration: 476400 Avg. Training loss: 1.5657 0.0020 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 476600 Avg. Training loss: 1.5901 0.0021 sec/batch\n",
      "Epoch 9/10 Iteration: 476800 Avg. Training loss: 1.4578 0.0020 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 477000 Avg. Training loss: 1.4992 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 477200 Avg. Training loss: 1.6691 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 477400 Avg. Training loss: 1.4576 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 477600 Avg. Training loss: 1.5030 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 477800 Avg. Training loss: 1.6341 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 478000 Avg. Training loss: 1.5253 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 478200 Avg. Training loss: 1.5487 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 478400 Avg. Training loss: 1.6273 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 478600 Avg. Training loss: 1.5016 0.0016 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 Iteration: 478800 Avg. Training loss: 1.6408 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 479000 Avg. Training loss: 1.6997 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 479200 Avg. Training loss: 1.4442 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 479400 Avg. Training loss: 1.6239 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 479600 Avg. Training loss: 1.5928 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 479800 Avg. Training loss: 1.4063 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 480000 Avg. Training loss: 1.8044 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 480200 Avg. Training loss: 1.5279 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 480400 Avg. Training loss: 1.4714 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 480600 Avg. Training loss: 1.5974 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 480800 Avg. Training loss: 1.5317 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 481000 Avg. Training loss: 1.4949 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 481200 Avg. Training loss: 1.5089 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 481400 Avg. Training loss: 1.5978 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 481600 Avg. Training loss: 1.6002 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 481800 Avg. Training loss: 1.5354 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 482000 Avg. Training loss: 1.5956 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 482200 Avg. Training loss: 1.6547 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 482400 Avg. Training loss: 1.4251 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 482600 Avg. Training loss: 1.4600 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 482800 Avg. Training loss: 1.5056 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 483000 Avg. Training loss: 1.6481 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 483200 Avg. Training loss: 1.5925 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 483400 Avg. Training loss: 1.5431 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 483600 Avg. Training loss: 1.5413 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 483800 Avg. Training loss: 1.5568 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 484000 Avg. Training loss: 1.5140 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 484200 Avg. Training loss: 1.6054 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 484400 Avg. Training loss: 1.7744 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 484600 Avg. Training loss: 1.5912 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 484800 Avg. Training loss: 1.5675 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 485000 Avg. Training loss: 1.6213 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 485200 Avg. Training loss: 1.8040 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 485400 Avg. Training loss: 1.5564 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 485600 Avg. Training loss: 1.6460 0.0019 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 485800 Avg. Training loss: 1.7933 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 486000 Avg. Training loss: 1.4585 0.0020 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 486200 Avg. Training loss: 1.6222 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 486400 Avg. Training loss: 1.5518 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 486600 Avg. Training loss: 1.5266 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 486800 Avg. Training loss: 1.6823 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 487000 Avg. Training loss: 1.5725 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 487200 Avg. Training loss: 1.4781 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 487400 Avg. Training loss: 1.4651 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 487600 Avg. Training loss: 1.5694 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 487800 Avg. Training loss: 1.6252 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 488000 Avg. Training loss: 1.5827 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 488200 Avg. Training loss: 1.5205 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 488400 Avg. Training loss: 1.6175 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 488600 Avg. Training loss: 1.5829 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 488800 Avg. Training loss: 1.5845 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 489000 Avg. Training loss: 1.6308 0.0014 sec/batch\n",
      "Epoch 9/10 Iteration: 489200 Avg. Training loss: 1.4585 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 489400 Avg. Training loss: 1.6225 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 489600 Avg. Training loss: 1.6056 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 489800 Avg. Training loss: 1.5252 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 490000 Avg. Training loss: 1.5058 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 490200 Avg. Training loss: 1.5350 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 490400 Avg. Training loss: 1.5149 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 490600 Avg. Training loss: 1.5279 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 490800 Avg. Training loss: 1.5518 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 491000 Avg. Training loss: 1.5097 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 491200 Avg. Training loss: 1.6604 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 491400 Avg. Training loss: 1.6170 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 491600 Avg. Training loss: 1.5324 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 491800 Avg. Training loss: 1.5652 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 492000 Avg. Training loss: 1.4630 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 492200 Avg. Training loss: 1.6234 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 492400 Avg. Training loss: 1.5147 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 492600 Avg. Training loss: 1.6430 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 492800 Avg. Training loss: 1.5536 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 493000 Avg. Training loss: 1.6237 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 493200 Avg. Training loss: 1.5912 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 493400 Avg. Training loss: 1.5760 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 493600 Avg. Training loss: 1.5301 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 493800 Avg. Training loss: 1.4679 0.0015 sec/batch\n",
      "Epoch 9/10 Iteration: 494000 Avg. Training loss: 1.6781 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 494200 Avg. Training loss: 1.6954 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 494400 Avg. Training loss: 1.6063 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 494600 Avg. Training loss: 1.4893 0.0015 sec/batch\n",
      "Epoch 9/10 Iteration: 494800 Avg. Training loss: 1.6267 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 495000 Avg. Training loss: 1.6274 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 495200 Avg. Training loss: 1.5930 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 495400 Avg. Training loss: 1.4139 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 495600 Avg. Training loss: 1.5817 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 495800 Avg. Training loss: 1.7186 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 496000 Avg. Training loss: 1.4399 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 496200 Avg. Training loss: 1.7569 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 496400 Avg. Training loss: 1.6142 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 496600 Avg. Training loss: 1.7137 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 496800 Avg. Training loss: 1.4947 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 497000 Avg. Training loss: 1.5946 0.0019 sec/batch\n",
      "Epoch 9/10 Iteration: 497200 Avg. Training loss: 1.5835 0.0019 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 497400 Avg. Training loss: 1.5100 0.0020 sec/batch\n",
      "Epoch 9/10 Iteration: 497600 Avg. Training loss: 1.4713 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 497800 Avg. Training loss: 1.5885 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 498000 Avg. Training loss: 1.6085 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 498200 Avg. Training loss: 1.4762 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 498400 Avg. Training loss: 1.5683 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 498600 Avg. Training loss: 1.5296 0.0021 sec/batch\n",
      "Epoch 9/10 Iteration: 498800 Avg. Training loss: 1.3520 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 499000 Avg. Training loss: 1.5377 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 499200 Avg. Training loss: 1.5003 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 499400 Avg. Training loss: 1.6572 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 499600 Avg. Training loss: 1.5008 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 499800 Avg. Training loss: 1.6486 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 500000 Avg. Training loss: 1.5268 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 500200 Avg. Training loss: 1.6559 0.0017 sec/batch\n",
      "Epoch 9/10 Iteration: 500400 Avg. Training loss: 1.4319 0.0017 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 Iteration: 500600 Avg. Training loss: 1.5709 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 500800 Avg. Training loss: 1.4161 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 501000 Avg. Training loss: 1.4496 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 501200 Avg. Training loss: 1.5277 0.0017 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 501400 Avg. Training loss: 1.4681 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 501600 Avg. Training loss: 1.4297 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 501800 Avg. Training loss: 1.6201 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 502000 Avg. Training loss: 1.5452 0.0016 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 502200 Avg. Training loss: 1.5926 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 502400 Avg. Training loss: 1.5292 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 502600 Avg. Training loss: 1.5346 0.0016 sec/batch\n",
      "Epoch 9/10 Iteration: 502800 Avg. Training loss: 1.5698 0.0015 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 503000 Avg. Training loss: 1.4444 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 503200 Avg. Training loss: 1.5504 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/10 Iteration: 503400 Avg. Training loss: 1.5995 0.0018 sec/batch\n",
      "Epoch 9/10 Iteration: 503600 Avg. Training loss: 1.6340 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 503800 Avg. Training loss: 1.6718 0.0001 sec/batch\n",
      "Epoch 10/10 Iteration: 504000 Avg. Training loss: 1.5241 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 504200 Avg. Training loss: 1.5546 0.0015 sec/batch\n",
      "Epoch 10/10 Iteration: 504400 Avg. Training loss: 1.5941 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 504600 Avg. Training loss: 1.5179 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 504800 Avg. Training loss: 1.5882 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 505000 Avg. Training loss: 1.6197 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 505200 Avg. Training loss: 1.5474 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 505400 Avg. Training loss: 1.6247 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 505600 Avg. Training loss: 1.6852 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 505800 Avg. Training loss: 1.4797 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 506000 Avg. Training loss: 1.5597 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 506200 Avg. Training loss: 1.6516 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 506400 Avg. Training loss: 1.4576 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 506600 Avg. Training loss: 1.7022 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 506800 Avg. Training loss: 1.5939 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 507000 Avg. Training loss: 1.5529 0.0020 sec/batch\n",
      "Epoch 10/10 Iteration: 507200 Avg. Training loss: 1.5378 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 507400 Avg. Training loss: 1.4462 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 507600 Avg. Training loss: 1.5903 0.0020 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 507800 Avg. Training loss: 1.5486 0.0020 sec/batch\n",
      "Epoch 10/10 Iteration: 508000 Avg. Training loss: 1.6107 0.0020 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 508200 Avg. Training loss: 1.5549 0.0022 sec/batch\n",
      "Epoch 10/10 Iteration: 508400 Avg. Training loss: 1.6262 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 508600 Avg. Training loss: 1.5131 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 508800 Avg. Training loss: 1.4564 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 509000 Avg. Training loss: 1.4797 0.0020 sec/batch\n",
      "Epoch 10/10 Iteration: 509200 Avg. Training loss: 1.4938 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 509400 Avg. Training loss: 1.4997 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 509600 Avg. Training loss: 1.5321 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 509800 Avg. Training loss: 1.5705 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 510000 Avg. Training loss: 1.5444 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 510200 Avg. Training loss: 1.6450 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 510400 Avg. Training loss: 1.6073 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 510600 Avg. Training loss: 1.6489 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 510800 Avg. Training loss: 1.5472 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 511000 Avg. Training loss: 1.6095 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 511200 Avg. Training loss: 1.3896 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 511400 Avg. Training loss: 1.5823 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 511600 Avg. Training loss: 1.4524 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 511800 Avg. Training loss: 1.6810 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 512000 Avg. Training loss: 1.5663 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 512200 Avg. Training loss: 1.5476 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 512400 Avg. Training loss: 1.5834 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 512600 Avg. Training loss: 1.6157 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 512800 Avg. Training loss: 1.6032 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 513000 Avg. Training loss: 1.6536 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 513200 Avg. Training loss: 1.6432 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 513400 Avg. Training loss: 1.5690 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 513600 Avg. Training loss: 1.5757 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 513800 Avg. Training loss: 1.7113 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 514000 Avg. Training loss: 1.6479 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 514200 Avg. Training loss: 1.6529 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 514400 Avg. Training loss: 1.5013 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 514600 Avg. Training loss: 1.6103 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 514800 Avg. Training loss: 1.4837 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 515000 Avg. Training loss: 1.5827 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 515200 Avg. Training loss: 1.4179 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 515400 Avg. Training loss: 1.5433 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 515600 Avg. Training loss: 1.5700 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 515800 Avg. Training loss: 1.4697 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 516000 Avg. Training loss: 1.6157 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 516200 Avg. Training loss: 1.5856 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 516400 Avg. Training loss: 1.6430 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 516600 Avg. Training loss: 1.4924 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 516800 Avg. Training loss: 1.4310 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 517000 Avg. Training loss: 1.6309 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 517200 Avg. Training loss: 1.7567 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 517400 Avg. Training loss: 1.5223 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 517600 Avg. Training loss: 1.6079 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 517800 Avg. Training loss: 1.4579 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 518000 Avg. Training loss: 1.3614 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 518200 Avg. Training loss: 1.4899 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 518400 Avg. Training loss: 1.4932 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 518600 Avg. Training loss: 1.5380 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 518800 Avg. Training loss: 1.5537 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 519000 Avg. Training loss: 1.5655 0.0020 sec/batch\n",
      "Epoch 10/10 Iteration: 519200 Avg. Training loss: 1.5961 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 519400 Avg. Training loss: 1.6215 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 519600 Avg. Training loss: 1.4808 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 519800 Avg. Training loss: 1.5055 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 520000 Avg. Training loss: 1.4801 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 520200 Avg. Training loss: 1.6190 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 520400 Avg. Training loss: 1.5814 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 520600 Avg. Training loss: 1.5261 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 520800 Avg. Training loss: 1.4722 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 521000 Avg. Training loss: 1.5670 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 521200 Avg. Training loss: 1.4718 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 521400 Avg. Training loss: 1.5563 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 521600 Avg. Training loss: 1.6676 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 521800 Avg. Training loss: 1.4736 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 522000 Avg. Training loss: 1.6209 0.0016 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 Iteration: 522200 Avg. Training loss: 1.4549 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 522400 Avg. Training loss: 1.6641 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 522600 Avg. Training loss: 1.4350 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 522800 Avg. Training loss: 1.5387 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 523000 Avg. Training loss: 1.5814 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 523200 Avg. Training loss: 1.6341 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 523400 Avg. Training loss: 1.6757 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 523600 Avg. Training loss: 1.4735 0.0043 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 523800 Avg. Training loss: 1.6573 0.0025 sec/batch\n",
      "Epoch 10/10 Iteration: 524000 Avg. Training loss: 1.5133 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 524200 Avg. Training loss: 1.6231 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 524400 Avg. Training loss: 1.5737 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 524600 Avg. Training loss: 1.6669 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 524800 Avg. Training loss: 1.7181 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 525000 Avg. Training loss: 1.4399 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 525200 Avg. Training loss: 1.5612 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 525400 Avg. Training loss: 1.6037 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 525600 Avg. Training loss: 1.5253 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 525800 Avg. Training loss: 1.6598 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 526000 Avg. Training loss: 1.6239 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 526200 Avg. Training loss: 1.5950 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 526400 Avg. Training loss: 1.5075 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 526600 Avg. Training loss: 1.5179 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 526800 Avg. Training loss: 1.5770 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 527000 Avg. Training loss: 1.6091 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 527200 Avg. Training loss: 1.7293 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 527400 Avg. Training loss: 1.6465 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 527600 Avg. Training loss: 1.5934 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 527800 Avg. Training loss: 1.6234 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 528000 Avg. Training loss: 1.5470 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 528200 Avg. Training loss: 1.4971 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 528400 Avg. Training loss: 1.6729 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 528600 Avg. Training loss: 1.5578 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 528800 Avg. Training loss: 1.4549 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 529000 Avg. Training loss: 1.6828 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 529200 Avg. Training loss: 1.5852 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 529400 Avg. Training loss: 1.6679 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 529600 Avg. Training loss: 1.6232 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 529800 Avg. Training loss: 1.4492 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 530000 Avg. Training loss: 1.6149 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 530200 Avg. Training loss: 1.6510 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 530400 Avg. Training loss: 1.5047 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 530600 Avg. Training loss: 1.4777 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 530800 Avg. Training loss: 1.4317 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 531000 Avg. Training loss: 1.5440 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 531200 Avg. Training loss: 1.5820 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 531400 Avg. Training loss: 1.5864 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 531600 Avg. Training loss: 1.6413 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 531800 Avg. Training loss: 1.5473 0.0015 sec/batch\n",
      "Epoch 10/10 Iteration: 532000 Avg. Training loss: 1.6649 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 532200 Avg. Training loss: 1.5800 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 532400 Avg. Training loss: 1.5327 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 532600 Avg. Training loss: 1.6443 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 532800 Avg. Training loss: 1.3990 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 533000 Avg. Training loss: 1.6177 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 533200 Avg. Training loss: 1.7035 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 533400 Avg. Training loss: 1.5335 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 533600 Avg. Training loss: 1.4621 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 533800 Avg. Training loss: 1.6590 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 534000 Avg. Training loss: 1.5163 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 534200 Avg. Training loss: 1.5041 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 534400 Avg. Training loss: 1.5874 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 534600 Avg. Training loss: 1.6102 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 534800 Avg. Training loss: 1.5517 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 535000 Avg. Training loss: 1.5784 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 535200 Avg. Training loss: 1.5133 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 535400 Avg. Training loss: 1.5611 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 535600 Avg. Training loss: 1.4510 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 535800 Avg. Training loss: 1.5362 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 536000 Avg. Training loss: 1.6452 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 536200 Avg. Training loss: 1.6814 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 536400 Avg. Training loss: 1.5393 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 536600 Avg. Training loss: 1.5409 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 536800 Avg. Training loss: 1.6464 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 537000 Avg. Training loss: 1.6247 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 537200 Avg. Training loss: 1.6288 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 537400 Avg. Training loss: 1.6039 0.0015 sec/batch\n",
      "Epoch 10/10 Iteration: 537600 Avg. Training loss: 1.4833 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 537800 Avg. Training loss: 1.4505 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 538000 Avg. Training loss: 1.4941 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 538200 Avg. Training loss: 1.5395 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 538400 Avg. Training loss: 1.4953 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 538600 Avg. Training loss: 1.5239 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 538800 Avg. Training loss: 1.6169 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 539000 Avg. Training loss: 1.6040 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 539200 Avg. Training loss: 1.6166 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 539400 Avg. Training loss: 1.4851 0.0020 sec/batch\n",
      "Epoch 10/10 Iteration: 539600 Avg. Training loss: 1.5507 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 539800 Avg. Training loss: 1.5296 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 540000 Avg. Training loss: 1.6150 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 540200 Avg. Training loss: 1.6772 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 540400 Avg. Training loss: 1.5462 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 540600 Avg. Training loss: 1.7756 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 540800 Avg. Training loss: 1.6510 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 541000 Avg. Training loss: 1.6404 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 541200 Avg. Training loss: 1.6904 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 541400 Avg. Training loss: 1.5919 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 541600 Avg. Training loss: 1.6418 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 541800 Avg. Training loss: 1.6918 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 542000 Avg. Training loss: 1.6555 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 542200 Avg. Training loss: 1.5446 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 542400 Avg. Training loss: 1.4702 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 542600 Avg. Training loss: 1.7053 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 542800 Avg. Training loss: 1.7058 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 543000 Avg. Training loss: 1.5210 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 543200 Avg. Training loss: 1.6129 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 543400 Avg. Training loss: 1.5041 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 543600 Avg. Training loss: 1.5030 0.0017 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 Iteration: 543800 Avg. Training loss: 1.5898 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 544000 Avg. Training loss: 1.5021 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 544200 Avg. Training loss: 1.6252 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 544400 Avg. Training loss: 1.6519 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 544600 Avg. Training loss: 1.4355 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 544800 Avg. Training loss: 1.6418 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 545000 Avg. Training loss: 1.5458 0.0021 sec/batch\n",
      "Epoch 10/10 Iteration: 545200 Avg. Training loss: 1.5671 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 545400 Avg. Training loss: 1.6191 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 545600 Avg. Training loss: 1.4931 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 545800 Avg. Training loss: 1.5722 0.0020 sec/batch\n",
      "Epoch 10/10 Iteration: 546000 Avg. Training loss: 1.6466 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 546200 Avg. Training loss: 1.5548 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 546400 Avg. Training loss: 1.5329 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 546600 Avg. Training loss: 1.5232 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 546800 Avg. Training loss: 1.5013 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 547000 Avg. Training loss: 1.4216 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 547200 Avg. Training loss: 1.6741 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 547400 Avg. Training loss: 1.6081 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 547600 Avg. Training loss: 1.5391 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 547800 Avg. Training loss: 1.5798 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 548000 Avg. Training loss: 1.4309 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 548200 Avg. Training loss: 1.6627 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 548400 Avg. Training loss: 1.6268 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 548600 Avg. Training loss: 1.5504 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 548800 Avg. Training loss: 1.6623 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 549000 Avg. Training loss: 1.5353 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 549200 Avg. Training loss: 1.5460 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 549400 Avg. Training loss: 1.4590 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 549600 Avg. Training loss: 1.7252 0.0020 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 549800 Avg. Training loss: 1.6507 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 550000 Avg. Training loss: 1.6042 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 550200 Avg. Training loss: 1.5385 0.0020 sec/batch\n",
      "Epoch 10/10 Iteration: 550400 Avg. Training loss: 1.6360 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 550600 Avg. Training loss: 1.6790 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 550800 Avg. Training loss: 1.6365 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 551000 Avg. Training loss: 1.5363 0.0015 sec/batch\n",
      "Epoch 10/10 Iteration: 551200 Avg. Training loss: 1.5685 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 551400 Avg. Training loss: 1.5869 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 551600 Avg. Training loss: 1.5191 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 551800 Avg. Training loss: 1.6863 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 552000 Avg. Training loss: 1.5343 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 552200 Avg. Training loss: 1.6582 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 552400 Avg. Training loss: 1.3985 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 552600 Avg. Training loss: 1.5716 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 552800 Avg. Training loss: 1.6071 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 553000 Avg. Training loss: 1.5322 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 553200 Avg. Training loss: 1.4818 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 553400 Avg. Training loss: 1.6024 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 553600 Avg. Training loss: 1.4687 0.0015 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 553800 Avg. Training loss: 1.4989 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 554000 Avg. Training loss: 1.5899 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 554200 Avg. Training loss: 1.6691 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 554400 Avg. Training loss: 1.4913 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 554600 Avg. Training loss: 1.4730 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 554800 Avg. Training loss: 1.4985 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 555000 Avg. Training loss: 1.4815 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 555200 Avg. Training loss: 1.5418 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 555400 Avg. Training loss: 1.5801 0.0016 sec/batch\n",
      "Epoch 10/10 Iteration: 555600 Avg. Training loss: 1.5142 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 555800 Avg. Training loss: 1.7145 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 556000 Avg. Training loss: 1.6046 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 556200 Avg. Training loss: 1.6726 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 556400 Avg. Training loss: 1.4228 0.0017 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 556600 Avg. Training loss: 1.5926 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 556800 Avg. Training loss: 1.5734 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 557000 Avg. Training loss: 1.5482 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 557200 Avg. Training loss: 1.3978 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 557400 Avg. Training loss: 1.5723 0.0020 sec/batch\n",
      "Epoch 10/10 Iteration: 557600 Avg. Training loss: 1.5149 0.0020 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 557800 Avg. Training loss: 1.6101 0.0020 sec/batch\n",
      "Epoch 10/10 Iteration: 558000 Avg. Training loss: 1.6235 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 558200 Avg. Training loss: 1.5351 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 558400 Avg. Training loss: 1.5003 0.0016 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 558600 Avg. Training loss: 1.7474 0.0018 sec/batch\n",
      "Epoch 10/10 Iteration: 558800 Avg. Training loss: 1.6765 0.0018 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 559000 Avg. Training loss: 1.4406 0.0019 sec/batch\n",
      "Epoch 10/10 Iteration: 559200 Avg. Training loss: 1.6163 0.0019 sec/batch\n",
      "error\n",
      "Epoch 10/10 Iteration: 559400 Avg. Training loss: 1.6749 0.0017 sec/batch\n",
      "Epoch 10/10 Iteration: 559600 Avg. Training loss: 1.5556 0.0017 sec/batch\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "Tdl.auto_train(datapath,keypath,n_embedding ,\\\n",
    "n_sampled,\\\n",
    "epochs,\\\n",
    "batch_size,\\\n",
    "window_size,\\\n",
    "ch_save,\\\n",
    "savename=savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
