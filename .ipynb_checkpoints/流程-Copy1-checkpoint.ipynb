{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wangls/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from data_process.process_data import *\n",
    "\n",
    "from skip_grame.skip_gram import *\n",
    "\n",
    "from visualize.visualize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.10067114093959731\n",
      "0.20134228187919462\n",
      "0.30201342281879195\n",
      "0.40268456375838924\n",
      "0.5033557046979866\n",
      "0.6040268456375839\n",
      "0.7046979865771812\n",
      "0.8053691275167785\n",
      "0.9060402684563759\n"
     ]
    }
   ],
   "source": [
    "DPS = Data_Prep_shop(auto = False)\n",
    "DPS.shop_name_clean()\n",
    "DPS.frequancy_filter()\n",
    "DPS.depart_group_of_cus()\n",
    "DPS.save_cus_result('pros_1_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24734,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('data/pros_1__cus.npy',allow_pickle=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPS = Data_Prep_shop(auto = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 Iteration: 200 Avg. Training loss: 0.9835 0.0101 sec/batch\n",
      "Epoch 1/50 Iteration: 400 Avg. Training loss: 1.0779 0.0083 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 600 Avg. Training loss: 0.8759 0.0082 sec/batch\n",
      "Epoch 1/50 Iteration: 800 Avg. Training loss: 1.0593 0.0087 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 1000 Avg. Training loss: 0.9752 0.0079 sec/batch\n",
      "Epoch 1/50 Iteration: 1200 Avg. Training loss: 1.0226 0.0071 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 1400 Avg. Training loss: 1.0609 0.0076 sec/batch\n",
      "Epoch 1/50 Iteration: 1600 Avg. Training loss: 0.9368 0.0075 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 1800 Avg. Training loss: 0.9625 0.0072 sec/batch\n",
      "Epoch 1/50 Iteration: 2000 Avg. Training loss: 1.0824 0.0072 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 2200 Avg. Training loss: 0.9820 0.0074 sec/batch\n",
      "Epoch 1/50 Iteration: 2400 Avg. Training loss: 0.8945 0.0073 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 2600 Avg. Training loss: 1.0074 0.0076 sec/batch\n",
      "Epoch 1/50 Iteration: 2800 Avg. Training loss: 1.0758 0.0073 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 3000 Avg. Training loss: 1.0185 0.0074 sec/batch\n",
      "Epoch 1/50 Iteration: 3200 Avg. Training loss: 1.1464 0.0106 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 3400 Avg. Training loss: 1.1321 0.0076 sec/batch\n",
      "Epoch 1/50 Iteration: 3600 Avg. Training loss: 1.1067 0.0074 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 3800 Avg. Training loss: 0.9711 0.0071 sec/batch\n",
      "Epoch 1/50 Iteration: 4000 Avg. Training loss: 1.0934 0.0074 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 4200 Avg. Training loss: 1.1047 0.0070 sec/batch\n",
      "Epoch 1/50 Iteration: 4400 Avg. Training loss: 0.9939 0.0073 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 4600 Avg. Training loss: 1.1205 0.0071 sec/batch\n",
      "Epoch 1/50 Iteration: 4800 Avg. Training loss: 1.1975 0.0070 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 5000 Avg. Training loss: 1.0811 0.0076 sec/batch\n",
      "Epoch 1/50 Iteration: 5200 Avg. Training loss: 1.0531 0.0071 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 5400 Avg. Training loss: 1.0022 0.0073 sec/batch\n",
      "Epoch 1/50 Iteration: 5600 Avg. Training loss: 1.0409 0.0119 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 5800 Avg. Training loss: 1.1042 0.0085 sec/batch\n",
      "Epoch 1/50 Iteration: 6000 Avg. Training loss: 1.0084 0.0071 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 6200 Avg. Training loss: 0.9454 0.0073 sec/batch\n",
      "Epoch 1/50 Iteration: 6400 Avg. Training loss: 1.0578 0.0074 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 6600 Avg. Training loss: 1.0414 0.0072 sec/batch\n",
      "Epoch 1/50 Iteration: 6800 Avg. Training loss: 1.0494 0.0072 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 7000 Avg. Training loss: 1.0222 0.0072 sec/batch\n",
      "Epoch 1/50 Iteration: 7200 Avg. Training loss: 1.0274 0.0073 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 7400 Avg. Training loss: 1.0497 0.0078 sec/batch\n",
      "Epoch 1/50 Iteration: 7600 Avg. Training loss: 0.9168 0.0074 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 7800 Avg. Training loss: 1.0016 0.0074 sec/batch\n",
      "Epoch 1/50 Iteration: 8000 Avg. Training loss: 1.0187 0.0073 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 8200 Avg. Training loss: 0.8836 0.0073 sec/batch\n",
      "Epoch 1/50 Iteration: 8400 Avg. Training loss: 1.0644 0.0089 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 8600 Avg. Training loss: 1.0513 0.0071 sec/batch\n",
      "Epoch 1/50 Iteration: 8800 Avg. Training loss: 0.9900 0.0071 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 9000 Avg. Training loss: 0.9904 0.0072 sec/batch\n",
      "Epoch 1/50 Iteration: 9200 Avg. Training loss: 0.8648 0.0073 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 9400 Avg. Training loss: 0.9960 0.0084 sec/batch\n",
      "Epoch 1/50 Iteration: 9600 Avg. Training loss: 0.9701 0.0075 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 9800 Avg. Training loss: 0.8995 0.0072 sec/batch\n",
      "Epoch 1/50 Iteration: 10000 Avg. Training loss: 1.0415 0.0071 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 10200 Avg. Training loss: 0.9178 0.0077 sec/batch\n",
      "Epoch 1/50 Iteration: 10400 Avg. Training loss: 1.0565 0.0073 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 10600 Avg. Training loss: 1.0179 0.0074 sec/batch\n",
      "Epoch 1/50 Iteration: 10800 Avg. Training loss: 0.9963 0.0071 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 11000 Avg. Training loss: 1.0204 0.0075 sec/batch\n",
      "Epoch 1/50 Iteration: 11200 Avg. Training loss: 0.8831 0.0199 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 11400 Avg. Training loss: 1.0600 0.0080 sec/batch\n",
      "Epoch 1/50 Iteration: 11600 Avg. Training loss: 1.0010 0.0073 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 11800 Avg. Training loss: 0.9764 0.0072 sec/batch\n",
      "Epoch 1/50 Iteration: 12000 Avg. Training loss: 0.9972 0.0072 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 12200 Avg. Training loss: 0.9748 0.0073 sec/batch\n",
      "Epoch 1/50 Iteration: 12400 Avg. Training loss: 1.1891 0.0073 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 12600 Avg. Training loss: 1.0464 0.0077 sec/batch\n",
      "Epoch 1/50 Iteration: 12800 Avg. Training loss: 1.0604 0.0082 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 13000 Avg. Training loss: 1.0705 0.0076 sec/batch\n",
      "Epoch 1/50 Iteration: 13200 Avg. Training loss: 1.1262 0.0083 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 13400 Avg. Training loss: 0.9493 0.0077 sec/batch\n",
      "Epoch 1/50 Iteration: 13600 Avg. Training loss: 1.0138 0.0074 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 13800 Avg. Training loss: 1.0507 0.0076 sec/batch\n",
      "Epoch 1/50 Iteration: 14000 Avg. Training loss: 1.1231 0.0078 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 14200 Avg. Training loss: 0.9231 0.0075 sec/batch\n",
      "Epoch 1/50 Iteration: 14400 Avg. Training loss: 1.1002 0.0074 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 14600 Avg. Training loss: 0.9703 0.0074 sec/batch\n",
      "Epoch 1/50 Iteration: 14800 Avg. Training loss: 1.0179 0.0071 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 15000 Avg. Training loss: 1.0685 0.0073 sec/batch\n",
      "Epoch 1/50 Iteration: 15200 Avg. Training loss: 1.1247 0.0073 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 15400 Avg. Training loss: 1.0425 0.0072 sec/batch\n",
      "Epoch 1/50 Iteration: 15600 Avg. Training loss: 0.9408 0.0072 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 15800 Avg. Training loss: 0.9786 0.0074 sec/batch\n",
      "Epoch 1/50 Iteration: 16000 Avg. Training loss: 0.8839 0.0076 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 16200 Avg. Training loss: 1.0986 0.0072 sec/batch\n",
      "Epoch 1/50 Iteration: 16400 Avg. Training loss: 0.9966 0.0078 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 16600 Avg. Training loss: 1.0656 0.0072 sec/batch\n",
      "Epoch 1/50 Iteration: 16800 Avg. Training loss: 0.9942 0.0073 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 17000 Avg. Training loss: 0.9365 0.0083 sec/batch\n",
      "Epoch 1/50 Iteration: 17200 Avg. Training loss: 1.0831 0.0072 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 17400 Avg. Training loss: 1.0602 0.0072 sec/batch\n",
      "Epoch 1/50 Iteration: 17600 Avg. Training loss: 0.9398 0.0074 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 17800 Avg. Training loss: 0.9057 0.0077 sec/batch\n",
      "Epoch 1/50 Iteration: 18000 Avg. Training loss: 0.9521 0.0078 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 18200 Avg. Training loss: 0.9805 0.0001 sec/batch\n",
      "Epoch 2/50 Iteration: 18400 Avg. Training loss: 1.0741 0.0075 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 18600 Avg. Training loss: 0.9295 0.0077 sec/batch\n",
      "Epoch 2/50 Iteration: 18800 Avg. Training loss: 0.9393 0.0074 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 19000 Avg. Training loss: 1.0580 0.0080 sec/batch\n",
      "Epoch 2/50 Iteration: 19200 Avg. Training loss: 1.0074 0.0076 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 19400 Avg. Training loss: 0.9737 0.0073 sec/batch\n",
      "Epoch 2/50 Iteration: 19600 Avg. Training loss: 0.9513 0.0076 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 19800 Avg. Training loss: 0.9101 0.0076 sec/batch\n",
      "Epoch 2/50 Iteration: 20000 Avg. Training loss: 0.9791 0.0073 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 20200 Avg. Training loss: 1.1211 0.0079 sec/batch\n",
      "Epoch 2/50 Iteration: 20400 Avg. Training loss: 1.1173 0.0072 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 20600 Avg. Training loss: 0.8974 0.0075 sec/batch\n",
      "Epoch 2/50 Iteration: 20800 Avg. Training loss: 0.9068 0.0075 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 21000 Avg. Training loss: 1.0025 0.0072 sec/batch\n",
      "Epoch 2/50 Iteration: 21200 Avg. Training loss: 0.8860 0.0148 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 21400 Avg. Training loss: 0.8619 0.0076 sec/batch\n",
      "Epoch 2/50 Iteration: 21600 Avg. Training loss: 0.7735 0.0079 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 21800 Avg. Training loss: 0.9679 0.0076 sec/batch\n",
      "Epoch 2/50 Iteration: 22000 Avg. Training loss: 0.9738 0.0072 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 Iteration: 22200 Avg. Training loss: 1.0249 0.0076 sec/batch\n",
      "Epoch 2/50 Iteration: 22400 Avg. Training loss: 1.0312 0.0070 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 22600 Avg. Training loss: 0.9307 0.0075 sec/batch\n",
      "Epoch 2/50 Iteration: 22800 Avg. Training loss: 1.0517 0.0072 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 23000 Avg. Training loss: 1.0036 0.0071 sec/batch\n",
      "Epoch 2/50 Iteration: 23200 Avg. Training loss: 0.9933 0.0076 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 23400 Avg. Training loss: 0.9828 0.0072 sec/batch\n",
      "Epoch 2/50 Iteration: 23600 Avg. Training loss: 0.9282 0.0072 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 23800 Avg. Training loss: 1.0047 0.0074 sec/batch\n",
      "Epoch 2/50 Iteration: 24000 Avg. Training loss: 1.0071 0.0075 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 24200 Avg. Training loss: 0.8628 0.0069 sec/batch\n",
      "Epoch 2/50 Iteration: 24400 Avg. Training loss: 0.9155 0.0070 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 24600 Avg. Training loss: 0.9886 0.0070 sec/batch\n",
      "Epoch 2/50 Iteration: 24800 Avg. Training loss: 0.9909 0.0069 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 25000 Avg. Training loss: 0.9700 0.0068 sec/batch\n",
      "Epoch 2/50 Iteration: 25200 Avg. Training loss: 0.9291 0.0069 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 25400 Avg. Training loss: 1.0196 0.0070 sec/batch\n",
      "Epoch 2/50 Iteration: 25600 Avg. Training loss: 0.9600 0.0075 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 25800 Avg. Training loss: 0.8430 0.0069 sec/batch\n",
      "Epoch 2/50 Iteration: 26000 Avg. Training loss: 0.9017 0.0070 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 26200 Avg. Training loss: 0.9261 0.0069 sec/batch\n",
      "Epoch 2/50 Iteration: 26400 Avg. Training loss: 0.8648 0.0070 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 26600 Avg. Training loss: 0.9457 0.0090 sec/batch\n",
      "Epoch 2/50 Iteration: 26800 Avg. Training loss: 1.0992 0.0067 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 27000 Avg. Training loss: 1.0986 0.0068 sec/batch\n",
      "Epoch 2/50 Iteration: 27200 Avg. Training loss: 0.8179 0.0068 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 27400 Avg. Training loss: 1.0166 0.0068 sec/batch\n",
      "Epoch 2/50 Iteration: 27600 Avg. Training loss: 0.9157 0.0080 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 27800 Avg. Training loss: 0.9831 0.0083 sec/batch\n",
      "Epoch 2/50 Iteration: 28000 Avg. Training loss: 0.8561 0.0066 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 28200 Avg. Training loss: 0.9207 0.0070 sec/batch\n",
      "Epoch 2/50 Iteration: 28400 Avg. Training loss: 1.0517 0.0074 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 28600 Avg. Training loss: 0.9148 0.0070 sec/batch\n",
      "Epoch 2/50 Iteration: 28800 Avg. Training loss: 0.8369 0.0071 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 29000 Avg. Training loss: 0.8958 0.0067 sec/batch\n",
      "Epoch 2/50 Iteration: 29200 Avg. Training loss: 1.1244 0.0070 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 29400 Avg. Training loss: 0.7889 0.0072 sec/batch\n",
      "Epoch 2/50 Iteration: 29600 Avg. Training loss: 0.8803 0.0068 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 29800 Avg. Training loss: 0.8669 0.0070 sec/batch\n",
      "Epoch 2/50 Iteration: 30000 Avg. Training loss: 0.9045 0.0174 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 30200 Avg. Training loss: 0.9418 0.0078 sec/batch\n",
      "Epoch 2/50 Iteration: 30400 Avg. Training loss: 0.9273 0.0069 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 30600 Avg. Training loss: 1.0517 0.0073 sec/batch\n",
      "Epoch 2/50 Iteration: 30800 Avg. Training loss: 0.9740 0.0069 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 31000 Avg. Training loss: 0.9230 0.0079 sec/batch\n",
      "Epoch 2/50 Iteration: 31200 Avg. Training loss: 0.8637 0.0072 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 31400 Avg. Training loss: 1.0021 0.0084 sec/batch\n",
      "Epoch 2/50 Iteration: 31600 Avg. Training loss: 0.9044 0.0075 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 31800 Avg. Training loss: 1.0743 0.0071 sec/batch\n",
      "Epoch 2/50 Iteration: 32000 Avg. Training loss: 0.8796 0.0067 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 32200 Avg. Training loss: 0.9689 0.0072 sec/batch\n",
      "Epoch 2/50 Iteration: 32400 Avg. Training loss: 0.9300 0.0069 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 32600 Avg. Training loss: 1.0292 0.0070 sec/batch\n",
      "Epoch 2/50 Iteration: 32800 Avg. Training loss: 0.9186 0.0076 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 33000 Avg. Training loss: 0.9922 0.0078 sec/batch\n",
      "Epoch 2/50 Iteration: 33200 Avg. Training loss: 1.0128 0.0067 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 33400 Avg. Training loss: 1.1731 0.0070 sec/batch\n",
      "Epoch 2/50 Iteration: 33600 Avg. Training loss: 0.9247 0.0070 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 33800 Avg. Training loss: 0.9926 0.0071 sec/batch\n",
      "Epoch 2/50 Iteration: 34000 Avg. Training loss: 0.9297 0.0068 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 34200 Avg. Training loss: 0.9670 0.0074 sec/batch\n",
      "Epoch 2/50 Iteration: 34400 Avg. Training loss: 0.9542 0.0067 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 34600 Avg. Training loss: 0.7693 0.0069 sec/batch\n",
      "Epoch 2/50 Iteration: 34800 Avg. Training loss: 0.9745 0.0066 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 35000 Avg. Training loss: 0.9485 0.0068 sec/batch\n",
      "Epoch 2/50 Iteration: 35200 Avg. Training loss: 1.0156 0.0080 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 35400 Avg. Training loss: 1.1529 0.0070 sec/batch\n",
      "Epoch 2/50 Iteration: 35600 Avg. Training loss: 0.8883 0.0069 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 35800 Avg. Training loss: 0.8581 0.0070 sec/batch\n",
      "Epoch 2/50 Iteration: 36000 Avg. Training loss: 0.8742 0.0076 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 36200 Avg. Training loss: 0.9771 0.0076 sec/batch\n",
      "Epoch 3/50 Iteration: 36400 Avg. Training loss: 0.8784 0.0002 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 36600 Avg. Training loss: 1.0651 0.0075 sec/batch\n",
      "Epoch 3/50 Iteration: 36800 Avg. Training loss: 0.9430 0.0076 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 37000 Avg. Training loss: 0.8431 0.0074 sec/batch\n",
      "Epoch 3/50 Iteration: 37200 Avg. Training loss: 1.1118 0.0080 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 37400 Avg. Training loss: 1.0473 0.0074 sec/batch\n",
      "Epoch 3/50 Iteration: 37600 Avg. Training loss: 0.9180 0.0098 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 37800 Avg. Training loss: 0.8134 0.0074 sec/batch\n",
      "Epoch 3/50 Iteration: 38000 Avg. Training loss: 0.7277 0.0071 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 38200 Avg. Training loss: 0.8598 0.0068 sec/batch\n",
      "Epoch 3/50 Iteration: 38400 Avg. Training loss: 0.9980 0.0070 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 38600 Avg. Training loss: 0.9028 0.0071 sec/batch\n",
      "Epoch 3/50 Iteration: 38800 Avg. Training loss: 0.8723 0.0070 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 39000 Avg. Training loss: 0.9354 0.0076 sec/batch\n",
      "Epoch 3/50 Iteration: 39200 Avg. Training loss: 0.9374 0.0071 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 39400 Avg. Training loss: 1.0075 0.0070 sec/batch\n",
      "Epoch 3/50 Iteration: 39600 Avg. Training loss: 0.8881 0.0072 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 39800 Avg. Training loss: 0.8072 0.0076 sec/batch\n",
      "Epoch 3/50 Iteration: 40000 Avg. Training loss: 0.8947 0.0071 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 40200 Avg. Training loss: 0.9151 0.0069 sec/batch\n",
      "Epoch 3/50 Iteration: 40400 Avg. Training loss: 0.7980 0.0073 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 40600 Avg. Training loss: 0.7993 0.0068 sec/batch\n",
      "Epoch 3/50 Iteration: 40800 Avg. Training loss: 0.8038 0.0072 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 41000 Avg. Training loss: 0.8158 0.0070 sec/batch\n",
      "Epoch 3/50 Iteration: 41200 Avg. Training loss: 0.9356 0.0069 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 41400 Avg. Training loss: 0.9987 0.0073 sec/batch\n",
      "Epoch 3/50 Iteration: 41600 Avg. Training loss: 1.0070 0.0067 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 41800 Avg. Training loss: 0.7795 0.0073 sec/batch\n",
      "Epoch 3/50 Iteration: 42000 Avg. Training loss: 0.8997 0.0075 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 42200 Avg. Training loss: 0.9489 0.0075 sec/batch\n",
      "Epoch 3/50 Iteration: 42400 Avg. Training loss: 0.8151 0.0069 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 42600 Avg. Training loss: 0.9018 0.0070 sec/batch\n",
      "Epoch 3/50 Iteration: 42800 Avg. Training loss: 0.8545 0.0070 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 43000 Avg. Training loss: 1.0153 0.0069 sec/batch\n",
      "Epoch 3/50 Iteration: 43200 Avg. Training loss: 0.8556 0.0077 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 43400 Avg. Training loss: 0.9898 0.0074 sec/batch\n",
      "Epoch 3/50 Iteration: 43600 Avg. Training loss: 0.8798 0.0071 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 43800 Avg. Training loss: 0.8858 0.0075 sec/batch\n",
      "Epoch 3/50 Iteration: 44000 Avg. Training loss: 0.8274 0.0066 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 Iteration: 44200 Avg. Training loss: 0.9409 0.0067 sec/batch\n",
      "Epoch 3/50 Iteration: 44400 Avg. Training loss: 0.9612 0.0067 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 44600 Avg. Training loss: 0.8440 0.0069 sec/batch\n",
      "Epoch 3/50 Iteration: 44800 Avg. Training loss: 0.9102 0.0087 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 45000 Avg. Training loss: 0.9166 0.0066 sec/batch\n",
      "Epoch 3/50 Iteration: 45200 Avg. Training loss: 0.9684 0.0067 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 45400 Avg. Training loss: 0.8149 0.0069 sec/batch\n",
      "Epoch 3/50 Iteration: 45600 Avg. Training loss: 0.8339 0.0078 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 45800 Avg. Training loss: 0.8537 0.0082 sec/batch\n",
      "Epoch 3/50 Iteration: 46000 Avg. Training loss: 0.8394 0.0068 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 46200 Avg. Training loss: 0.8777 0.0071 sec/batch\n",
      "Epoch 3/50 Iteration: 46400 Avg. Training loss: 0.9945 0.0076 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 46600 Avg. Training loss: 1.0158 0.0077 sec/batch\n",
      "Epoch 3/50 Iteration: 46800 Avg. Training loss: 0.8453 0.0071 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 47000 Avg. Training loss: 0.9202 0.0071 sec/batch\n",
      "Epoch 3/50 Iteration: 47200 Avg. Training loss: 0.9953 0.0065 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 47400 Avg. Training loss: 0.8712 0.0071 sec/batch\n",
      "Epoch 3/50 Iteration: 47600 Avg. Training loss: 0.9062 0.0170 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 47800 Avg. Training loss: 0.9111 0.0076 sec/batch\n",
      "Epoch 3/50 Iteration: 48000 Avg. Training loss: 0.6567 0.0071 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 48200 Avg. Training loss: 0.8727 0.0073 sec/batch\n",
      "Epoch 3/50 Iteration: 48400 Avg. Training loss: 0.7964 0.0075 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 48600 Avg. Training loss: 0.7852 0.0073 sec/batch\n",
      "Epoch 3/50 Iteration: 48800 Avg. Training loss: 0.9315 0.0071 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 49000 Avg. Training loss: 0.7990 0.0078 sec/batch\n",
      "Epoch 3/50 Iteration: 49200 Avg. Training loss: 0.7844 0.0080 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 49400 Avg. Training loss: 0.8254 0.0071 sec/batch\n",
      "Epoch 3/50 Iteration: 49600 Avg. Training loss: 0.9076 0.0083 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 49800 Avg. Training loss: 0.9335 0.0073 sec/batch\n",
      "Epoch 3/50 Iteration: 50000 Avg. Training loss: 0.8321 0.0069 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 50200 Avg. Training loss: 0.9645 0.0067 sec/batch\n",
      "Epoch 3/50 Iteration: 50400 Avg. Training loss: 0.8484 0.0070 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 50600 Avg. Training loss: 0.8373 0.0070 sec/batch\n",
      "Epoch 3/50 Iteration: 50800 Avg. Training loss: 1.0300 0.0069 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 51000 Avg. Training loss: 0.9394 0.0070 sec/batch\n",
      "Epoch 3/50 Iteration: 51200 Avg. Training loss: 0.9323 0.0065 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 51400 Avg. Training loss: 0.9508 0.0067 sec/batch\n",
      "Epoch 3/50 Iteration: 51600 Avg. Training loss: 1.0051 0.0069 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 51800 Avg. Training loss: 0.7695 0.0069 sec/batch\n",
      "Epoch 3/50 Iteration: 52000 Avg. Training loss: 0.9937 0.0070 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 52200 Avg. Training loss: 0.8389 0.0067 sec/batch\n",
      "Epoch 3/50 Iteration: 52400 Avg. Training loss: 0.9839 0.0073 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 52600 Avg. Training loss: 0.9127 0.0067 sec/batch\n",
      "Epoch 3/50 Iteration: 52800 Avg. Training loss: 0.7513 0.0069 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 53000 Avg. Training loss: 0.9443 0.0066 sec/batch\n",
      "Epoch 3/50 Iteration: 53200 Avg. Training loss: 0.9945 0.0068 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 53400 Avg. Training loss: 1.0230 0.0079 sec/batch\n",
      "Epoch 3/50 Iteration: 53600 Avg. Training loss: 0.9277 0.0068 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 53800 Avg. Training loss: 1.0320 0.0067 sec/batch\n",
      "Epoch 3/50 Iteration: 54000 Avg. Training loss: 0.8124 0.0070 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 54200 Avg. Training loss: 0.7074 0.0074 sec/batch\n",
      "Epoch 3/50 Iteration: 54400 Avg. Training loss: 0.9370 0.0075 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 54600 Avg. Training loss: 0.9377 0.0003 sec/batch\n",
      "Epoch 4/50 Iteration: 54800 Avg. Training loss: 0.8805 0.0073 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 55000 Avg. Training loss: 0.8696 0.0074 sec/batch\n",
      "Epoch 4/50 Iteration: 55200 Avg. Training loss: 0.8437 0.0071 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 55400 Avg. Training loss: 0.8602 0.0079 sec/batch\n",
      "Epoch 4/50 Iteration: 55600 Avg. Training loss: 0.8885 0.0071 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 55800 Avg. Training loss: 0.7896 0.0068 sec/batch\n",
      "Epoch 4/50 Iteration: 56000 Avg. Training loss: 0.8889 0.0078 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 56200 Avg. Training loss: 0.7811 0.0073 sec/batch\n",
      "Epoch 4/50 Iteration: 56400 Avg. Training loss: 0.8575 0.0069 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 56600 Avg. Training loss: 0.9932 0.0067 sec/batch\n",
      "Epoch 4/50 Iteration: 56800 Avg. Training loss: 0.9254 0.0067 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 57000 Avg. Training loss: 0.8480 0.0069 sec/batch\n",
      "Epoch 4/50 Iteration: 57200 Avg. Training loss: 0.7959 0.0069 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 57400 Avg. Training loss: 0.7480 0.0069 sec/batch\n",
      "Epoch 4/50 Iteration: 57600 Avg. Training loss: 0.9447 0.0068 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 57800 Avg. Training loss: 0.9015 0.0070 sec/batch\n",
      "Epoch 4/50 Iteration: 58000 Avg. Training loss: 0.8432 0.0073 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 58200 Avg. Training loss: 0.8942 0.0069 sec/batch\n",
      "Epoch 4/50 Iteration: 58400 Avg. Training loss: 0.8709 0.0067 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 58600 Avg. Training loss: 0.7830 0.0072 sec/batch\n",
      "Epoch 4/50 Iteration: 58800 Avg. Training loss: 0.8479 0.0066 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 59000 Avg. Training loss: 0.7091 0.0071 sec/batch\n",
      "Epoch 4/50 Iteration: 59200 Avg. Training loss: 0.7871 0.0066 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 59400 Avg. Training loss: 0.7151 0.0066 sec/batch\n",
      "Epoch 4/50 Iteration: 59600 Avg. Training loss: 0.7817 0.0071 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 59800 Avg. Training loss: 0.8621 0.0067 sec/batch\n",
      "Epoch 4/50 Iteration: 60000 Avg. Training loss: 1.0571 0.0072 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 60200 Avg. Training loss: 0.8893 0.0072 sec/batch\n",
      "Epoch 4/50 Iteration: 60400 Avg. Training loss: 0.8323 0.0072 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 60600 Avg. Training loss: 0.7012 0.0068 sec/batch\n",
      "Epoch 4/50 Iteration: 60800 Avg. Training loss: 0.7651 0.0068 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 61000 Avg. Training loss: 0.7923 0.0068 sec/batch\n",
      "Epoch 4/50 Iteration: 61200 Avg. Training loss: 0.9213 0.0067 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 61400 Avg. Training loss: 0.8118 0.0068 sec/batch\n",
      "Epoch 4/50 Iteration: 61600 Avg. Training loss: 0.8286 0.0069 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 61800 Avg. Training loss: 0.7726 0.0068 sec/batch\n",
      "Epoch 4/50 Iteration: 62000 Avg. Training loss: 0.9736 0.0073 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 62200 Avg. Training loss: 0.8026 0.0066 sec/batch\n",
      "Epoch 4/50 Iteration: 62400 Avg. Training loss: 0.7893 0.0066 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 62600 Avg. Training loss: 0.8464 0.0066 sec/batch\n",
      "Epoch 4/50 Iteration: 62800 Avg. Training loss: 0.8734 0.0069 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 63000 Avg. Training loss: 0.9574 0.0089 sec/batch\n",
      "Epoch 4/50 Iteration: 63200 Avg. Training loss: 0.8409 0.0069 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 63400 Avg. Training loss: 0.8537 0.0068 sec/batch\n",
      "Epoch 4/50 Iteration: 63600 Avg. Training loss: 0.8589 0.0067 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 63800 Avg. Training loss: 0.9243 0.0068 sec/batch\n",
      "Epoch 4/50 Iteration: 64000 Avg. Training loss: 0.8643 0.0080 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 64200 Avg. Training loss: 0.7316 0.0068 sec/batch\n",
      "Epoch 4/50 Iteration: 64400 Avg. Training loss: 0.6438 0.0065 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 64600 Avg. Training loss: 0.9013 0.0067 sec/batch\n",
      "Epoch 4/50 Iteration: 64800 Avg. Training loss: 0.9402 0.0072 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 65000 Avg. Training loss: 0.9423 0.0068 sec/batch\n",
      "Epoch 4/50 Iteration: 65200 Avg. Training loss: 0.8571 0.0069 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 65400 Avg. Training loss: 0.8168 0.0065 sec/batch\n",
      "Epoch 4/50 Iteration: 65600 Avg. Training loss: 0.8086 0.0070 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 65800 Avg. Training loss: 0.7913 0.0071 sec/batch\n",
      "Epoch 4/50 Iteration: 66000 Avg. Training loss: 0.9080 0.0066 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 Iteration: 66200 Avg. Training loss: 0.7117 0.0103 sec/batch\n",
      "Epoch 4/50 Iteration: 66400 Avg. Training loss: 0.8838 0.0080 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 66600 Avg. Training loss: 0.7377 0.0068 sec/batch\n",
      "Epoch 4/50 Iteration: 66800 Avg. Training loss: 0.9109 0.0078 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 67000 Avg. Training loss: 0.8412 0.0070 sec/batch\n",
      "Epoch 4/50 Iteration: 67200 Avg. Training loss: 0.8160 0.0069 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 67400 Avg. Training loss: 0.7839 0.0080 sec/batch\n",
      "Epoch 4/50 Iteration: 67600 Avg. Training loss: 0.8263 0.0071 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 67800 Avg. Training loss: 0.9869 0.0081 sec/batch\n",
      "Epoch 4/50 Iteration: 68000 Avg. Training loss: 0.7884 0.0071 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 68200 Avg. Training loss: 0.8287 0.0072 sec/batch\n",
      "Epoch 4/50 Iteration: 68400 Avg. Training loss: 0.9621 0.0068 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 68600 Avg. Training loss: 0.8312 0.0071 sec/batch\n",
      "Epoch 4/50 Iteration: 68800 Avg. Training loss: 0.9574 0.0071 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 69000 Avg. Training loss: 0.9022 0.0071 sec/batch\n",
      "Epoch 4/50 Iteration: 69200 Avg. Training loss: 0.8250 0.0070 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 69400 Avg. Training loss: 0.8586 0.0069 sec/batch\n",
      "Epoch 4/50 Iteration: 69600 Avg. Training loss: 0.9247 0.0070 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 69800 Avg. Training loss: 0.7611 0.0070 sec/batch\n",
      "Epoch 4/50 Iteration: 70000 Avg. Training loss: 0.8633 0.0069 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 70200 Avg. Training loss: 0.9505 0.0071 sec/batch\n",
      "Epoch 4/50 Iteration: 70400 Avg. Training loss: 0.8898 0.0070 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 70600 Avg. Training loss: 0.8634 0.0076 sec/batch\n",
      "Epoch 4/50 Iteration: 70800 Avg. Training loss: 0.7228 0.0070 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 71000 Avg. Training loss: 0.8228 0.0071 sec/batch\n",
      "Epoch 4/50 Iteration: 71200 Avg. Training loss: 0.9242 0.0066 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 71400 Avg. Training loss: 0.8066 0.0068 sec/batch\n",
      "Epoch 4/50 Iteration: 71600 Avg. Training loss: 1.0297 0.0079 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 71800 Avg. Training loss: 0.9918 0.0069 sec/batch\n",
      "Epoch 4/50 Iteration: 72000 Avg. Training loss: 0.9185 0.0067 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 72200 Avg. Training loss: 0.7630 0.0069 sec/batch\n",
      "Epoch 4/50 Iteration: 72400 Avg. Training loss: 0.7127 0.0074 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 72600 Avg. Training loss: 0.9128 0.0073 sec/batch\n",
      "Epoch 5/50 Iteration: 72800 Avg. Training loss: 0.8171 0.0005 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 73000 Avg. Training loss: 0.9657 0.0073 sec/batch\n",
      "Epoch 5/50 Iteration: 73200 Avg. Training loss: 0.8468 0.0074 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 73400 Avg. Training loss: 0.7682 0.0071 sec/batch\n",
      "Epoch 5/50 Iteration: 73600 Avg. Training loss: 0.9097 0.0077 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 73800 Avg. Training loss: 0.8670 0.0073 sec/batch\n",
      "Epoch 5/50 Iteration: 74000 Avg. Training loss: 0.7452 0.0066 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 74200 Avg. Training loss: 1.0474 0.0073 sec/batch\n",
      "Epoch 5/50 Iteration: 74400 Avg. Training loss: 0.7328 0.0070 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 74600 Avg. Training loss: 0.7896 0.0067 sec/batch\n",
      "Epoch 5/50 Iteration: 74800 Avg. Training loss: 0.8777 0.0068 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 75000 Avg. Training loss: 0.9656 0.0068 sec/batch\n",
      "Epoch 5/50 Iteration: 75200 Avg. Training loss: 0.8306 0.0069 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 75400 Avg. Training loss: 0.7784 0.0069 sec/batch\n",
      "Epoch 5/50 Iteration: 75600 Avg. Training loss: 0.7891 0.0068 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 75800 Avg. Training loss: 0.9153 0.0067 sec/batch\n",
      "Epoch 5/50 Iteration: 76000 Avg. Training loss: 0.8307 0.0070 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 76200 Avg. Training loss: 0.8270 0.0073 sec/batch\n",
      "Epoch 5/50 Iteration: 76400 Avg. Training loss: 0.9033 0.0069 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 76600 Avg. Training loss: 0.9056 0.0066 sec/batch\n",
      "Epoch 5/50 Iteration: 76800 Avg. Training loss: 0.8345 0.0070 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 77000 Avg. Training loss: 0.7860 0.0065 sec/batch\n",
      "Epoch 5/50 Iteration: 77200 Avg. Training loss: 0.7168 0.0070 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 77400 Avg. Training loss: 0.7769 0.0067 sec/batch\n",
      "Epoch 5/50 Iteration: 77600 Avg. Training loss: 0.8034 0.0065 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 77800 Avg. Training loss: 0.8169 0.0072 sec/batch\n",
      "Epoch 5/50 Iteration: 78000 Avg. Training loss: 0.9657 0.0065 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 78200 Avg. Training loss: 0.8689 0.0072 sec/batch\n",
      "Epoch 5/50 Iteration: 78400 Avg. Training loss: 0.8118 0.0071 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 78600 Avg. Training loss: 0.7841 0.0074 sec/batch\n",
      "Epoch 5/50 Iteration: 78800 Avg. Training loss: 0.7189 0.0067 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 79000 Avg. Training loss: 0.7646 0.0067 sec/batch\n",
      "Epoch 5/50 Iteration: 79200 Avg. Training loss: 0.7645 0.0068 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 79400 Avg. Training loss: 0.9466 0.0068 sec/batch\n",
      "Epoch 5/50 Iteration: 79600 Avg. Training loss: 0.8000 0.0067 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 79800 Avg. Training loss: 0.7688 0.0068 sec/batch\n",
      "Epoch 5/50 Iteration: 80000 Avg. Training loss: 0.7643 0.0073 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 80200 Avg. Training loss: 0.7648 0.0077 sec/batch\n",
      "Epoch 5/50 Iteration: 80400 Avg. Training loss: 0.7833 0.0066 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 80600 Avg. Training loss: 0.8547 0.0066 sec/batch\n",
      "Epoch 5/50 Iteration: 80800 Avg. Training loss: 0.9428 0.0065 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 81000 Avg. Training loss: 0.7481 0.0068 sec/batch\n",
      "Epoch 5/50 Iteration: 81200 Avg. Training loss: 0.8868 0.0085 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 81400 Avg. Training loss: 0.8180 0.0066 sec/batch\n",
      "Epoch 5/50 Iteration: 81600 Avg. Training loss: 0.8920 0.0067 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 81800 Avg. Training loss: 0.8563 0.0068 sec/batch\n",
      "Epoch 5/50 Iteration: 82000 Avg. Training loss: 0.7613 0.0068 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 82200 Avg. Training loss: 0.8221 0.0081 sec/batch\n",
      "Epoch 5/50 Iteration: 82400 Avg. Training loss: 0.7133 0.0068 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 82600 Avg. Training loss: 0.6535 0.0068 sec/batch\n",
      "Epoch 5/50 Iteration: 82800 Avg. Training loss: 0.8367 0.0070 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 83000 Avg. Training loss: 0.7809 0.0074 sec/batch\n",
      "Epoch 5/50 Iteration: 83200 Avg. Training loss: 0.8332 0.0069 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 83400 Avg. Training loss: 0.8041 0.0070 sec/batch\n",
      "Epoch 5/50 Iteration: 83600 Avg. Training loss: 0.8743 0.0067 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 83800 Avg. Training loss: 0.8774 0.0070 sec/batch\n",
      "Epoch 5/50 Iteration: 84000 Avg. Training loss: 0.7674 0.0073 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 84200 Avg. Training loss: 0.8171 0.0069 sec/batch\n",
      "Epoch 5/50 Iteration: 84400 Avg. Training loss: 0.6774 0.0069 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 84600 Avg. Training loss: 0.8573 0.0069 sec/batch\n",
      "Epoch 5/50 Iteration: 84800 Avg. Training loss: 0.7894 0.0070 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 85000 Avg. Training loss: 0.7547 0.0070 sec/batch\n",
      "Epoch 5/50 Iteration: 85200 Avg. Training loss: 0.8010 0.0070 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 85400 Avg. Training loss: 0.8320 0.0071 sec/batch\n",
      "Epoch 5/50 Iteration: 85600 Avg. Training loss: 0.7814 0.0080 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 85800 Avg. Training loss: 0.7941 0.0072 sec/batch\n",
      "Epoch 5/50 Iteration: 86000 Avg. Training loss: 0.9625 0.0083 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 86200 Avg. Training loss: 0.6941 0.0071 sec/batch\n",
      "Epoch 5/50 Iteration: 86400 Avg. Training loss: 0.8024 0.0070 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 86600 Avg. Training loss: 0.8358 0.0068 sec/batch\n",
      "Epoch 5/50 Iteration: 86800 Avg. Training loss: 0.8851 0.0071 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 87000 Avg. Training loss: 0.8668 0.0071 sec/batch\n",
      "Epoch 5/50 Iteration: 87200 Avg. Training loss: 0.9041 0.0070 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 87400 Avg. Training loss: 0.7403 0.0071 sec/batch\n",
      "Epoch 5/50 Iteration: 87600 Avg. Training loss: 0.8520 0.0067 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 87800 Avg. Training loss: 0.9834 0.0069 sec/batch\n",
      "Epoch 5/50 Iteration: 88000 Avg. Training loss: 0.9654 0.0069 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 Iteration: 88200 Avg. Training loss: 0.7915 0.0069 sec/batch\n",
      "Epoch 5/50 Iteration: 88400 Avg. Training loss: 0.8807 0.0070 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 88600 Avg. Training loss: 0.8300 0.0069 sec/batch\n",
      "Epoch 5/50 Iteration: 88800 Avg. Training loss: 0.9651 0.0074 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 89000 Avg. Training loss: 0.6904 0.0068 sec/batch\n",
      "Epoch 5/50 Iteration: 89200 Avg. Training loss: 0.7561 0.0070 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 89400 Avg. Training loss: 0.9474 0.0067 sec/batch\n",
      "Epoch 5/50 Iteration: 89600 Avg. Training loss: 0.9884 0.0068 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 89800 Avg. Training loss: 0.9819 0.0079 sec/batch\n",
      "Epoch 5/50 Iteration: 90000 Avg. Training loss: 0.9337 0.0068 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 90200 Avg. Training loss: 0.7844 0.0069 sec/batch\n",
      "Epoch 5/50 Iteration: 90400 Avg. Training loss: 0.7898 0.0070 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 90600 Avg. Training loss: 0.7421 0.0075 sec/batch\n",
      "Epoch 5/50 Iteration: 90800 Avg. Training loss: 0.8356 0.0073 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 91000 Avg. Training loss: 0.8446 0.0005 sec/batch\n",
      "Epoch 6/50 Iteration: 91200 Avg. Training loss: 0.8574 0.0073 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 91400 Avg. Training loss: 0.8341 0.0074 sec/batch\n",
      "Epoch 6/50 Iteration: 91600 Avg. Training loss: 0.7427 0.0071 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 91800 Avg. Training loss: 0.8926 0.0078 sec/batch\n",
      "Epoch 6/50 Iteration: 92000 Avg. Training loss: 0.7749 0.0073 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 92200 Avg. Training loss: 0.7175 0.0067 sec/batch\n",
      "Epoch 6/50 Iteration: 92400 Avg. Training loss: 0.7496 0.0075 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 92600 Avg. Training loss: 0.6073 0.0071 sec/batch\n",
      "Epoch 6/50 Iteration: 92800 Avg. Training loss: 0.8522 0.0068 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 93000 Avg. Training loss: 0.8676 0.0069 sec/batch\n",
      "Epoch 6/50 Iteration: 93200 Avg. Training loss: 0.9634 0.0069 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 93400 Avg. Training loss: 0.7161 0.0071 sec/batch\n",
      "Epoch 6/50 Iteration: 93600 Avg. Training loss: 0.7174 0.0070 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 93800 Avg. Training loss: 0.8536 0.0070 sec/batch\n",
      "Epoch 6/50 Iteration: 94000 Avg. Training loss: 0.8505 0.0069 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 94200 Avg. Training loss: 0.9691 0.0071 sec/batch\n",
      "Epoch 6/50 Iteration: 94400 Avg. Training loss: 0.8058 0.0075 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 94600 Avg. Training loss: 0.7597 0.0070 sec/batch\n",
      "Epoch 6/50 Iteration: 94800 Avg. Training loss: 0.8070 0.0068 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 95000 Avg. Training loss: 0.8105 0.0072 sec/batch\n",
      "Epoch 6/50 Iteration: 95200 Avg. Training loss: 0.7341 0.0067 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 95400 Avg. Training loss: 0.7618 0.0072 sec/batch\n",
      "Epoch 6/50 Iteration: 95600 Avg. Training loss: 0.5687 0.0068 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 95800 Avg. Training loss: 0.6357 0.0068 sec/batch\n",
      "Epoch 6/50 Iteration: 96000 Avg. Training loss: 0.8438 0.0072 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 96200 Avg. Training loss: 0.8366 0.0068 sec/batch\n",
      "Epoch 6/50 Iteration: 96400 Avg. Training loss: 0.8387 0.0075 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 96600 Avg. Training loss: 0.8258 0.0073 sec/batch\n",
      "Epoch 6/50 Iteration: 96800 Avg. Training loss: 0.8008 0.0075 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 97000 Avg. Training loss: 0.6950 0.0073 sec/batch\n",
      "Epoch 6/50 Iteration: 97200 Avg. Training loss: 0.7613 0.0074 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 97400 Avg. Training loss: 0.7333 0.0070 sec/batch\n",
      "Epoch 6/50 Iteration: 97600 Avg. Training loss: 0.7750 0.0069 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 97800 Avg. Training loss: 0.8186 0.0067 sec/batch\n",
      "Epoch 6/50 Iteration: 98000 Avg. Training loss: 0.9469 0.0070 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 98200 Avg. Training loss: 0.8583 0.0069 sec/batch\n",
      "Epoch 6/50 Iteration: 98400 Avg. Training loss: 0.7576 0.0074 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 98600 Avg. Training loss: 0.6836 0.0068 sec/batch\n",
      "Epoch 6/50 Iteration: 98800 Avg. Training loss: 0.7701 0.0067 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 99000 Avg. Training loss: 0.7754 0.0067 sec/batch\n",
      "Epoch 6/50 Iteration: 99200 Avg. Training loss: 0.7703 0.0071 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 99400 Avg. Training loss: 0.8860 0.0087 sec/batch\n",
      "Epoch 6/50 Iteration: 99600 Avg. Training loss: 0.8900 0.0067 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 99800 Avg. Training loss: 0.9313 0.0070 sec/batch\n",
      "Epoch 6/50 Iteration: 100000 Avg. Training loss: 0.7481 0.0070 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 100200 Avg. Training loss: 0.9354 0.0071 sec/batch\n",
      "Epoch 6/50 Iteration: 100400 Avg. Training loss: 0.7778 0.0083 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 100600 Avg. Training loss: 0.7016 0.0070 sec/batch\n",
      "Epoch 6/50 Iteration: 100800 Avg. Training loss: 0.6791 0.0069 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 101000 Avg. Training loss: 0.7406 0.0073 sec/batch\n",
      "Epoch 6/50 Iteration: 101200 Avg. Training loss: 0.8929 0.0077 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 101400 Avg. Training loss: 0.8266 0.0072 sec/batch\n",
      "Epoch 6/50 Iteration: 101600 Avg. Training loss: 0.7487 0.0073 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 101800 Avg. Training loss: 0.8228 0.0068 sec/batch\n",
      "Epoch 6/50 Iteration: 102000 Avg. Training loss: 0.8262 0.0073 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 102200 Avg. Training loss: 0.7373 0.0072 sec/batch\n",
      "Epoch 6/50 Iteration: 102400 Avg. Training loss: 0.8202 0.0068 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 102600 Avg. Training loss: 0.7355 0.0068 sec/batch\n",
      "Epoch 6/50 Iteration: 102800 Avg. Training loss: 0.8885 0.0068 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 103000 Avg. Training loss: 0.6498 0.0069 sec/batch\n",
      "Epoch 6/50 Iteration: 103200 Avg. Training loss: 0.6484 0.0069 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 103400 Avg. Training loss: 0.8655 0.0072 sec/batch\n",
      "Epoch 6/50 Iteration: 103600 Avg. Training loss: 0.8352 0.0071 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 103800 Avg. Training loss: 0.7403 0.0082 sec/batch\n",
      "Epoch 6/50 Iteration: 104000 Avg. Training loss: 0.7716 0.0073 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 104200 Avg. Training loss: 0.8564 0.0083 sec/batch\n",
      "Epoch 6/50 Iteration: 104400 Avg. Training loss: 0.7277 0.0072 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 104600 Avg. Training loss: 0.7974 0.0071 sec/batch\n",
      "Epoch 6/50 Iteration: 104800 Avg. Training loss: 0.8835 0.0069 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 105000 Avg. Training loss: 0.8465 0.0074 sec/batch\n",
      "Epoch 6/50 Iteration: 105200 Avg. Training loss: 0.8538 0.0070 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 105400 Avg. Training loss: 0.8898 0.0069 sec/batch\n",
      "Epoch 6/50 Iteration: 105600 Avg. Training loss: 0.7741 0.0069 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 105800 Avg. Training loss: 0.7025 0.0066 sec/batch\n",
      "Epoch 6/50 Iteration: 106000 Avg. Training loss: 0.8781 0.0068 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 106200 Avg. Training loss: 0.8576 0.0068 sec/batch\n",
      "Epoch 6/50 Iteration: 106400 Avg. Training loss: 0.7810 0.0068 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 106600 Avg. Training loss: 0.9027 0.0069 sec/batch\n",
      "Epoch 6/50 Iteration: 106800 Avg. Training loss: 0.8410 0.0067 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 107000 Avg. Training loss: 0.7891 0.0072 sec/batch\n",
      "Epoch 6/50 Iteration: 107200 Avg. Training loss: 0.6205 0.0067 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 107400 Avg. Training loss: 0.7405 0.0069 sec/batch\n",
      "Epoch 6/50 Iteration: 107600 Avg. Training loss: 0.8872 0.0067 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 107800 Avg. Training loss: 0.8832 0.0068 sec/batch\n",
      "Epoch 6/50 Iteration: 108000 Avg. Training loss: 0.9783 0.0078 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 108200 Avg. Training loss: 0.9946 0.0066 sec/batch\n",
      "Epoch 6/50 Iteration: 108400 Avg. Training loss: 0.8558 0.0065 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 108600 Avg. Training loss: 0.7229 0.0070 sec/batch\n",
      "Epoch 6/50 Iteration: 108800 Avg. Training loss: 0.7826 0.0074 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 109000 Avg. Training loss: 0.8659 0.0073 sec/batch\n",
      "Epoch 7/50 Iteration: 109200 Avg. Training loss: 0.7872 0.0006 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 109400 Avg. Training loss: 0.8569 0.0072 sec/batch\n",
      "Epoch 7/50 Iteration: 109600 Avg. Training loss: 0.7107 0.0073 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 109800 Avg. Training loss: 0.6521 0.0070 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 Iteration: 110000 Avg. Training loss: 0.9661 0.0078 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 110200 Avg. Training loss: 0.7728 0.0072 sec/batch\n",
      "Epoch 7/50 Iteration: 110400 Avg. Training loss: 0.7921 0.0066 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 110600 Avg. Training loss: 0.8443 0.0074 sec/batch\n",
      "Epoch 7/50 Iteration: 110800 Avg. Training loss: 0.6679 0.0071 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 111000 Avg. Training loss: 0.7947 0.0066 sec/batch\n",
      "Epoch 7/50 Iteration: 111200 Avg. Training loss: 0.7385 0.0066 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 111400 Avg. Training loss: 0.8633 0.0070 sec/batch\n",
      "Epoch 7/50 Iteration: 111600 Avg. Training loss: 0.7499 0.0069 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 111800 Avg. Training loss: 0.7954 0.0070 sec/batch\n",
      "Epoch 7/50 Iteration: 112000 Avg. Training loss: 0.7753 0.0069 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 112200 Avg. Training loss: 0.8673 0.0068 sec/batch\n",
      "Epoch 7/50 Iteration: 112400 Avg. Training loss: 0.8354 0.0070 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 112600 Avg. Training loss: 0.6857 0.0074 sec/batch\n",
      "Epoch 7/50 Iteration: 112800 Avg. Training loss: 0.8021 0.0068 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 113000 Avg. Training loss: 0.9235 0.0067 sec/batch\n",
      "Epoch 7/50 Iteration: 113200 Avg. Training loss: 0.7124 0.0070 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 113400 Avg. Training loss: 0.6761 0.0066 sec/batch\n",
      "Epoch 7/50 Iteration: 113600 Avg. Training loss: 0.7279 0.0071 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 113800 Avg. Training loss: 0.6863 0.0069 sec/batch\n",
      "Epoch 7/50 Iteration: 114000 Avg. Training loss: 0.6253 0.0071 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 114200 Avg. Training loss: 0.8047 0.0074 sec/batch\n",
      "Epoch 7/50 Iteration: 114400 Avg. Training loss: 0.6593 0.0065 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 114600 Avg. Training loss: 0.7382 0.0072 sec/batch\n",
      "Epoch 7/50 Iteration: 114800 Avg. Training loss: 0.8444 0.0071 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 115000 Avg. Training loss: 0.7801 0.0073 sec/batch\n",
      "Epoch 7/50 Iteration: 115200 Avg. Training loss: 0.6537 0.0068 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 115400 Avg. Training loss: 0.7004 0.0068 sec/batch\n",
      "Epoch 7/50 Iteration: 115600 Avg. Training loss: 0.8726 0.0068 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 115800 Avg. Training loss: 0.7633 0.0068 sec/batch\n",
      "Epoch 7/50 Iteration: 116000 Avg. Training loss: 0.7759 0.0067 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 116200 Avg. Training loss: 0.8142 0.0070 sec/batch\n",
      "Epoch 7/50 Iteration: 116400 Avg. Training loss: 0.9513 0.0068 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 116600 Avg. Training loss: 0.7332 0.0073 sec/batch\n",
      "Epoch 7/50 Iteration: 116800 Avg. Training loss: 0.7500 0.0065 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 117000 Avg. Training loss: 0.7427 0.0065 sec/batch\n",
      "Epoch 7/50 Iteration: 117200 Avg. Training loss: 0.7650 0.0065 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 117400 Avg. Training loss: 0.8001 0.0069 sec/batch\n",
      "Epoch 7/50 Iteration: 117600 Avg. Training loss: 0.8221 0.0085 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 117800 Avg. Training loss: 0.8264 0.0065 sec/batch\n",
      "Epoch 7/50 Iteration: 118000 Avg. Training loss: 0.8671 0.0067 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 118200 Avg. Training loss: 0.9243 0.0069 sec/batch\n",
      "Epoch 7/50 Iteration: 118400 Avg. Training loss: 0.8142 0.0068 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 118600 Avg. Training loss: 0.9456 0.0082 sec/batch\n",
      "Epoch 7/50 Iteration: 118800 Avg. Training loss: 0.6635 0.0067 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 119000 Avg. Training loss: 0.6540 0.0066 sec/batch\n",
      "Epoch 7/50 Iteration: 119200 Avg. Training loss: 0.8149 0.0069 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 119400 Avg. Training loss: 0.8309 0.0074 sec/batch\n",
      "Epoch 7/50 Iteration: 119600 Avg. Training loss: 0.8456 0.0068 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 119800 Avg. Training loss: 0.7809 0.0069 sec/batch\n",
      "Epoch 7/50 Iteration: 120000 Avg. Training loss: 0.8669 0.0065 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 120200 Avg. Training loss: 0.7813 0.0070 sec/batch\n",
      "Epoch 7/50 Iteration: 120400 Avg. Training loss: 0.7333 0.0070 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 120600 Avg. Training loss: 0.7069 0.0067 sec/batch\n",
      "Epoch 7/50 Iteration: 120800 Avg. Training loss: 0.5703 0.0067 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 121000 Avg. Training loss: 0.8926 0.0067 sec/batch\n",
      "Epoch 7/50 Iteration: 121200 Avg. Training loss: 0.6970 0.0068 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 121400 Avg. Training loss: 0.7986 0.0068 sec/batch\n",
      "Epoch 7/50 Iteration: 121600 Avg. Training loss: 0.7163 0.0070 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 121800 Avg. Training loss: 0.6568 0.0071 sec/batch\n",
      "Epoch 7/50 Iteration: 122000 Avg. Training loss: 0.6514 0.0080 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 122200 Avg. Training loss: 0.7632 0.0070 sec/batch\n",
      "Epoch 7/50 Iteration: 122400 Avg. Training loss: 0.7984 0.0082 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 122600 Avg. Training loss: 0.6259 0.0070 sec/batch\n",
      "Epoch 7/50 Iteration: 122800 Avg. Training loss: 0.8477 0.0070 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 123000 Avg. Training loss: 0.8893 0.0066 sec/batch\n",
      "Epoch 7/50 Iteration: 123200 Avg. Training loss: 0.8468 0.0070 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 123400 Avg. Training loss: 0.7602 0.0070 sec/batch\n",
      "Epoch 7/50 Iteration: 123600 Avg. Training loss: 0.9047 0.0069 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 123800 Avg. Training loss: 0.7726 0.0070 sec/batch\n",
      "Epoch 7/50 Iteration: 124000 Avg. Training loss: 0.8086 0.0065 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 124200 Avg. Training loss: 0.8954 0.0068 sec/batch\n",
      "Epoch 7/50 Iteration: 124400 Avg. Training loss: 0.8534 0.0068 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 124600 Avg. Training loss: 0.7829 0.0069 sec/batch\n",
      "Epoch 7/50 Iteration: 124800 Avg. Training loss: 0.8030 0.0069 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 125000 Avg. Training loss: 0.7495 0.0067 sec/batch\n",
      "Epoch 7/50 Iteration: 125200 Avg. Training loss: 0.8088 0.0072 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 125400 Avg. Training loss: 0.6915 0.0067 sec/batch\n",
      "Epoch 7/50 Iteration: 125600 Avg. Training loss: 0.6101 0.0070 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 125800 Avg. Training loss: 0.8405 0.0066 sec/batch\n",
      "Epoch 7/50 Iteration: 126000 Avg. Training loss: 0.7190 0.0067 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 126200 Avg. Training loss: 0.9778 0.0078 sec/batch\n",
      "Epoch 7/50 Iteration: 126400 Avg. Training loss: 0.9261 0.0067 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 126600 Avg. Training loss: 0.6926 0.0066 sec/batch\n",
      "Epoch 7/50 Iteration: 126800 Avg. Training loss: 0.7736 0.0070 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 127000 Avg. Training loss: 0.6047 0.0073 sec/batch\n",
      "Epoch 7/50 Iteration: 127200 Avg. Training loss: 0.8094 0.0074 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 127400 Avg. Training loss: 0.8712 0.0008 sec/batch\n",
      "Epoch 8/50 Iteration: 127600 Avg. Training loss: 0.8400 0.0073 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 127800 Avg. Training loss: 0.6956 0.0074 sec/batch\n",
      "Epoch 8/50 Iteration: 128000 Avg. Training loss: 0.6257 0.0071 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 128200 Avg. Training loss: 0.8668 0.0078 sec/batch\n",
      "Epoch 8/50 Iteration: 128400 Avg. Training loss: 0.8108 0.0074 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 128600 Avg. Training loss: 0.8269 0.0068 sec/batch\n",
      "Epoch 8/50 Iteration: 128800 Avg. Training loss: 0.8012 0.0076 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 129000 Avg. Training loss: 0.6210 0.0071 sec/batch\n",
      "Epoch 8/50 Iteration: 129200 Avg. Training loss: 0.8095 0.0066 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 129400 Avg. Training loss: 0.8088 0.0068 sec/batch\n",
      "Epoch 8/50 Iteration: 129600 Avg. Training loss: 0.9712 0.0068 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 129800 Avg. Training loss: 0.6579 0.0072 sec/batch\n",
      "Epoch 8/50 Iteration: 130000 Avg. Training loss: 0.7599 0.0070 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 130200 Avg. Training loss: 0.7711 0.0069 sec/batch\n",
      "Epoch 8/50 Iteration: 130400 Avg. Training loss: 0.6957 0.0071 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 130600 Avg. Training loss: 0.8245 0.0075 sec/batch\n",
      "Epoch 8/50 Iteration: 130800 Avg. Training loss: 0.7393 0.0078 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 131000 Avg. Training loss: 0.8425 0.0074 sec/batch\n",
      "Epoch 8/50 Iteration: 131200 Avg. Training loss: 0.9133 0.0072 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 131400 Avg. Training loss: 0.7626 0.0074 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 Iteration: 131600 Avg. Training loss: 0.6525 0.0068 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 131800 Avg. Training loss: 0.6678 0.0073 sec/batch\n",
      "Epoch 8/50 Iteration: 132000 Avg. Training loss: 0.6259 0.0070 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 132200 Avg. Training loss: 0.7533 0.0067 sec/batch\n",
      "Epoch 8/50 Iteration: 132400 Avg. Training loss: 0.7447 0.0072 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 132600 Avg. Training loss: 0.8101 0.0068 sec/batch\n",
      "Epoch 8/50 Iteration: 132800 Avg. Training loss: 0.8285 0.0075 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 133000 Avg. Training loss: 0.8438 0.0073 sec/batch\n",
      "Epoch 8/50 Iteration: 133200 Avg. Training loss: 0.7232 0.0074 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 133400 Avg. Training loss: 0.5923 0.0069 sec/batch\n",
      "Epoch 8/50 Iteration: 133600 Avg. Training loss: 0.7437 0.0068 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 133800 Avg. Training loss: 0.6679 0.0071 sec/batch\n",
      "Epoch 8/50 Iteration: 134000 Avg. Training loss: 0.9106 0.0069 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 134200 Avg. Training loss: 0.7605 0.0068 sec/batch\n",
      "Epoch 8/50 Iteration: 134400 Avg. Training loss: 0.8515 0.0070 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 134600 Avg. Training loss: 0.8946 0.0069 sec/batch\n",
      "Epoch 8/50 Iteration: 134800 Avg. Training loss: 0.6260 0.0074 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 135000 Avg. Training loss: 0.7869 0.0067 sec/batch\n",
      "Epoch 8/50 Iteration: 135200 Avg. Training loss: 0.6551 0.0066 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 135400 Avg. Training loss: 0.7724 0.0067 sec/batch\n",
      "Epoch 8/50 Iteration: 135600 Avg. Training loss: 0.8135 0.0072 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 135800 Avg. Training loss: 0.7906 0.0085 sec/batch\n",
      "Epoch 8/50 Iteration: 136000 Avg. Training loss: 0.8343 0.0068 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 136200 Avg. Training loss: 0.8241 0.0068 sec/batch\n",
      "Epoch 8/50 Iteration: 136400 Avg. Training loss: 0.9369 0.0068 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 136600 Avg. Training loss: 0.8446 0.0070 sec/batch\n",
      "Epoch 8/50 Iteration: 136800 Avg. Training loss: 0.8407 0.0082 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 137000 Avg. Training loss: 0.6672 0.0069 sec/batch\n",
      "Epoch 8/50 Iteration: 137200 Avg. Training loss: 0.6043 0.0067 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 137400 Avg. Training loss: 0.8647 0.0069 sec/batch\n",
      "Epoch 8/50 Iteration: 137600 Avg. Training loss: 0.8158 0.0074 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 137800 Avg. Training loss: 0.7026 0.0070 sec/batch\n",
      "Epoch 8/50 Iteration: 138000 Avg. Training loss: 0.8230 0.0070 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 138200 Avg. Training loss: 0.8178 0.0068 sec/batch\n",
      "Epoch 8/50 Iteration: 138400 Avg. Training loss: 0.8937 0.0071 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 138600 Avg. Training loss: 0.7464 0.0073 sec/batch\n",
      "Epoch 8/50 Iteration: 138800 Avg. Training loss: 0.7079 0.0068 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 139000 Avg. Training loss: 0.7259 0.0068 sec/batch\n",
      "Epoch 8/50 Iteration: 139200 Avg. Training loss: 0.7964 0.0068 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 139400 Avg. Training loss: 0.6336 0.0069 sec/batch\n",
      "Epoch 8/50 Iteration: 139600 Avg. Training loss: 0.5941 0.0070 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 139800 Avg. Training loss: 0.7026 0.0070 sec/batch\n",
      "Epoch 8/50 Iteration: 140000 Avg. Training loss: 0.8226 0.0070 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 140200 Avg. Training loss: 0.6326 0.0080 sec/batch\n",
      "Epoch 8/50 Iteration: 140400 Avg. Training loss: 0.7349 0.0071 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 140600 Avg. Training loss: 0.7019 0.0084 sec/batch\n",
      "Epoch 8/50 Iteration: 140800 Avg. Training loss: 0.6212 0.0072 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 141000 Avg. Training loss: 0.7814 0.0071 sec/batch\n",
      "Epoch 8/50 Iteration: 141200 Avg. Training loss: 0.8952 0.0068 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 141400 Avg. Training loss: 0.7564 0.0071 sec/batch\n",
      "Epoch 8/50 Iteration: 141600 Avg. Training loss: 0.8165 0.0070 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 141800 Avg. Training loss: 0.7505 0.0070 sec/batch\n",
      "Epoch 8/50 Iteration: 142000 Avg. Training loss: 0.7962 0.0069 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 142200 Avg. Training loss: 0.6577 0.0067 sec/batch\n",
      "Epoch 8/50 Iteration: 142400 Avg. Training loss: 0.8643 0.0069 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 142600 Avg. Training loss: 0.8199 0.0069 sec/batch\n",
      "Epoch 8/50 Iteration: 142800 Avg. Training loss: 0.7841 0.0069 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 143000 Avg. Training loss: 0.7958 0.0069 sec/batch\n",
      "Epoch 8/50 Iteration: 143200 Avg. Training loss: 0.8108 0.0070 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 143400 Avg. Training loss: 0.8272 0.0074 sec/batch\n",
      "Epoch 8/50 Iteration: 143600 Avg. Training loss: 0.6184 0.0068 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 143800 Avg. Training loss: 0.7442 0.0071 sec/batch\n",
      "Epoch 8/50 Iteration: 144000 Avg. Training loss: 0.9587 0.0067 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 144200 Avg. Training loss: 0.6880 0.0069 sec/batch\n",
      "Epoch 8/50 Iteration: 144400 Avg. Training loss: 0.9879 0.0078 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 144600 Avg. Training loss: 0.8865 0.0068 sec/batch\n",
      "Epoch 8/50 Iteration: 144800 Avg. Training loss: 0.7898 0.0067 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 145000 Avg. Training loss: 0.7091 0.0069 sec/batch\n",
      "Epoch 8/50 Iteration: 145200 Avg. Training loss: 0.6238 0.0076 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 145400 Avg. Training loss: 0.7294 0.0072 sec/batch\n",
      "Epoch 9/50 Iteration: 145600 Avg. Training loss: 0.7512 0.0009 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 145800 Avg. Training loss: 0.9876 0.0072 sec/batch\n",
      "Epoch 9/50 Iteration: 146000 Avg. Training loss: 0.9146 0.0073 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 146200 Avg. Training loss: 0.6163 0.0071 sec/batch\n",
      "Epoch 9/50 Iteration: 146400 Avg. Training loss: 0.8762 0.0077 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 146600 Avg. Training loss: 0.8455 0.0072 sec/batch\n",
      "Epoch 9/50 Iteration: 146800 Avg. Training loss: 0.7509 0.0067 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 147000 Avg. Training loss: 0.8002 0.0074 sec/batch\n",
      "Epoch 9/50 Iteration: 147200 Avg. Training loss: 0.5146 0.0070 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 147400 Avg. Training loss: 0.8482 0.0067 sec/batch\n",
      "Epoch 9/50 Iteration: 147600 Avg. Training loss: 0.7759 0.0067 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 147800 Avg. Training loss: 0.8698 0.0070 sec/batch\n",
      "Epoch 9/50 Iteration: 148000 Avg. Training loss: 0.6441 0.0074 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 148200 Avg. Training loss: 0.5828 0.0073 sec/batch\n",
      "Epoch 9/50 Iteration: 148400 Avg. Training loss: 0.7215 0.0071 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 148600 Avg. Training loss: 0.7511 0.0069 sec/batch\n",
      "Epoch 9/50 Iteration: 148800 Avg. Training loss: 0.7473 0.0070 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 149000 Avg. Training loss: 0.6992 0.0075 sec/batch\n",
      "Epoch 9/50 Iteration: 149200 Avg. Training loss: 0.7976 0.0068 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 149400 Avg. Training loss: 0.8385 0.0067 sec/batch\n",
      "Epoch 9/50 Iteration: 149600 Avg. Training loss: 0.8058 0.0071 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 149800 Avg. Training loss: 0.6417 0.0066 sec/batch\n",
      "Epoch 9/50 Iteration: 150000 Avg. Training loss: 0.6741 0.0072 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 150200 Avg. Training loss: 0.7467 0.0067 sec/batch\n",
      "Epoch 9/50 Iteration: 150400 Avg. Training loss: 0.6254 0.0065 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 150600 Avg. Training loss: 0.8074 0.0070 sec/batch\n",
      "Epoch 9/50 Iteration: 150800 Avg. Training loss: 0.7283 0.0065 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 151000 Avg. Training loss: 0.7393 0.0073 sec/batch\n",
      "Epoch 9/50 Iteration: 151200 Avg. Training loss: 0.8336 0.0070 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 151400 Avg. Training loss: 0.8562 0.0074 sec/batch\n",
      "Epoch 9/50 Iteration: 151600 Avg. Training loss: 0.6342 0.0067 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 151800 Avg. Training loss: 0.7405 0.0069 sec/batch\n",
      "Epoch 9/50 Iteration: 152000 Avg. Training loss: 0.7069 0.0069 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 152200 Avg. Training loss: 0.7992 0.0068 sec/batch\n",
      "Epoch 9/50 Iteration: 152400 Avg. Training loss: 0.7548 0.0068 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 152600 Avg. Training loss: 0.7737 0.0070 sec/batch\n",
      "Epoch 9/50 Iteration: 152800 Avg. Training loss: 0.8005 0.0068 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 153000 Avg. Training loss: 0.6370 0.0073 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 Iteration: 153200 Avg. Training loss: 0.6657 0.0066 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 153400 Avg. Training loss: 0.6289 0.0065 sec/batch\n",
      "Epoch 9/50 Iteration: 153600 Avg. Training loss: 0.7814 0.0066 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 153800 Avg. Training loss: 0.5889 0.0070 sec/batch\n",
      "Epoch 9/50 Iteration: 154000 Avg. Training loss: 0.8359 0.0084 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 154200 Avg. Training loss: 0.6996 0.0066 sec/batch\n",
      "Epoch 9/50 Iteration: 154400 Avg. Training loss: 0.8602 0.0066 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 154600 Avg. Training loss: 0.8237 0.0068 sec/batch\n",
      "Epoch 9/50 Iteration: 154800 Avg. Training loss: 0.7560 0.0068 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 155000 Avg. Training loss: 0.8884 0.0080 sec/batch\n",
      "Epoch 9/50 Iteration: 155200 Avg. Training loss: 0.7622 0.0068 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 155400 Avg. Training loss: 0.6012 0.0066 sec/batch\n",
      "Epoch 9/50 Iteration: 155600 Avg. Training loss: 0.8391 0.0069 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 155800 Avg. Training loss: 0.7916 0.0073 sec/batch\n",
      "Epoch 9/50 Iteration: 156000 Avg. Training loss: 0.7921 0.0068 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 156200 Avg. Training loss: 0.7926 0.0070 sec/batch\n",
      "Epoch 9/50 Iteration: 156400 Avg. Training loss: 0.8702 0.0066 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 156600 Avg. Training loss: 0.7612 0.0070 sec/batch\n",
      "Epoch 9/50 Iteration: 156800 Avg. Training loss: 0.6723 0.0071 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 157000 Avg. Training loss: 0.6688 0.0066 sec/batch\n",
      "Epoch 9/50 Iteration: 157200 Avg. Training loss: 0.6516 0.0068 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 157400 Avg. Training loss: 0.7394 0.0068 sec/batch\n",
      "Epoch 9/50 Iteration: 157600 Avg. Training loss: 0.7398 0.0067 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 157800 Avg. Training loss: 0.7627 0.0196 sec/batch\n",
      "Epoch 9/50 Iteration: 158000 Avg. Training loss: 0.8274 0.0081 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 158200 Avg. Training loss: 0.7615 0.0077 sec/batch\n",
      "Epoch 9/50 Iteration: 158400 Avg. Training loss: 0.7525 0.0078 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 158600 Avg. Training loss: 0.8307 0.0069 sec/batch\n",
      "Epoch 9/50 Iteration: 158800 Avg. Training loss: 0.7218 0.0084 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 159000 Avg. Training loss: 0.5859 0.0069 sec/batch\n",
      "Epoch 9/50 Iteration: 159200 Avg. Training loss: 0.8708 0.0070 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 159400 Avg. Training loss: 0.7941 0.0066 sec/batch\n",
      "Epoch 9/50 Iteration: 159600 Avg. Training loss: 0.8237 0.0071 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 159800 Avg. Training loss: 0.9048 0.0071 sec/batch\n",
      "Epoch 9/50 Iteration: 160000 Avg. Training loss: 0.9337 0.0070 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 160200 Avg. Training loss: 0.8127 0.0069 sec/batch\n",
      "Epoch 9/50 Iteration: 160400 Avg. Training loss: 0.6245 0.0066 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 160600 Avg. Training loss: 0.9334 0.0068 sec/batch\n",
      "Epoch 9/50 Iteration: 160800 Avg. Training loss: 0.8717 0.0068 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 161000 Avg. Training loss: 0.7302 0.0069 sec/batch\n",
      "Epoch 9/50 Iteration: 161200 Avg. Training loss: 0.8115 0.0069 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 161400 Avg. Training loss: 0.8641 0.0068 sec/batch\n",
      "Epoch 9/50 Iteration: 161600 Avg. Training loss: 0.8457 0.0073 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 161800 Avg. Training loss: 0.6160 0.0066 sec/batch\n",
      "Epoch 9/50 Iteration: 162000 Avg. Training loss: 0.6128 0.0069 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 162200 Avg. Training loss: 0.8540 0.0065 sec/batch\n",
      "Epoch 9/50 Iteration: 162400 Avg. Training loss: 0.8468 0.0068 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 162600 Avg. Training loss: 0.9897 0.0078 sec/batch\n",
      "Epoch 9/50 Iteration: 162800 Avg. Training loss: 0.8801 0.0066 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 163000 Avg. Training loss: 0.7080 0.0067 sec/batch\n",
      "Epoch 9/50 Iteration: 163200 Avg. Training loss: 0.7578 0.0069 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 163400 Avg. Training loss: 0.6071 0.0077 sec/batch\n",
      "Epoch 9/50 Iteration: 163600 Avg. Training loss: 0.8506 0.0073 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 163800 Avg. Training loss: 0.7467 0.0010 sec/batch\n",
      "Epoch 10/50 Iteration: 164000 Avg. Training loss: 0.8762 0.0073 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 164200 Avg. Training loss: 0.7160 0.0073 sec/batch\n",
      "Epoch 10/50 Iteration: 164400 Avg. Training loss: 0.6036 0.0072 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 164600 Avg. Training loss: 1.0263 0.0082 sec/batch\n",
      "Epoch 10/50 Iteration: 164800 Avg. Training loss: 0.7450 0.0075 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 165000 Avg. Training loss: 0.7602 0.0067 sec/batch\n",
      "Epoch 10/50 Iteration: 165200 Avg. Training loss: 0.7473 0.0075 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 165400 Avg. Training loss: 0.5951 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 165600 Avg. Training loss: 0.8354 0.0066 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 165800 Avg. Training loss: 0.8375 0.0068 sec/batch\n",
      "Epoch 10/50 Iteration: 166000 Avg. Training loss: 0.9002 0.0069 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 166200 Avg. Training loss: 0.7088 0.0072 sec/batch\n",
      "Epoch 10/50 Iteration: 166400 Avg. Training loss: 0.6972 0.0067 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 166600 Avg. Training loss: 0.6484 0.0068 sec/batch\n",
      "Epoch 10/50 Iteration: 166800 Avg. Training loss: 0.9836 0.0067 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 167000 Avg. Training loss: 0.8613 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 167200 Avg. Training loss: 0.8165 0.0075 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 167400 Avg. Training loss: 0.8023 0.0068 sec/batch\n",
      "Epoch 10/50 Iteration: 167600 Avg. Training loss: 0.8170 0.0067 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 167800 Avg. Training loss: 0.7388 0.0071 sec/batch\n",
      "Epoch 10/50 Iteration: 168000 Avg. Training loss: 0.6149 0.0065 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 168200 Avg. Training loss: 0.6787 0.0073 sec/batch\n",
      "Epoch 10/50 Iteration: 168400 Avg. Training loss: 0.6003 0.0067 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 168600 Avg. Training loss: 0.7082 0.0066 sec/batch\n",
      "Epoch 10/50 Iteration: 168800 Avg. Training loss: 0.7463 0.0071 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 169000 Avg. Training loss: 0.6711 0.0066 sec/batch\n",
      "Epoch 10/50 Iteration: 169200 Avg. Training loss: 0.6850 0.0073 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 169400 Avg. Training loss: 0.8508 0.0071 sec/batch\n",
      "Epoch 10/50 Iteration: 169600 Avg. Training loss: 0.8018 0.0072 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 169800 Avg. Training loss: 0.6200 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 170000 Avg. Training loss: 0.6237 0.0070 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 170200 Avg. Training loss: 0.6212 0.0069 sec/batch\n",
      "Epoch 10/50 Iteration: 170400 Avg. Training loss: 0.7634 0.0068 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 170600 Avg. Training loss: 0.7421 0.0069 sec/batch\n",
      "Epoch 10/50 Iteration: 170800 Avg. Training loss: 0.7418 0.0070 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 171000 Avg. Training loss: 0.9034 0.0068 sec/batch\n",
      "Epoch 10/50 Iteration: 171200 Avg. Training loss: 0.6459 0.0073 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 171400 Avg. Training loss: 0.5907 0.0067 sec/batch\n",
      "Epoch 10/50 Iteration: 171600 Avg. Training loss: 0.5879 0.0066 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 171800 Avg. Training loss: 0.8122 0.0066 sec/batch\n",
      "Epoch 10/50 Iteration: 172000 Avg. Training loss: 0.8007 0.0070 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 172200 Avg. Training loss: 0.7099 0.0084 sec/batch\n",
      "Epoch 10/50 Iteration: 172400 Avg. Training loss: 0.8654 0.0065 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 172600 Avg. Training loss: 0.8556 0.0068 sec/batch\n",
      "Epoch 10/50 Iteration: 172800 Avg. Training loss: 0.7776 0.0069 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 173000 Avg. Training loss: 0.7824 0.0068 sec/batch\n",
      "Epoch 10/50 Iteration: 173200 Avg. Training loss: 0.9240 0.0080 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 173400 Avg. Training loss: 0.7713 0.0067 sec/batch\n",
      "Epoch 10/50 Iteration: 173600 Avg. Training loss: 0.4732 0.0068 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 173800 Avg. Training loss: 0.8465 0.0068 sec/batch\n",
      "Epoch 10/50 Iteration: 174000 Avg. Training loss: 0.8372 0.0074 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 174200 Avg. Training loss: 0.8886 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 174400 Avg. Training loss: 0.7114 0.0068 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 174600 Avg. Training loss: 0.7683 0.0066 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 Iteration: 174800 Avg. Training loss: 0.8267 0.0070 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 175000 Avg. Training loss: 0.7459 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 175200 Avg. Training loss: 0.7823 0.0066 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 175400 Avg. Training loss: 0.6182 0.0066 sec/batch\n",
      "Epoch 10/50 Iteration: 175600 Avg. Training loss: 0.7312 0.0067 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 175800 Avg. Training loss: 0.6956 0.0067 sec/batch\n",
      "Epoch 10/50 Iteration: 176000 Avg. Training loss: 0.7356 0.0069 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 176200 Avg. Training loss: 0.8755 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 176400 Avg. Training loss: 0.8368 0.0070 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 176600 Avg. Training loss: 0.7350 0.0079 sec/batch\n",
      "Epoch 10/50 Iteration: 176800 Avg. Training loss: 0.8178 0.0069 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 177000 Avg. Training loss: 0.8233 0.0084 sec/batch\n",
      "Epoch 10/50 Iteration: 177200 Avg. Training loss: 0.6432 0.0070 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 177400 Avg. Training loss: 0.7802 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 177600 Avg. Training loss: 0.8091 0.0068 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 177800 Avg. Training loss: 0.8483 0.0072 sec/batch\n",
      "Epoch 10/50 Iteration: 178000 Avg. Training loss: 1.0029 0.0071 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 178200 Avg. Training loss: 0.9624 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 178400 Avg. Training loss: 0.6737 0.0070 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 178600 Avg. Training loss: 0.7777 0.0068 sec/batch\n",
      "Epoch 10/50 Iteration: 178800 Avg. Training loss: 0.7625 0.0069 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 179000 Avg. Training loss: 0.8941 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 179200 Avg. Training loss: 0.6673 0.0070 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 179400 Avg. Training loss: 0.9497 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 179600 Avg. Training loss: 0.8050 0.0070 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 179800 Avg. Training loss: 0.7780 0.0074 sec/batch\n",
      "Epoch 10/50 Iteration: 180000 Avg. Training loss: 0.6829 0.0068 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 180200 Avg. Training loss: 0.6752 0.0071 sec/batch\n",
      "Epoch 10/50 Iteration: 180400 Avg. Training loss: 0.7012 0.0068 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 180600 Avg. Training loss: 0.8115 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 180800 Avg. Training loss: 0.8242 0.0078 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 181000 Avg. Training loss: 0.8744 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 181200 Avg. Training loss: 0.6816 0.0069 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 181400 Avg. Training loss: 0.7372 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 181600 Avg. Training loss: 0.7497 0.0082 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 181800 Avg. Training loss: 0.8462 0.0077 sec/batch\n",
      "Epoch 11/50 Iteration: 182000 Avg. Training loss: 0.7469 0.0011 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 182200 Avg. Training loss: 0.9287 0.0073 sec/batch\n",
      "Epoch 11/50 Iteration: 182400 Avg. Training loss: 0.8237 0.0074 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 182600 Avg. Training loss: 0.6203 0.0071 sec/batch\n",
      "Epoch 11/50 Iteration: 182800 Avg. Training loss: 0.8648 0.0078 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 183000 Avg. Training loss: 0.7846 0.0074 sec/batch\n",
      "Epoch 11/50 Iteration: 183200 Avg. Training loss: 0.7900 0.0068 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 183400 Avg. Training loss: 0.7947 0.0076 sec/batch\n",
      "Epoch 11/50 Iteration: 183600 Avg. Training loss: 0.6057 0.0071 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 183800 Avg. Training loss: 0.8317 0.0068 sec/batch\n",
      "Epoch 11/50 Iteration: 184000 Avg. Training loss: 0.8929 0.0069 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 184200 Avg. Training loss: 0.8699 0.0070 sec/batch\n",
      "Epoch 11/50 Iteration: 184400 Avg. Training loss: 0.6991 0.0072 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 184600 Avg. Training loss: 0.6381 0.0069 sec/batch\n",
      "Epoch 11/50 Iteration: 184800 Avg. Training loss: 0.7544 0.0070 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 185000 Avg. Training loss: 0.6812 0.0069 sec/batch\n",
      "Epoch 11/50 Iteration: 185200 Avg. Training loss: 0.8535 0.0072 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 185400 Avg. Training loss: 0.6691 0.0076 sec/batch\n",
      "Epoch 11/50 Iteration: 185600 Avg. Training loss: 0.9368 0.0070 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 185800 Avg. Training loss: 0.8471 0.0068 sec/batch\n",
      "Epoch 11/50 Iteration: 186000 Avg. Training loss: 0.7434 0.0072 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 186200 Avg. Training loss: 0.6837 0.0068 sec/batch\n",
      "Epoch 11/50 Iteration: 186400 Avg. Training loss: 0.6386 0.0074 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 186600 Avg. Training loss: 0.6006 0.0067 sec/batch\n",
      "Epoch 11/50 Iteration: 186800 Avg. Training loss: 0.6464 0.0068 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 187000 Avg. Training loss: 0.8359 0.0072 sec/batch\n",
      "Epoch 11/50 Iteration: 187200 Avg. Training loss: 0.8397 0.0067 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 187400 Avg. Training loss: 0.7239 0.0075 sec/batch\n",
      "Epoch 11/50 Iteration: 187600 Avg. Training loss: 0.8644 0.0071 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 187800 Avg. Training loss: 0.7643 0.0075 sec/batch\n",
      "Epoch 11/50 Iteration: 188000 Avg. Training loss: 0.5897 0.0069 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 188200 Avg. Training loss: 0.7713 0.0071 sec/batch\n",
      "Epoch 11/50 Iteration: 188400 Avg. Training loss: 0.7267 0.0071 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 188600 Avg. Training loss: 0.7283 0.0070 sec/batch\n",
      "Epoch 11/50 Iteration: 188800 Avg. Training loss: 0.6123 0.0069 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 189000 Avg. Training loss: 0.8835 0.0070 sec/batch\n",
      "Epoch 11/50 Iteration: 189200 Avg. Training loss: 0.7455 0.0070 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 189400 Avg. Training loss: 0.7551 0.0075 sec/batch\n",
      "Epoch 11/50 Iteration: 189600 Avg. Training loss: 0.6694 0.0068 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 189800 Avg. Training loss: 0.6506 0.0067 sec/batch\n",
      "Epoch 11/50 Iteration: 190000 Avg. Training loss: 0.7956 0.0067 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 190200 Avg. Training loss: 0.7581 0.0072 sec/batch\n",
      "Epoch 11/50 Iteration: 190400 Avg. Training loss: 0.7904 0.0084 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 190600 Avg. Training loss: 0.9080 0.0067 sec/batch\n",
      "Epoch 11/50 Iteration: 190800 Avg. Training loss: 0.9022 0.0069 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 191000 Avg. Training loss: 0.7929 0.0069 sec/batch\n",
      "Epoch 11/50 Iteration: 191200 Avg. Training loss: 0.7822 0.0070 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 191400 Avg. Training loss: 0.8843 0.0082 sec/batch\n",
      "Epoch 11/50 Iteration: 191600 Avg. Training loss: 0.7204 0.0069 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 191800 Avg. Training loss: 0.5991 0.0068 sec/batch\n",
      "Epoch 11/50 Iteration: 192000 Avg. Training loss: 0.7088 0.0069 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 192200 Avg. Training loss: 0.7874 0.0074 sec/batch\n",
      "Epoch 11/50 Iteration: 192400 Avg. Training loss: 0.8508 0.0070 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 192600 Avg. Training loss: 0.7924 0.0070 sec/batch\n",
      "Epoch 11/50 Iteration: 192800 Avg. Training loss: 0.7429 0.0066 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 193000 Avg. Training loss: 0.6892 0.0071 sec/batch\n",
      "Epoch 11/50 Iteration: 193200 Avg. Training loss: 0.8292 0.0071 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 193400 Avg. Training loss: 0.7749 0.0068 sec/batch\n",
      "Epoch 11/50 Iteration: 193600 Avg. Training loss: 0.6251 0.0069 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 193800 Avg. Training loss: 0.7998 0.0069 sec/batch\n",
      "Epoch 11/50 Iteration: 194000 Avg. Training loss: 0.7812 0.0069 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 194200 Avg. Training loss: 0.6992 0.0070 sec/batch\n",
      "Epoch 11/50 Iteration: 194400 Avg. Training loss: 0.7624 0.0069 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 194600 Avg. Training loss: 0.6499 0.0072 sec/batch\n",
      "Epoch 11/50 Iteration: 194800 Avg. Training loss: 0.8863 0.0081 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 195000 Avg. Training loss: 0.9517 0.0072 sec/batch\n",
      "Epoch 11/50 Iteration: 195200 Avg. Training loss: 0.7822 0.0084 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 195400 Avg. Training loss: 0.6977 0.0072 sec/batch\n",
      "Epoch 11/50 Iteration: 195600 Avg. Training loss: 0.8516 0.0073 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 195800 Avg. Training loss: 0.9260 0.0067 sec/batch\n",
      "Epoch 11/50 Iteration: 196000 Avg. Training loss: 0.6463 0.0072 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 Iteration: 196200 Avg. Training loss: 0.7076 0.0072 sec/batch\n",
      "Epoch 11/50 Iteration: 196400 Avg. Training loss: 0.9318 0.0071 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 196600 Avg. Training loss: 0.7050 0.0071 sec/batch\n",
      "Epoch 11/50 Iteration: 196800 Avg. Training loss: 0.6602 0.0068 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 197000 Avg. Training loss: 0.6913 0.0070 sec/batch\n",
      "Epoch 11/50 Iteration: 197200 Avg. Training loss: 0.9804 0.0069 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 197400 Avg. Training loss: 0.7760 0.0070 sec/batch\n",
      "Epoch 11/50 Iteration: 197600 Avg. Training loss: 0.8643 0.0069 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 197800 Avg. Training loss: 0.8909 0.0071 sec/batch\n",
      "Epoch 11/50 Iteration: 198000 Avg. Training loss: 0.8324 0.0073 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 198200 Avg. Training loss: 0.5778 0.0069 sec/batch\n",
      "Epoch 11/50 Iteration: 198400 Avg. Training loss: 0.6970 0.0074 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 198600 Avg. Training loss: 0.7986 0.0072 sec/batch\n",
      "Epoch 11/50 Iteration: 198800 Avg. Training loss: 0.8847 0.0073 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 199000 Avg. Training loss: 0.8827 0.0078 sec/batch\n",
      "Epoch 11/50 Iteration: 199200 Avg. Training loss: 0.8309 0.0068 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 199400 Avg. Training loss: 0.7097 0.0068 sec/batch\n",
      "Epoch 11/50 Iteration: 199600 Avg. Training loss: 0.6682 0.0070 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 199800 Avg. Training loss: 0.7637 0.0078 sec/batch\n",
      "Epoch 11/50 Iteration: 200000 Avg. Training loss: 0.6933 0.0072 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 200200 Avg. Training loss: 0.8388 0.0013 sec/batch\n",
      "Epoch 12/50 Iteration: 200400 Avg. Training loss: 0.7503 0.0073 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 200600 Avg. Training loss: 0.6691 0.0074 sec/batch\n",
      "Epoch 12/50 Iteration: 200800 Avg. Training loss: 0.5707 0.0071 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 201000 Avg. Training loss: 1.0178 0.0078 sec/batch\n",
      "Epoch 12/50 Iteration: 201200 Avg. Training loss: 0.8088 0.0073 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 201400 Avg. Training loss: 0.7338 0.0067 sec/batch\n",
      "Epoch 12/50 Iteration: 201600 Avg. Training loss: 0.6909 0.0074 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 201800 Avg. Training loss: 0.6060 0.0072 sec/batch\n",
      "Epoch 12/50 Iteration: 202000 Avg. Training loss: 0.7982 0.0067 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 202200 Avg. Training loss: 1.0449 0.0068 sec/batch\n",
      "Epoch 12/50 Iteration: 202400 Avg. Training loss: 0.9019 0.0069 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 202600 Avg. Training loss: 0.7097 0.0073 sec/batch\n",
      "Epoch 12/50 Iteration: 202800 Avg. Training loss: 0.5936 0.0068 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 203000 Avg. Training loss: 0.7956 0.0070 sec/batch\n",
      "Epoch 12/50 Iteration: 203200 Avg. Training loss: 0.8197 0.0069 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 203400 Avg. Training loss: 0.8332 0.0073 sec/batch\n",
      "Epoch 12/50 Iteration: 203600 Avg. Training loss: 0.7832 0.0076 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 203800 Avg. Training loss: 0.8711 0.0075 sec/batch\n",
      "Epoch 12/50 Iteration: 204000 Avg. Training loss: 0.8232 0.0076 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 204200 Avg. Training loss: 0.7591 0.0079 sec/batch\n",
      "Epoch 12/50 Iteration: 204400 Avg. Training loss: 0.6804 0.0069 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 204600 Avg. Training loss: 0.6626 0.0074 sec/batch\n",
      "Epoch 12/50 Iteration: 204800 Avg. Training loss: 0.7187 0.0068 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 205000 Avg. Training loss: 0.5077 0.0068 sec/batch\n",
      "Epoch 12/50 Iteration: 205200 Avg. Training loss: 0.7587 0.0073 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 205400 Avg. Training loss: 0.6300 0.0066 sec/batch\n",
      "Epoch 12/50 Iteration: 205600 Avg. Training loss: 0.8682 0.0075 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 205800 Avg. Training loss: 0.8314 0.0070 sec/batch\n",
      "Epoch 12/50 Iteration: 206000 Avg. Training loss: 0.6547 0.0074 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 206200 Avg. Training loss: 0.6980 0.0069 sec/batch\n",
      "Epoch 12/50 Iteration: 206400 Avg. Training loss: 0.6809 0.0070 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 206600 Avg. Training loss: 0.6644 0.0069 sec/batch\n",
      "Epoch 12/50 Iteration: 206800 Avg. Training loss: 0.8847 0.0069 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 207000 Avg. Training loss: 0.9248 0.0068 sec/batch\n",
      "Epoch 12/50 Iteration: 207200 Avg. Training loss: 0.7575 0.0070 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 207400 Avg. Training loss: 0.7467 0.0068 sec/batch\n",
      "Epoch 12/50 Iteration: 207600 Avg. Training loss: 0.6071 0.0074 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 207800 Avg. Training loss: 0.8072 0.0068 sec/batch\n",
      "Epoch 12/50 Iteration: 208000 Avg. Training loss: 0.6051 0.0067 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 208200 Avg. Training loss: 0.8890 0.0067 sec/batch\n",
      "Epoch 12/50 Iteration: 208400 Avg. Training loss: 0.7878 0.0072 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 208600 Avg. Training loss: 0.7461 0.0082 sec/batch\n",
      "Epoch 12/50 Iteration: 208800 Avg. Training loss: 0.7803 0.0065 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 209000 Avg. Training loss: 0.8786 0.0069 sec/batch\n",
      "Epoch 12/50 Iteration: 209200 Avg. Training loss: 0.7655 0.0069 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 209400 Avg. Training loss: 0.6887 0.0069 sec/batch\n",
      "Epoch 12/50 Iteration: 209600 Avg. Training loss: 1.0666 0.0081 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 209800 Avg. Training loss: 0.7319 0.0068 sec/batch\n",
      "Epoch 12/50 Iteration: 210000 Avg. Training loss: 0.6549 0.0067 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 210200 Avg. Training loss: 0.8257 0.0069 sec/batch\n",
      "Epoch 12/50 Iteration: 210400 Avg. Training loss: 0.9206 0.0073 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 210600 Avg. Training loss: 0.7911 0.0071 sec/batch\n",
      "Epoch 12/50 Iteration: 210800 Avg. Training loss: 0.8042 0.0069 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 211000 Avg. Training loss: 0.8498 0.0066 sec/batch\n",
      "Epoch 12/50 Iteration: 211200 Avg. Training loss: 0.6252 0.0071 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 211400 Avg. Training loss: 0.7146 0.0071 sec/batch\n",
      "Epoch 12/50 Iteration: 211600 Avg. Training loss: 0.7007 0.0067 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 211800 Avg. Training loss: 0.6687 0.0068 sec/batch\n",
      "Epoch 12/50 Iteration: 212000 Avg. Training loss: 0.7977 0.0068 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 212200 Avg. Training loss: 0.6521 0.0068 sec/batch\n",
      "Epoch 12/50 Iteration: 212400 Avg. Training loss: 0.6750 0.0069 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 212600 Avg. Training loss: 0.7027 0.0073 sec/batch\n",
      "Epoch 12/50 Iteration: 212800 Avg. Training loss: 0.7205 0.0071 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 213000 Avg. Training loss: 0.8234 0.0082 sec/batch\n",
      "Epoch 12/50 Iteration: 213200 Avg. Training loss: 0.8340 0.0070 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 213400 Avg. Training loss: 0.7331 0.0085 sec/batch\n",
      "Epoch 12/50 Iteration: 213600 Avg. Training loss: 0.6609 0.0070 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 213800 Avg. Training loss: 0.9300 0.0071 sec/batch\n",
      "Epoch 12/50 Iteration: 214000 Avg. Training loss: 1.0181 0.0067 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 214200 Avg. Training loss: 0.8730 0.0072 sec/batch\n",
      "Epoch 12/50 Iteration: 214400 Avg. Training loss: 0.9433 0.0072 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 214600 Avg. Training loss: 0.8217 0.0072 sec/batch\n",
      "Epoch 12/50 Iteration: 214800 Avg. Training loss: 0.7990 0.0071 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 215000 Avg. Training loss: 0.5563 0.0068 sec/batch\n",
      "Epoch 12/50 Iteration: 215200 Avg. Training loss: 0.9294 0.0069 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 215400 Avg. Training loss: 0.9605 0.0072 sec/batch\n",
      "Epoch 12/50 Iteration: 215600 Avg. Training loss: 0.8855 0.0074 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 215800 Avg. Training loss: 0.8592 0.0070 sec/batch\n",
      "Epoch 12/50 Iteration: 216000 Avg. Training loss: 0.8224 0.0069 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 216200 Avg. Training loss: 0.9642 0.0074 sec/batch\n",
      "Epoch 12/50 Iteration: 216400 Avg. Training loss: 0.5114 0.0067 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 216600 Avg. Training loss: 0.6801 0.0068 sec/batch\n",
      "Epoch 12/50 Iteration: 216800 Avg. Training loss: 0.7453 0.0066 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 217000 Avg. Training loss: 0.7731 0.0069 sec/batch\n",
      "Epoch 12/50 Iteration: 217200 Avg. Training loss: 0.9888 0.0078 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 217400 Avg. Training loss: 0.8942 0.0068 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 Iteration: 217600 Avg. Training loss: 0.6819 0.0066 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 217800 Avg. Training loss: 0.6301 0.0070 sec/batch\n",
      "Epoch 12/50 Iteration: 218000 Avg. Training loss: 0.7812 0.0076 sec/batch\n",
      "error\n",
      "Epoch 12/50 Iteration: 218200 Avg. Training loss: 0.7605 0.0071 sec/batch\n",
      "Epoch 13/50 Iteration: 218400 Avg. Training loss: 0.7825 0.0013 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 218600 Avg. Training loss: 0.8791 0.0074 sec/batch\n",
      "Epoch 13/50 Iteration: 218800 Avg. Training loss: 0.8174 0.0073 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 219000 Avg. Training loss: 0.6588 0.0069 sec/batch\n",
      "Epoch 13/50 Iteration: 219200 Avg. Training loss: 0.9449 0.0077 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 219400 Avg. Training loss: 0.8312 0.0074 sec/batch\n",
      "Epoch 13/50 Iteration: 219600 Avg. Training loss: 0.7386 0.0067 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 219800 Avg. Training loss: 0.7699 0.0074 sec/batch\n",
      "Epoch 13/50 Iteration: 220000 Avg. Training loss: 0.6345 0.0071 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 220200 Avg. Training loss: 1.0097 0.0068 sec/batch\n",
      "Epoch 13/50 Iteration: 220400 Avg. Training loss: 0.7309 0.0069 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 220600 Avg. Training loss: 1.0021 0.0068 sec/batch\n",
      "Epoch 13/50 Iteration: 220800 Avg. Training loss: 0.5899 0.0073 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 221000 Avg. Training loss: 0.6879 0.0068 sec/batch\n",
      "Epoch 13/50 Iteration: 221200 Avg. Training loss: 0.6970 0.0069 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 221400 Avg. Training loss: 0.7809 0.0069 sec/batch\n",
      "Epoch 13/50 Iteration: 221600 Avg. Training loss: 0.9405 0.0070 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 221800 Avg. Training loss: 0.6641 0.0076 sec/batch\n",
      "Epoch 13/50 Iteration: 222000 Avg. Training loss: 0.7869 0.0068 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 222200 Avg. Training loss: 0.7168 0.0067 sec/batch\n",
      "Epoch 13/50 Iteration: 222400 Avg. Training loss: 0.8471 0.0071 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 222600 Avg. Training loss: 0.5786 0.0066 sec/batch\n",
      "Epoch 13/50 Iteration: 222800 Avg. Training loss: 0.6465 0.0073 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 223000 Avg. Training loss: 0.5009 0.0066 sec/batch\n",
      "Epoch 13/50 Iteration: 223200 Avg. Training loss: 0.6769 0.0068 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 223400 Avg. Training loss: 0.9904 0.0072 sec/batch\n",
      "Epoch 13/50 Iteration: 223600 Avg. Training loss: 0.7110 0.0065 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 223800 Avg. Training loss: 0.8920 0.0074 sec/batch\n",
      "Epoch 13/50 Iteration: 224000 Avg. Training loss: 0.7405 0.0070 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 224200 Avg. Training loss: 0.7265 0.0073 sec/batch\n",
      "Epoch 13/50 Iteration: 224400 Avg. Training loss: 0.6054 0.0068 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 224600 Avg. Training loss: 0.6366 0.0069 sec/batch\n",
      "Epoch 13/50 Iteration: 224800 Avg. Training loss: 0.7752 0.0068 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 225000 Avg. Training loss: 0.8202 0.0068 sec/batch\n",
      "Epoch 13/50 Iteration: 225200 Avg. Training loss: 0.8258 0.0070 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 225400 Avg. Training loss: 0.7478 0.0069 sec/batch\n",
      "Epoch 13/50 Iteration: 225600 Avg. Training loss: 0.7076 0.0068 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 225800 Avg. Training loss: 0.5804 0.0073 sec/batch\n",
      "Epoch 13/50 Iteration: 226000 Avg. Training loss: 0.7952 0.0066 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 226200 Avg. Training loss: 0.6374 0.0067 sec/batch\n",
      "Epoch 13/50 Iteration: 226400 Avg. Training loss: 0.8711 0.0065 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 226600 Avg. Training loss: 0.9865 0.0073 sec/batch\n",
      "Epoch 13/50 Iteration: 226800 Avg. Training loss: 0.8133 0.0082 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 227000 Avg. Training loss: 0.8155 0.0065 sec/batch\n",
      "Epoch 13/50 Iteration: 227200 Avg. Training loss: 0.7892 0.0068 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 227400 Avg. Training loss: 0.7645 0.0069 sec/batch\n",
      "Epoch 13/50 Iteration: 227600 Avg. Training loss: 0.6868 0.0069 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 227800 Avg. Training loss: 0.9580 0.0080 sec/batch\n",
      "Epoch 13/50 Iteration: 228000 Avg. Training loss: 0.7766 0.0067 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 228200 Avg. Training loss: 0.6430 0.0067 sec/batch\n",
      "Epoch 13/50 Iteration: 228400 Avg. Training loss: 0.7128 0.0068 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 228600 Avg. Training loss: 0.7491 0.0073 sec/batch\n",
      "Epoch 13/50 Iteration: 228800 Avg. Training loss: 0.6509 0.0070 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 229000 Avg. Training loss: 0.8400 0.0069 sec/batch\n",
      "Epoch 13/50 Iteration: 229200 Avg. Training loss: 0.7312 0.0066 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 229400 Avg. Training loss: 0.7083 0.0072 sec/batch\n",
      "Epoch 13/50 Iteration: 229600 Avg. Training loss: 0.7344 0.0070 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 229800 Avg. Training loss: 0.9075 0.0067 sec/batch\n",
      "Epoch 13/50 Iteration: 230000 Avg. Training loss: 0.6016 0.0067 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 230200 Avg. Training loss: 0.6628 0.0069 sec/batch\n",
      "Epoch 13/50 Iteration: 230400 Avg. Training loss: 0.5934 0.0069 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 230600 Avg. Training loss: 0.7052 0.0069 sec/batch\n",
      "Epoch 13/50 Iteration: 230800 Avg. Training loss: 0.7880 0.0070 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 231000 Avg. Training loss: 0.7223 0.0071 sec/batch\n",
      "Epoch 13/50 Iteration: 231200 Avg. Training loss: 0.8866 0.0080 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 231400 Avg. Training loss: 0.7281 0.0067 sec/batch\n",
      "Epoch 13/50 Iteration: 231600 Avg. Training loss: 0.6658 0.0083 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 231800 Avg. Training loss: 0.6802 0.0070 sec/batch\n",
      "Epoch 13/50 Iteration: 232000 Avg. Training loss: 0.8215 0.0071 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 232200 Avg. Training loss: 0.7415 0.0067 sec/batch\n",
      "Epoch 13/50 Iteration: 232400 Avg. Training loss: 0.7543 0.0072 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 232600 Avg. Training loss: 0.9099 0.0076 sec/batch\n",
      "Epoch 13/50 Iteration: 232800 Avg. Training loss: 0.8957 0.0071 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 233000 Avg. Training loss: 0.6794 0.0069 sec/batch\n",
      "Epoch 13/50 Iteration: 233200 Avg. Training loss: 0.7865 0.0068 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 233400 Avg. Training loss: 0.8908 0.0070 sec/batch\n",
      "Epoch 13/50 Iteration: 233600 Avg. Training loss: 0.8221 0.0069 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 233800 Avg. Training loss: 0.8340 0.0072 sec/batch\n",
      "Epoch 13/50 Iteration: 234000 Avg. Training loss: 0.7984 0.0068 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 234200 Avg. Training loss: 0.6526 0.0071 sec/batch\n",
      "Epoch 13/50 Iteration: 234400 Avg. Training loss: 0.9104 0.0074 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 234600 Avg. Training loss: 0.5482 0.0069 sec/batch\n",
      "Epoch 13/50 Iteration: 234800 Avg. Training loss: 0.7252 0.0069 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 235000 Avg. Training loss: 0.6803 0.0065 sec/batch\n",
      "Epoch 13/50 Iteration: 235200 Avg. Training loss: 0.7390 0.0069 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 235400 Avg. Training loss: 0.9917 0.0077 sec/batch\n",
      "Epoch 13/50 Iteration: 235600 Avg. Training loss: 0.8654 0.0068 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 235800 Avg. Training loss: 0.5864 0.0068 sec/batch\n",
      "Epoch 13/50 Iteration: 236000 Avg. Training loss: 0.8119 0.0071 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 236200 Avg. Training loss: 0.7305 0.0077 sec/batch\n",
      "Epoch 13/50 Iteration: 236400 Avg. Training loss: 0.6748 0.0071 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 236600 Avg. Training loss: 0.8317 0.0014 sec/batch\n",
      "Epoch 14/50 Iteration: 236800 Avg. Training loss: 1.0014 0.0072 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 237000 Avg. Training loss: 0.7577 0.0073 sec/batch\n",
      "Epoch 14/50 Iteration: 237200 Avg. Training loss: 0.6288 0.0069 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 237400 Avg. Training loss: 1.0255 0.0077 sec/batch\n",
      "Epoch 14/50 Iteration: 237600 Avg. Training loss: 0.7753 0.0071 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 237800 Avg. Training loss: 0.7652 0.0067 sec/batch\n",
      "Epoch 14/50 Iteration: 238000 Avg. Training loss: 0.8350 0.0073 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 238200 Avg. Training loss: 0.5745 0.0071 sec/batch\n",
      "Epoch 14/50 Iteration: 238400 Avg. Training loss: 0.9454 0.0065 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 238600 Avg. Training loss: 0.6591 0.0067 sec/batch\n",
      "Epoch 14/50 Iteration: 238800 Avg. Training loss: 0.8582 0.0068 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 Iteration: 239000 Avg. Training loss: 0.7577 0.0072 sec/batch\n",
      "Epoch 14/50 Iteration: 239200 Avg. Training loss: 0.5423 0.0067 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 239400 Avg. Training loss: 0.7674 0.0070 sec/batch\n",
      "Epoch 14/50 Iteration: 239600 Avg. Training loss: 0.7470 0.0070 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 239800 Avg. Training loss: 0.9014 0.0072 sec/batch\n",
      "Epoch 14/50 Iteration: 240000 Avg. Training loss: 0.8426 0.0075 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 240200 Avg. Training loss: 0.8318 0.0069 sec/batch\n",
      "Epoch 14/50 Iteration: 240400 Avg. Training loss: 0.8208 0.0067 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 240600 Avg. Training loss: 0.7383 0.0072 sec/batch\n",
      "Epoch 14/50 Iteration: 240800 Avg. Training loss: 0.5903 0.0066 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 241000 Avg. Training loss: 0.6721 0.0072 sec/batch\n",
      "Epoch 14/50 Iteration: 241200 Avg. Training loss: 0.6183 0.0065 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 241400 Avg. Training loss: 0.5410 0.0066 sec/batch\n",
      "Epoch 14/50 Iteration: 241600 Avg. Training loss: 0.7106 0.0071 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 241800 Avg. Training loss: 0.7926 0.0066 sec/batch\n",
      "Epoch 14/50 Iteration: 242000 Avg. Training loss: 0.7233 0.0074 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 242200 Avg. Training loss: 0.6937 0.0070 sec/batch\n",
      "Epoch 14/50 Iteration: 242400 Avg. Training loss: 0.8187 0.0073 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 242600 Avg. Training loss: 0.5568 0.0069 sec/batch\n",
      "Epoch 14/50 Iteration: 242800 Avg. Training loss: 0.7701 0.0068 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 243000 Avg. Training loss: 0.6613 0.0069 sec/batch\n",
      "Epoch 14/50 Iteration: 243200 Avg. Training loss: 0.7906 0.0068 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 243400 Avg. Training loss: 0.9393 0.0067 sec/batch\n",
      "Epoch 14/50 Iteration: 243600 Avg. Training loss: 0.6951 0.0071 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 243800 Avg. Training loss: 0.8950 0.0069 sec/batch\n",
      "Epoch 14/50 Iteration: 244000 Avg. Training loss: 0.7101 0.0073 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 244200 Avg. Training loss: 0.6647 0.0068 sec/batch\n",
      "Epoch 14/50 Iteration: 244400 Avg. Training loss: 0.6066 0.0066 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 244600 Avg. Training loss: 0.7711 0.0067 sec/batch\n",
      "Epoch 14/50 Iteration: 244800 Avg. Training loss: 0.7096 0.0073 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 245000 Avg. Training loss: 0.8970 0.0082 sec/batch\n",
      "Epoch 14/50 Iteration: 245200 Avg. Training loss: 0.7917 0.0066 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 245400 Avg. Training loss: 0.6969 0.0069 sec/batch\n",
      "Epoch 14/50 Iteration: 245600 Avg. Training loss: 0.8338 0.0068 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 245800 Avg. Training loss: 0.8231 0.0070 sec/batch\n",
      "Epoch 14/50 Iteration: 246000 Avg. Training loss: 0.9502 0.0080 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 246200 Avg. Training loss: 0.6534 0.0068 sec/batch\n",
      "Epoch 14/50 Iteration: 246400 Avg. Training loss: 0.6180 0.0068 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 246600 Avg. Training loss: 0.7237 0.0068 sec/batch\n",
      "Epoch 14/50 Iteration: 246800 Avg. Training loss: 0.9034 0.0072 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 247000 Avg. Training loss: 0.7842 0.0070 sec/batch\n",
      "Epoch 14/50 Iteration: 247200 Avg. Training loss: 0.8943 0.0069 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 247400 Avg. Training loss: 0.8086 0.0066 sec/batch\n",
      "Epoch 14/50 Iteration: 247600 Avg. Training loss: 0.6147 0.0071 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 247800 Avg. Training loss: 0.7526 0.0197 sec/batch\n",
      "Epoch 14/50 Iteration: 248000 Avg. Training loss: 0.7530 0.0081 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 248200 Avg. Training loss: 0.5620 0.0068 sec/batch\n",
      "Epoch 14/50 Iteration: 248400 Avg. Training loss: 0.7684 0.0068 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 248600 Avg. Training loss: 0.7804 0.0070 sec/batch\n",
      "Epoch 14/50 Iteration: 248800 Avg. Training loss: 0.6703 0.0070 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 249000 Avg. Training loss: 0.8166 0.0070 sec/batch\n",
      "Epoch 14/50 Iteration: 249200 Avg. Training loss: 0.6658 0.0074 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 249400 Avg. Training loss: 0.8452 0.0083 sec/batch\n",
      "Epoch 14/50 Iteration: 249600 Avg. Training loss: 0.7430 0.0068 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 249800 Avg. Training loss: 0.8491 0.0084 sec/batch\n",
      "Epoch 14/50 Iteration: 250000 Avg. Training loss: 0.5301 0.0070 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 250200 Avg. Training loss: 0.7912 0.0070 sec/batch\n",
      "Epoch 14/50 Iteration: 250400 Avg. Training loss: 0.8162 0.0067 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 250600 Avg. Training loss: 0.9280 0.0071 sec/batch\n",
      "Epoch 14/50 Iteration: 250800 Avg. Training loss: 0.9793 0.0071 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 251000 Avg. Training loss: 0.7227 0.0070 sec/batch\n",
      "Epoch 14/50 Iteration: 251200 Avg. Training loss: 0.7931 0.0068 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 251400 Avg. Training loss: 0.5832 0.0066 sec/batch\n",
      "Epoch 14/50 Iteration: 251600 Avg. Training loss: 0.9739 0.0069 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 251800 Avg. Training loss: 0.8410 0.0068 sec/batch\n",
      "Epoch 14/50 Iteration: 252000 Avg. Training loss: 0.7398 0.0071 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 252200 Avg. Training loss: 0.7854 0.0068 sec/batch\n",
      "Epoch 14/50 Iteration: 252400 Avg. Training loss: 0.8548 0.0068 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 252600 Avg. Training loss: 0.8644 0.0073 sec/batch\n",
      "Epoch 14/50 Iteration: 252800 Avg. Training loss: 0.6046 0.0066 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 253000 Avg. Training loss: 0.7723 0.0069 sec/batch\n",
      "Epoch 14/50 Iteration: 253200 Avg. Training loss: 0.8031 0.0066 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 253400 Avg. Training loss: 0.8091 0.0069 sec/batch\n",
      "Epoch 14/50 Iteration: 253600 Avg. Training loss: 0.9802 0.0078 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 253800 Avg. Training loss: 0.8876 0.0067 sec/batch\n",
      "Epoch 14/50 Iteration: 254000 Avg. Training loss: 0.6081 0.0068 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 254200 Avg. Training loss: 0.8155 0.0070 sec/batch\n",
      "Epoch 14/50 Iteration: 254400 Avg. Training loss: 0.4967 0.0076 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 254600 Avg. Training loss: 0.8473 0.0070 sec/batch\n",
      "Epoch 15/50 Iteration: 254800 Avg. Training loss: 0.7934 0.0016 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 255000 Avg. Training loss: 0.7861 0.0073 sec/batch\n",
      "Epoch 15/50 Iteration: 255200 Avg. Training loss: 0.6597 0.0073 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 255400 Avg. Training loss: 0.5644 0.0071 sec/batch\n",
      "Epoch 15/50 Iteration: 255600 Avg. Training loss: 0.8928 0.0079 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 255800 Avg. Training loss: 0.6971 0.0072 sec/batch\n",
      "Epoch 15/50 Iteration: 256000 Avg. Training loss: 0.7004 0.0066 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 256200 Avg. Training loss: 0.9038 0.0074 sec/batch\n",
      "Epoch 15/50 Iteration: 256400 Avg. Training loss: 0.4774 0.0071 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 256600 Avg. Training loss: 0.8146 0.0067 sec/batch\n",
      "Epoch 15/50 Iteration: 256800 Avg. Training loss: 0.7707 0.0067 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 257000 Avg. Training loss: 0.9510 0.0069 sec/batch\n",
      "Epoch 15/50 Iteration: 257200 Avg. Training loss: 0.6669 0.0073 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 257400 Avg. Training loss: 0.5553 0.0066 sec/batch\n",
      "Epoch 15/50 Iteration: 257600 Avg. Training loss: 0.7638 0.0069 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 257800 Avg. Training loss: 0.7814 0.0068 sec/batch\n",
      "Epoch 15/50 Iteration: 258000 Avg. Training loss: 0.8655 0.0071 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 258200 Avg. Training loss: 0.7521 0.0075 sec/batch\n",
      "Epoch 15/50 Iteration: 258400 Avg. Training loss: 0.7183 0.0069 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 258600 Avg. Training loss: 0.7921 0.0069 sec/batch\n",
      "Epoch 15/50 Iteration: 258800 Avg. Training loss: 0.8112 0.0073 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 259000 Avg. Training loss: 0.5841 0.0068 sec/batch\n",
      "Epoch 15/50 Iteration: 259200 Avg. Training loss: 0.6529 0.0074 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 259400 Avg. Training loss: 0.7085 0.0070 sec/batch\n",
      "Epoch 15/50 Iteration: 259600 Avg. Training loss: 0.6007 0.0071 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 259800 Avg. Training loss: 0.8619 0.0074 sec/batch\n",
      "Epoch 15/50 Iteration: 260000 Avg. Training loss: 0.6247 0.0069 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 260200 Avg. Training loss: 0.9267 0.0077 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 Iteration: 260400 Avg. Training loss: 0.8615 0.0073 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 260600 Avg. Training loss: 0.7057 0.0076 sec/batch\n",
      "Epoch 15/50 Iteration: 260800 Avg. Training loss: 0.6345 0.0071 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 261000 Avg. Training loss: 0.7217 0.0072 sec/batch\n",
      "Epoch 15/50 Iteration: 261200 Avg. Training loss: 0.7110 0.0072 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 261400 Avg. Training loss: 0.8923 0.0070 sec/batch\n",
      "Epoch 15/50 Iteration: 261600 Avg. Training loss: 0.8788 0.0070 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 261800 Avg. Training loss: 0.7619 0.0074 sec/batch\n",
      "Epoch 15/50 Iteration: 262000 Avg. Training loss: 0.8115 0.0071 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 262200 Avg. Training loss: 0.5928 0.0077 sec/batch\n",
      "Epoch 15/50 Iteration: 262400 Avg. Training loss: 0.7784 0.0072 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 262600 Avg. Training loss: 0.5625 0.0070 sec/batch\n",
      "Epoch 15/50 Iteration: 262800 Avg. Training loss: 0.6652 0.0068 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 263000 Avg. Training loss: 0.8866 0.0077 sec/batch\n",
      "Epoch 15/50 Iteration: 263200 Avg. Training loss: 0.8225 0.0084 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 263400 Avg. Training loss: 0.8785 0.0068 sec/batch\n",
      "Epoch 15/50 Iteration: 263600 Avg. Training loss: 0.8802 0.0071 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 263800 Avg. Training loss: 0.8508 0.0071 sec/batch\n",
      "Epoch 15/50 Iteration: 264000 Avg. Training loss: 0.7835 0.0072 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 264200 Avg. Training loss: 0.9116 0.0084 sec/batch\n",
      "Epoch 15/50 Iteration: 264400 Avg. Training loss: 0.7781 0.0071 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 264600 Avg. Training loss: 0.6474 0.0071 sec/batch\n",
      "Epoch 15/50 Iteration: 264800 Avg. Training loss: 0.8042 0.0072 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 265000 Avg. Training loss: 0.7842 0.0077 sec/batch\n",
      "Epoch 15/50 Iteration: 265200 Avg. Training loss: 0.7417 0.0073 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 265400 Avg. Training loss: 0.8167 0.0072 sec/batch\n",
      "Epoch 15/50 Iteration: 265600 Avg. Training loss: 0.8832 0.0068 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 265800 Avg. Training loss: 0.6882 0.0073 sec/batch\n",
      "Epoch 15/50 Iteration: 266000 Avg. Training loss: 0.6106 0.0079 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 266200 Avg. Training loss: 0.7105 0.0074 sec/batch\n",
      "Epoch 15/50 Iteration: 266400 Avg. Training loss: 0.6448 0.0071 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 266600 Avg. Training loss: 0.6889 0.0070 sec/batch\n",
      "Epoch 15/50 Iteration: 266800 Avg. Training loss: 0.6938 0.0070 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 267000 Avg. Training loss: 0.7113 0.0072 sec/batch\n",
      "Epoch 15/50 Iteration: 267200 Avg. Training loss: 0.8675 0.0072 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 267400 Avg. Training loss: 0.7539 0.0072 sec/batch\n",
      "Epoch 15/50 Iteration: 267600 Avg. Training loss: 0.7453 0.0082 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 267800 Avg. Training loss: 0.6401 0.0070 sec/batch\n",
      "Epoch 15/50 Iteration: 268000 Avg. Training loss: 0.8302 0.0085 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 268200 Avg. Training loss: 0.6336 0.0073 sec/batch\n",
      "Epoch 15/50 Iteration: 268400 Avg. Training loss: 0.8298 0.0073 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 268600 Avg. Training loss: 0.8617 0.0070 sec/batch\n",
      "Epoch 15/50 Iteration: 268800 Avg. Training loss: 0.7142 0.0074 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 269000 Avg. Training loss: 0.7981 0.0075 sec/batch\n",
      "Epoch 15/50 Iteration: 269200 Avg. Training loss: 0.8454 0.0073 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 269400 Avg. Training loss: 0.8726 0.0073 sec/batch\n",
      "Epoch 15/50 Iteration: 269600 Avg. Training loss: 0.8342 0.0071 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 269800 Avg. Training loss: 0.8797 0.0073 sec/batch\n",
      "Epoch 15/50 Iteration: 270000 Avg. Training loss: 0.8891 0.0072 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 270200 Avg. Training loss: 0.7550 0.0073 sec/batch\n",
      "Epoch 15/50 Iteration: 270400 Avg. Training loss: 0.8240 0.0071 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 270600 Avg. Training loss: 0.8935 0.0073 sec/batch\n",
      "Epoch 15/50 Iteration: 270800 Avg. Training loss: 0.9685 0.0076 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 271000 Avg. Training loss: 0.5363 0.0070 sec/batch\n",
      "Epoch 15/50 Iteration: 271200 Avg. Training loss: 0.7890 0.0071 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 271400 Avg. Training loss: 0.8202 0.0068 sec/batch\n",
      "Epoch 15/50 Iteration: 271600 Avg. Training loss: 0.6759 0.0072 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 271800 Avg. Training loss: 1.0418 0.0079 sec/batch\n",
      "Epoch 15/50 Iteration: 272000 Avg. Training loss: 0.7352 0.0070 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 272200 Avg. Training loss: 0.6959 0.0069 sec/batch\n",
      "Epoch 15/50 Iteration: 272400 Avg. Training loss: 0.7457 0.0072 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 272600 Avg. Training loss: 0.6062 0.0077 sec/batch\n",
      "Epoch 15/50 Iteration: 272800 Avg. Training loss: 0.7893 0.0070 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 273000 Avg. Training loss: 0.7354 0.0017 sec/batch\n",
      "Epoch 16/50 Iteration: 273200 Avg. Training loss: 0.9840 0.0072 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 273400 Avg. Training loss: 0.7797 0.0074 sec/batch\n",
      "Epoch 16/50 Iteration: 273600 Avg. Training loss: 0.6678 0.0069 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 273800 Avg. Training loss: 0.8826 0.0077 sec/batch\n",
      "Epoch 16/50 Iteration: 274000 Avg. Training loss: 0.7133 0.0073 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 274200 Avg. Training loss: 0.7033 0.0068 sec/batch\n",
      "Epoch 16/50 Iteration: 274400 Avg. Training loss: 0.7633 0.0074 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 274600 Avg. Training loss: 0.6646 0.0070 sec/batch\n",
      "Epoch 16/50 Iteration: 274800 Avg. Training loss: 0.7766 0.0066 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 275000 Avg. Training loss: 0.7819 0.0068 sec/batch\n",
      "Epoch 16/50 Iteration: 275200 Avg. Training loss: 0.9341 0.0068 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 275400 Avg. Training loss: 0.9337 0.0072 sec/batch\n",
      "Epoch 16/50 Iteration: 275600 Avg. Training loss: 0.5368 0.0067 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 275800 Avg. Training loss: 0.7652 0.0070 sec/batch\n",
      "Epoch 16/50 Iteration: 276000 Avg. Training loss: 0.7654 0.0068 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 276200 Avg. Training loss: 0.8521 0.0070 sec/batch\n",
      "Epoch 16/50 Iteration: 276400 Avg. Training loss: 0.8654 0.0074 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 276600 Avg. Training loss: 0.6811 0.0068 sec/batch\n",
      "Epoch 16/50 Iteration: 276800 Avg. Training loss: 0.8384 0.0067 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 277000 Avg. Training loss: 0.8210 0.0070 sec/batch\n",
      "Epoch 16/50 Iteration: 277200 Avg. Training loss: 0.6385 0.0065 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 277400 Avg. Training loss: 0.7260 0.0073 sec/batch\n",
      "Epoch 16/50 Iteration: 277600 Avg. Training loss: 0.5217 0.0066 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 277800 Avg. Training loss: 0.5885 0.0067 sec/batch\n",
      "Epoch 16/50 Iteration: 278000 Avg. Training loss: 0.7643 0.0071 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 278200 Avg. Training loss: 0.7299 0.0067 sec/batch\n",
      "Epoch 16/50 Iteration: 278400 Avg. Training loss: 0.9775 0.0074 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 278600 Avg. Training loss: 0.7291 0.0070 sec/batch\n",
      "Epoch 16/50 Iteration: 278800 Avg. Training loss: 0.8491 0.0073 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 279000 Avg. Training loss: 0.5525 0.0068 sec/batch\n",
      "Epoch 16/50 Iteration: 279200 Avg. Training loss: 0.7873 0.0070 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 279400 Avg. Training loss: 0.7211 0.0070 sec/batch\n",
      "Epoch 16/50 Iteration: 279600 Avg. Training loss: 0.7859 0.0067 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 279800 Avg. Training loss: 0.8049 0.0067 sec/batch\n",
      "Epoch 16/50 Iteration: 280000 Avg. Training loss: 0.7667 0.0071 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 280200 Avg. Training loss: 0.9368 0.0070 sec/batch\n",
      "Epoch 16/50 Iteration: 280400 Avg. Training loss: 0.6171 0.0074 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 280600 Avg. Training loss: 0.6925 0.0069 sec/batch\n",
      "Epoch 16/50 Iteration: 280800 Avg. Training loss: 0.5398 0.0066 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 281000 Avg. Training loss: 0.5476 0.0067 sec/batch\n",
      "Epoch 16/50 Iteration: 281200 Avg. Training loss: 0.8005 0.0074 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 281400 Avg. Training loss: 0.7750 0.0082 sec/batch\n",
      "Epoch 16/50 Iteration: 281600 Avg. Training loss: 0.6054 0.0065 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 Iteration: 281800 Avg. Training loss: 0.7385 0.0069 sec/batch\n",
      "Epoch 16/50 Iteration: 282000 Avg. Training loss: 0.7722 0.0069 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 282200 Avg. Training loss: 0.7535 0.0068 sec/batch\n",
      "Epoch 16/50 Iteration: 282400 Avg. Training loss: 1.2058 0.0080 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 282600 Avg. Training loss: 0.5025 0.0068 sec/batch\n",
      "Epoch 16/50 Iteration: 282800 Avg. Training loss: 0.5894 0.0067 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 283000 Avg. Training loss: 0.7945 0.0072 sec/batch\n",
      "Epoch 16/50 Iteration: 283200 Avg. Training loss: 0.7735 0.0076 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 283400 Avg. Training loss: 0.6878 0.0071 sec/batch\n",
      "Epoch 16/50 Iteration: 283600 Avg. Training loss: 0.7494 0.0067 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 283800 Avg. Training loss: 0.9027 0.0066 sec/batch\n",
      "Epoch 16/50 Iteration: 284000 Avg. Training loss: 0.6601 0.0071 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 284200 Avg. Training loss: 0.8623 0.0070 sec/batch\n",
      "Epoch 16/50 Iteration: 284400 Avg. Training loss: 0.6538 0.0068 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 284600 Avg. Training loss: 0.6574 0.0066 sec/batch\n",
      "Epoch 16/50 Iteration: 284800 Avg. Training loss: 0.7277 0.0068 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 285000 Avg. Training loss: 0.6474 0.0068 sec/batch\n",
      "Epoch 16/50 Iteration: 285200 Avg. Training loss: 0.7509 0.0068 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 285400 Avg. Training loss: 0.6369 0.0069 sec/batch\n",
      "Epoch 16/50 Iteration: 285600 Avg. Training loss: 0.7257 0.0070 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 285800 Avg. Training loss: 0.7303 0.0079 sec/batch\n",
      "Epoch 16/50 Iteration: 286000 Avg. Training loss: 0.8026 0.0068 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 286200 Avg. Training loss: 0.8068 0.0083 sec/batch\n",
      "Epoch 16/50 Iteration: 286400 Avg. Training loss: 0.5623 0.0069 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 286600 Avg. Training loss: 0.9482 0.0071 sec/batch\n",
      "Epoch 16/50 Iteration: 286800 Avg. Training loss: 0.8962 0.0064 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 287000 Avg. Training loss: 0.7171 0.0070 sec/batch\n",
      "Epoch 16/50 Iteration: 287200 Avg. Training loss: 0.8015 0.0071 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 287400 Avg. Training loss: 0.8728 0.0067 sec/batch\n",
      "Epoch 16/50 Iteration: 287600 Avg. Training loss: 0.7006 0.0069 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 287800 Avg. Training loss: 0.8054 0.0065 sec/batch\n",
      "Epoch 16/50 Iteration: 288000 Avg. Training loss: 0.9460 0.0069 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 288200 Avg. Training loss: 0.7755 0.0067 sec/batch\n",
      "Epoch 16/50 Iteration: 288400 Avg. Training loss: 0.9532 0.0071 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 288600 Avg. Training loss: 0.6739 0.0069 sec/batch\n",
      "Epoch 16/50 Iteration: 288800 Avg. Training loss: 0.9337 0.0070 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 289000 Avg. Training loss: 0.9579 0.0073 sec/batch\n",
      "Epoch 16/50 Iteration: 289200 Avg. Training loss: 0.6008 0.0067 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 289400 Avg. Training loss: 0.8538 0.0069 sec/batch\n",
      "Epoch 16/50 Iteration: 289600 Avg. Training loss: 0.6275 0.0066 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 289800 Avg. Training loss: 0.8626 0.0070 sec/batch\n",
      "Epoch 16/50 Iteration: 290000 Avg. Training loss: 0.8948 0.0077 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 290200 Avg. Training loss: 0.8769 0.0068 sec/batch\n",
      "Epoch 16/50 Iteration: 290400 Avg. Training loss: 0.7140 0.0067 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 290600 Avg. Training loss: 0.7652 0.0070 sec/batch\n",
      "Epoch 16/50 Iteration: 290800 Avg. Training loss: 0.7720 0.0077 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 291000 Avg. Training loss: 0.7226 0.0071 sec/batch\n",
      "Epoch 17/50 Iteration: 291200 Avg. Training loss: 0.8465 0.0018 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 291400 Avg. Training loss: 1.0930 0.0073 sec/batch\n",
      "Epoch 17/50 Iteration: 291600 Avg. Training loss: 0.7178 0.0073 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 291800 Avg. Training loss: 0.8854 0.0069 sec/batch\n",
      "Epoch 17/50 Iteration: 292000 Avg. Training loss: 0.9958 0.0078 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 292200 Avg. Training loss: 1.1728 0.0073 sec/batch\n",
      "Epoch 17/50 Iteration: 292400 Avg. Training loss: 0.7397 0.0067 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 292600 Avg. Training loss: 0.7179 0.0074 sec/batch\n",
      "Epoch 17/50 Iteration: 292800 Avg. Training loss: 0.6074 0.0071 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 293000 Avg. Training loss: 0.8730 0.0066 sec/batch\n",
      "Epoch 17/50 Iteration: 293200 Avg. Training loss: 0.8551 0.0067 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 293400 Avg. Training loss: 0.9008 0.0070 sec/batch\n",
      "Epoch 17/50 Iteration: 293600 Avg. Training loss: 0.6366 0.0073 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 293800 Avg. Training loss: 0.6085 0.0067 sec/batch\n",
      "Epoch 17/50 Iteration: 294000 Avg. Training loss: 0.7708 0.0068 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 294200 Avg. Training loss: 0.7137 0.0069 sec/batch\n",
      "Epoch 17/50 Iteration: 294400 Avg. Training loss: 0.9578 0.0070 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 294600 Avg. Training loss: 0.7519 0.0075 sec/batch\n",
      "Epoch 17/50 Iteration: 294800 Avg. Training loss: 0.6873 0.0069 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 295000 Avg. Training loss: 0.9323 0.0068 sec/batch\n",
      "Epoch 17/50 Iteration: 295200 Avg. Training loss: 0.7884 0.0070 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 295400 Avg. Training loss: 0.7746 0.0065 sec/batch\n",
      "Epoch 17/50 Iteration: 295600 Avg. Training loss: 0.7624 0.0072 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 295800 Avg. Training loss: 0.4949 0.0065 sec/batch\n",
      "Epoch 17/50 Iteration: 296000 Avg. Training loss: 0.6016 0.0066 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 296200 Avg. Training loss: 0.8275 0.0072 sec/batch\n",
      "Epoch 17/50 Iteration: 296400 Avg. Training loss: 0.8187 0.0066 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 296600 Avg. Training loss: 0.7672 0.0075 sec/batch\n",
      "Epoch 17/50 Iteration: 296800 Avg. Training loss: 0.6425 0.0069 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 297000 Avg. Training loss: 0.6888 0.0074 sec/batch\n",
      "Epoch 17/50 Iteration: 297200 Avg. Training loss: 0.6279 0.0067 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 297400 Avg. Training loss: 0.7140 0.0069 sec/batch\n",
      "Epoch 17/50 Iteration: 297600 Avg. Training loss: 0.7833 0.0069 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 297800 Avg. Training loss: 0.8134 0.0068 sec/batch\n",
      "Epoch 17/50 Iteration: 298000 Avg. Training loss: 0.8261 0.0067 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 298200 Avg. Training loss: 0.8770 0.0070 sec/batch\n",
      "Epoch 17/50 Iteration: 298400 Avg. Training loss: 0.8757 0.0069 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 298600 Avg. Training loss: 0.5547 0.0073 sec/batch\n",
      "Epoch 17/50 Iteration: 298800 Avg. Training loss: 0.7007 0.0065 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 299000 Avg. Training loss: 0.4452 0.0067 sec/batch\n",
      "Epoch 17/50 Iteration: 299200 Avg. Training loss: 0.6725 0.0065 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 299400 Avg. Training loss: 0.7289 0.0074 sec/batch\n",
      "Epoch 17/50 Iteration: 299600 Avg. Training loss: 0.7574 0.0080 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 299800 Avg. Training loss: 0.9843 0.0066 sec/batch\n",
      "Epoch 17/50 Iteration: 300000 Avg. Training loss: 0.7500 0.0068 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 300200 Avg. Training loss: 0.8232 0.0072 sec/batch\n",
      "Epoch 17/50 Iteration: 300400 Avg. Training loss: 0.7095 0.0072 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 300600 Avg. Training loss: 0.9564 0.0080 sec/batch\n",
      "Epoch 17/50 Iteration: 300800 Avg. Training loss: 0.7321 0.0066 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 301000 Avg. Training loss: 0.6588 0.0068 sec/batch\n",
      "Epoch 17/50 Iteration: 301200 Avg. Training loss: 0.8260 0.0069 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 301400 Avg. Training loss: 0.8515 0.0072 sec/batch\n",
      "Epoch 17/50 Iteration: 301600 Avg. Training loss: 0.7228 0.0068 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 301800 Avg. Training loss: 0.7525 0.0068 sec/batch\n",
      "Epoch 17/50 Iteration: 302000 Avg. Training loss: 1.0804 0.0065 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 302200 Avg. Training loss: 0.8347 0.0072 sec/batch\n",
      "Epoch 17/50 Iteration: 302400 Avg. Training loss: 0.8446 0.0070 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 302600 Avg. Training loss: 0.8030 0.0067 sec/batch\n",
      "Epoch 17/50 Iteration: 302800 Avg. Training loss: 0.6341 0.0067 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 303000 Avg. Training loss: 0.7034 0.0068 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 Iteration: 303200 Avg. Training loss: 0.5185 0.0069 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 303400 Avg. Training loss: 0.5513 0.0069 sec/batch\n",
      "Epoch 17/50 Iteration: 303600 Avg. Training loss: 0.7859 0.0070 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 303800 Avg. Training loss: 0.6603 0.0070 sec/batch\n",
      "Epoch 17/50 Iteration: 304000 Avg. Training loss: 0.9485 0.0081 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 304200 Avg. Training loss: 0.7804 0.0069 sec/batch\n",
      "Epoch 17/50 Iteration: 304400 Avg. Training loss: 0.7617 0.0084 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 304600 Avg. Training loss: 0.6498 0.0070 sec/batch\n",
      "Epoch 17/50 Iteration: 304800 Avg. Training loss: 0.8116 0.0070 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 305000 Avg. Training loss: 0.8677 0.0067 sec/batch\n",
      "Epoch 17/50 Iteration: 305200 Avg. Training loss: 0.6549 0.0070 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 305400 Avg. Training loss: 0.9676 0.0072 sec/batch\n",
      "Epoch 17/50 Iteration: 305600 Avg. Training loss: 0.6466 0.0070 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 305800 Avg. Training loss: 0.7751 0.0069 sec/batch\n",
      "Epoch 17/50 Iteration: 306000 Avg. Training loss: 0.7687 0.0066 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 306200 Avg. Training loss: 1.0219 0.0070 sec/batch\n",
      "Epoch 17/50 Iteration: 306400 Avg. Training loss: 0.8343 0.0069 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 306600 Avg. Training loss: 0.6735 0.0071 sec/batch\n",
      "Epoch 17/50 Iteration: 306800 Avg. Training loss: 0.7009 0.0068 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 307000 Avg. Training loss: 0.8261 0.0069 sec/batch\n",
      "Epoch 17/50 Iteration: 307200 Avg. Training loss: 0.8776 0.0073 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 307400 Avg. Training loss: 0.6006 0.0068 sec/batch\n",
      "Epoch 17/50 Iteration: 307600 Avg. Training loss: 0.7685 0.0069 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 307800 Avg. Training loss: 0.6089 0.0067 sec/batch\n",
      "Epoch 17/50 Iteration: 308000 Avg. Training loss: 0.8565 0.0070 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 308200 Avg. Training loss: 0.9474 0.0077 sec/batch\n",
      "Epoch 17/50 Iteration: 308400 Avg. Training loss: 0.8717 0.0068 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 308600 Avg. Training loss: 0.7326 0.0068 sec/batch\n",
      "Epoch 17/50 Iteration: 308800 Avg. Training loss: 0.8203 0.0070 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 309000 Avg. Training loss: 0.7753 0.0077 sec/batch\n",
      "Epoch 17/50 Iteration: 309200 Avg. Training loss: 0.6854 0.0071 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 309400 Avg. Training loss: 0.7835 0.0019 sec/batch\n",
      "Epoch 18/50 Iteration: 309600 Avg. Training loss: 0.7786 0.0073 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 309800 Avg. Training loss: 0.8348 0.0073 sec/batch\n",
      "Epoch 18/50 Iteration: 310000 Avg. Training loss: 0.8267 0.0069 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 310200 Avg. Training loss: 1.1067 0.0078 sec/batch\n",
      "Epoch 18/50 Iteration: 310400 Avg. Training loss: 0.9577 0.0073 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 310600 Avg. Training loss: 0.8088 0.0067 sec/batch\n",
      "Epoch 18/50 Iteration: 310800 Avg. Training loss: 0.7442 0.0073 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 311000 Avg. Training loss: 0.5848 0.0071 sec/batch\n",
      "Epoch 18/50 Iteration: 311200 Avg. Training loss: 0.6748 0.0066 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 311400 Avg. Training loss: 0.7449 0.0068 sec/batch\n",
      "Epoch 18/50 Iteration: 311600 Avg. Training loss: 0.9936 0.0069 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 311800 Avg. Training loss: 0.5679 0.0073 sec/batch\n",
      "Epoch 18/50 Iteration: 312000 Avg. Training loss: 0.6475 0.0066 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 312200 Avg. Training loss: 0.7370 0.0069 sec/batch\n",
      "Epoch 18/50 Iteration: 312400 Avg. Training loss: 0.7057 0.0068 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 312600 Avg. Training loss: 0.7515 0.0071 sec/batch\n",
      "Epoch 18/50 Iteration: 312800 Avg. Training loss: 0.7154 0.0076 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 313000 Avg. Training loss: 0.7650 0.0069 sec/batch\n",
      "Epoch 18/50 Iteration: 313200 Avg. Training loss: 0.8805 0.0069 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 313400 Avg. Training loss: 0.6558 0.0071 sec/batch\n",
      "Epoch 18/50 Iteration: 313600 Avg. Training loss: 0.6186 0.0066 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 313800 Avg. Training loss: 0.5577 0.0073 sec/batch\n",
      "Epoch 18/50 Iteration: 314000 Avg. Training loss: 0.5399 0.0066 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 314200 Avg. Training loss: 0.4992 0.0067 sec/batch\n",
      "Epoch 18/50 Iteration: 314400 Avg. Training loss: 0.8052 0.0071 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 314600 Avg. Training loss: 0.5657 0.0067 sec/batch\n",
      "Epoch 18/50 Iteration: 314800 Avg. Training loss: 0.8462 0.0075 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 315000 Avg. Training loss: 0.9059 0.0069 sec/batch\n",
      "Epoch 18/50 Iteration: 315200 Avg. Training loss: 0.7365 0.0074 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 315400 Avg. Training loss: 0.5937 0.0069 sec/batch\n",
      "Epoch 18/50 Iteration: 315600 Avg. Training loss: 0.7018 0.0068 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 315800 Avg. Training loss: 0.6650 0.0070 sec/batch\n",
      "Epoch 18/50 Iteration: 316000 Avg. Training loss: 0.8932 0.0069 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 316200 Avg. Training loss: 0.7559 0.0067 sec/batch\n",
      "Epoch 18/50 Iteration: 316400 Avg. Training loss: 0.7522 0.0071 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 316600 Avg. Training loss: 0.7975 0.0070 sec/batch\n",
      "Epoch 18/50 Iteration: 316800 Avg. Training loss: 0.5694 0.0073 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 317000 Avg. Training loss: 0.8883 0.0066 sec/batch\n",
      "Epoch 18/50 Iteration: 317200 Avg. Training loss: 0.4619 0.0071 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 317400 Avg. Training loss: 0.6939 0.0072 sec/batch\n",
      "Epoch 18/50 Iteration: 317600 Avg. Training loss: 0.8879 0.0079 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 317800 Avg. Training loss: 0.8454 0.0081 sec/batch\n",
      "Epoch 18/50 Iteration: 318000 Avg. Training loss: 0.8549 0.0068 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 318200 Avg. Training loss: 0.7775 0.0070 sec/batch\n",
      "Epoch 18/50 Iteration: 318400 Avg. Training loss: 0.7969 0.0068 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 318600 Avg. Training loss: 0.8053 0.0071 sec/batch\n",
      "Epoch 18/50 Iteration: 318800 Avg. Training loss: 1.0395 0.0080 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 319000 Avg. Training loss: 0.6152 0.0067 sec/batch\n",
      "Epoch 18/50 Iteration: 319200 Avg. Training loss: 0.6091 0.0067 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 319400 Avg. Training loss: 0.8149 0.0068 sec/batch\n",
      "Epoch 18/50 Iteration: 319600 Avg. Training loss: 0.9116 0.0073 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 319800 Avg. Training loss: 0.7064 0.0071 sec/batch\n",
      "Epoch 18/50 Iteration: 320000 Avg. Training loss: 0.6298 0.0069 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 320200 Avg. Training loss: 0.7294 0.0067 sec/batch\n",
      "Epoch 18/50 Iteration: 320400 Avg. Training loss: 0.7204 0.0073 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 320600 Avg. Training loss: 0.6261 0.0071 sec/batch\n",
      "Epoch 18/50 Iteration: 320800 Avg. Training loss: 0.6644 0.0069 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 321000 Avg. Training loss: 0.5446 0.0068 sec/batch\n",
      "Epoch 18/50 Iteration: 321200 Avg. Training loss: 0.7114 0.0070 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 321400 Avg. Training loss: 0.6380 0.0069 sec/batch\n",
      "Epoch 18/50 Iteration: 321600 Avg. Training loss: 0.6569 0.0070 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 321800 Avg. Training loss: 0.8257 0.0071 sec/batch\n",
      "Epoch 18/50 Iteration: 322000 Avg. Training loss: 0.7477 0.0071 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 322200 Avg. Training loss: 0.8722 0.0081 sec/batch\n",
      "Epoch 18/50 Iteration: 322400 Avg. Training loss: 0.8274 0.0068 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 322600 Avg. Training loss: 0.6417 0.0084 sec/batch\n",
      "Epoch 18/50 Iteration: 322800 Avg. Training loss: 0.6461 0.0071 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 323000 Avg. Training loss: 0.8264 0.0072 sec/batch\n",
      "Epoch 18/50 Iteration: 323200 Avg. Training loss: 0.8756 0.0066 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 323400 Avg. Training loss: 0.8690 0.0072 sec/batch\n",
      "Epoch 18/50 Iteration: 323600 Avg. Training loss: 0.7468 0.0072 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 323800 Avg. Training loss: 0.9654 0.0069 sec/batch\n",
      "Epoch 18/50 Iteration: 324000 Avg. Training loss: 0.6464 0.0069 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 324200 Avg. Training loss: 0.7981 0.0068 sec/batch\n",
      "Epoch 18/50 Iteration: 324400 Avg. Training loss: 0.8621 0.0070 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 Iteration: 324600 Avg. Training loss: 0.8611 0.0068 sec/batch\n",
      "Epoch 18/50 Iteration: 324800 Avg. Training loss: 0.6854 0.0073 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 325000 Avg. Training loss: 0.8143 0.0068 sec/batch\n",
      "Epoch 18/50 Iteration: 325200 Avg. Training loss: 0.7333 0.0069 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 325400 Avg. Training loss: 0.8979 0.0073 sec/batch\n",
      "Epoch 18/50 Iteration: 325600 Avg. Training loss: 0.6364 0.0068 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 325800 Avg. Training loss: 0.6729 0.0069 sec/batch\n",
      "Epoch 18/50 Iteration: 326000 Avg. Training loss: 0.7308 0.0066 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 326200 Avg. Training loss: 0.7766 0.0071 sec/batch\n",
      "Epoch 18/50 Iteration: 326400 Avg. Training loss: 0.9656 0.0076 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 326600 Avg. Training loss: 0.8674 0.0068 sec/batch\n",
      "Epoch 18/50 Iteration: 326800 Avg. Training loss: 0.6410 0.0066 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 327000 Avg. Training loss: 0.8368 0.0071 sec/batch\n",
      "Epoch 18/50 Iteration: 327200 Avg. Training loss: 0.5685 0.0077 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 327400 Avg. Training loss: 0.7788 0.0070 sec/batch\n",
      "Epoch 19/50 Iteration: 327600 Avg. Training loss: 0.8958 0.0020 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 327800 Avg. Training loss: 1.0402 0.0073 sec/batch\n",
      "Epoch 19/50 Iteration: 328000 Avg. Training loss: 0.7077 0.0072 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 328200 Avg. Training loss: 0.8206 0.0070 sec/batch\n",
      "Epoch 19/50 Iteration: 328400 Avg. Training loss: 0.9863 0.0078 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 328600 Avg. Training loss: 0.8834 0.0072 sec/batch\n",
      "Epoch 19/50 Iteration: 328800 Avg. Training loss: 0.7967 0.0067 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 329000 Avg. Training loss: 0.8948 0.0074 sec/batch\n",
      "Epoch 19/50 Iteration: 329200 Avg. Training loss: 0.6256 0.0070 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 329400 Avg. Training loss: 0.8325 0.0066 sec/batch\n",
      "Epoch 19/50 Iteration: 329600 Avg. Training loss: 0.9471 0.0067 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 329800 Avg. Training loss: 0.9248 0.0069 sec/batch\n",
      "Epoch 19/50 Iteration: 330000 Avg. Training loss: 0.8419 0.0073 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 330200 Avg. Training loss: 0.5327 0.0068 sec/batch\n",
      "Epoch 19/50 Iteration: 330400 Avg. Training loss: 0.7945 0.0068 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 330600 Avg. Training loss: 0.6080 0.0069 sec/batch\n",
      "Epoch 19/50 Iteration: 330800 Avg. Training loss: 0.7292 0.0071 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 331000 Avg. Training loss: 0.7973 0.0076 sec/batch\n",
      "Epoch 19/50 Iteration: 331200 Avg. Training loss: 0.7395 0.0069 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 331400 Avg. Training loss: 0.6708 0.0068 sec/batch\n",
      "Epoch 19/50 Iteration: 331600 Avg. Training loss: 0.6577 0.0071 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 331800 Avg. Training loss: 0.6620 0.0066 sec/batch\n",
      "Epoch 19/50 Iteration: 332000 Avg. Training loss: 0.6174 0.0072 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 332200 Avg. Training loss: 0.6110 0.0068 sec/batch\n",
      "Epoch 19/50 Iteration: 332400 Avg. Training loss: 0.6396 0.0067 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 332600 Avg. Training loss: 0.9235 0.0071 sec/batch\n",
      "Epoch 19/50 Iteration: 332800 Avg. Training loss: 0.7188 0.0067 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 333000 Avg. Training loss: 0.8600 0.0077 sec/batch\n",
      "Epoch 19/50 Iteration: 333200 Avg. Training loss: 0.6957 0.0070 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 333400 Avg. Training loss: 0.7333 0.0073 sec/batch\n",
      "Epoch 19/50 Iteration: 333600 Avg. Training loss: 0.6077 0.0068 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 333800 Avg. Training loss: 0.6974 0.0069 sec/batch\n",
      "Epoch 19/50 Iteration: 334000 Avg. Training loss: 0.6811 0.0071 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 334200 Avg. Training loss: 0.6611 0.0073 sec/batch\n",
      "Epoch 19/50 Iteration: 334400 Avg. Training loss: 0.7857 0.0069 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 334600 Avg. Training loss: 0.9118 0.0070 sec/batch\n",
      "Epoch 19/50 Iteration: 334800 Avg. Training loss: 0.9539 0.0069 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 335000 Avg. Training loss: 0.5832 0.0073 sec/batch\n",
      "Epoch 19/50 Iteration: 335200 Avg. Training loss: 0.7218 0.0067 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 335400 Avg. Training loss: 0.5850 0.0066 sec/batch\n",
      "Epoch 19/50 Iteration: 335600 Avg. Training loss: 0.7449 0.0066 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 335800 Avg. Training loss: 0.8468 0.0076 sec/batch\n",
      "Epoch 19/50 Iteration: 336000 Avg. Training loss: 0.8472 0.0079 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 336200 Avg. Training loss: 0.6576 0.0065 sec/batch\n",
      "Epoch 19/50 Iteration: 336400 Avg. Training loss: 0.6784 0.0067 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 336600 Avg. Training loss: 0.7140 0.0068 sec/batch\n",
      "Epoch 19/50 Iteration: 336800 Avg. Training loss: 0.7768 0.0069 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 337000 Avg. Training loss: 0.9050 0.0080 sec/batch\n",
      "Epoch 19/50 Iteration: 337200 Avg. Training loss: 0.5029 0.0068 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 337400 Avg. Training loss: 0.5850 0.0067 sec/batch\n",
      "Epoch 19/50 Iteration: 337600 Avg. Training loss: 0.8088 0.0068 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 337800 Avg. Training loss: 0.6291 0.0072 sec/batch\n",
      "Epoch 19/50 Iteration: 338000 Avg. Training loss: 0.9174 0.0069 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 338200 Avg. Training loss: 0.7941 0.0067 sec/batch\n",
      "Epoch 19/50 Iteration: 338400 Avg. Training loss: 0.7851 0.0065 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 338600 Avg. Training loss: 0.6317 0.0073 sec/batch\n",
      "Epoch 19/50 Iteration: 338800 Avg. Training loss: 0.6122 0.0070 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 339000 Avg. Training loss: 0.6233 0.0068 sec/batch\n",
      "Epoch 19/50 Iteration: 339200 Avg. Training loss: 0.5489 0.0066 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 339400 Avg. Training loss: 0.7269 0.0068 sec/batch\n",
      "Epoch 19/50 Iteration: 339600 Avg. Training loss: 0.6079 0.0069 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 339800 Avg. Training loss: 0.6561 0.0068 sec/batch\n",
      "Epoch 19/50 Iteration: 340000 Avg. Training loss: 0.8662 0.0068 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 340200 Avg. Training loss: 0.8332 0.0069 sec/batch\n",
      "Epoch 19/50 Iteration: 340400 Avg. Training loss: 0.8173 0.0079 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 340600 Avg. Training loss: 0.8349 0.0067 sec/batch\n",
      "Epoch 19/50 Iteration: 340800 Avg. Training loss: 0.8397 0.0083 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 341000 Avg. Training loss: 0.6731 0.0069 sec/batch\n",
      "Epoch 19/50 Iteration: 341200 Avg. Training loss: 0.7736 0.0069 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 341400 Avg. Training loss: 0.8062 0.0065 sec/batch\n",
      "Epoch 19/50 Iteration: 341600 Avg. Training loss: 0.6886 0.0072 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 341800 Avg. Training loss: 0.9498 0.0070 sec/batch\n",
      "Epoch 19/50 Iteration: 342000 Avg. Training loss: 0.8722 0.0069 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 342200 Avg. Training loss: 0.6095 0.0068 sec/batch\n",
      "Epoch 19/50 Iteration: 342400 Avg. Training loss: 0.7499 0.0065 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 342600 Avg. Training loss: 0.9763 0.0068 sec/batch\n",
      "Epoch 19/50 Iteration: 342800 Avg. Training loss: 0.7971 0.0069 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 343000 Avg. Training loss: 0.7427 0.0071 sec/batch\n",
      "Epoch 19/50 Iteration: 343200 Avg. Training loss: 0.8372 0.0067 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 343400 Avg. Training loss: 0.8484 0.0070 sec/batch\n",
      "Epoch 19/50 Iteration: 343600 Avg. Training loss: 0.9740 0.0072 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 343800 Avg. Training loss: 0.6336 0.0069 sec/batch\n",
      "Epoch 19/50 Iteration: 344000 Avg. Training loss: 0.6442 0.0070 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 344200 Avg. Training loss: 0.6920 0.0065 sec/batch\n",
      "Epoch 19/50 Iteration: 344400 Avg. Training loss: 0.8835 0.0071 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 344600 Avg. Training loss: 0.9715 0.0074 sec/batch\n",
      "Epoch 19/50 Iteration: 344800 Avg. Training loss: 0.8425 0.0067 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 345000 Avg. Training loss: 0.5617 0.0066 sec/batch\n",
      "Epoch 19/50 Iteration: 345200 Avg. Training loss: 0.8816 0.0069 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 345400 Avg. Training loss: 0.7696 0.0077 sec/batch\n",
      "Epoch 19/50 Iteration: 345600 Avg. Training loss: 0.8200 0.0071 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 345800 Avg. Training loss: 0.9120 0.0054 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 Iteration: 346000 Avg. Training loss: 0.8171 0.0095 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 346200 Avg. Training loss: 0.7673 0.0087 sec/batch\n",
      "Epoch 20/50 Iteration: 346400 Avg. Training loss: 0.7292 0.0077 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 346600 Avg. Training loss: 0.8242 0.0088 sec/batch\n",
      "Epoch 20/50 Iteration: 346800 Avg. Training loss: 0.9355 0.0082 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 347000 Avg. Training loss: 0.5594 0.0078 sec/batch\n",
      "Epoch 20/50 Iteration: 347200 Avg. Training loss: 0.8242 0.0088 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 347400 Avg. Training loss: 0.5472 0.0075 sec/batch\n",
      "Epoch 20/50 Iteration: 347600 Avg. Training loss: 0.7327 0.0073 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 347800 Avg. Training loss: 0.8037 0.0078 sec/batch\n",
      "Epoch 20/50 Iteration: 348000 Avg. Training loss: 1.0156 0.0113 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 348200 Avg. Training loss: 0.7762 0.0085 sec/batch\n",
      "Epoch 20/50 Iteration: 348400 Avg. Training loss: 0.5736 0.0082 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 348600 Avg. Training loss: 0.9073 0.0074 sec/batch\n",
      "Epoch 20/50 Iteration: 348800 Avg. Training loss: 0.6983 0.0069 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 349000 Avg. Training loss: 0.7165 0.0071 sec/batch\n",
      "Epoch 20/50 Iteration: 349200 Avg. Training loss: 0.8052 0.0078 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 349400 Avg. Training loss: 0.8106 0.0068 sec/batch\n",
      "Epoch 20/50 Iteration: 349600 Avg. Training loss: 0.7997 0.0067 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 349800 Avg. Training loss: 0.6685 0.0073 sec/batch\n",
      "Epoch 20/50 Iteration: 350000 Avg. Training loss: 0.6440 0.0068 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 350200 Avg. Training loss: 0.6610 0.0074 sec/batch\n",
      "Epoch 20/50 Iteration: 350400 Avg. Training loss: 0.3978 0.0066 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 350600 Avg. Training loss: 0.5356 0.0075 sec/batch\n",
      "Epoch 20/50 Iteration: 350800 Avg. Training loss: 0.7816 0.0076 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 351000 Avg. Training loss: 0.5818 0.0070 sec/batch\n",
      "Epoch 20/50 Iteration: 351200 Avg. Training loss: 0.9598 0.0077 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 351400 Avg. Training loss: 0.8154 0.0070 sec/batch\n",
      "Epoch 20/50 Iteration: 351600 Avg. Training loss: 0.7943 0.0075 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 351800 Avg. Training loss: 0.5889 0.0071 sec/batch\n",
      "Epoch 20/50 Iteration: 352000 Avg. Training loss: 0.5968 0.0071 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 352200 Avg. Training loss: 0.7140 0.0071 sec/batch\n",
      "Epoch 20/50 Iteration: 352400 Avg. Training loss: 0.6886 0.0070 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 352600 Avg. Training loss: 0.8530 0.0070 sec/batch\n",
      "Epoch 20/50 Iteration: 352800 Avg. Training loss: 0.7681 0.0071 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 353000 Avg. Training loss: 0.8821 0.0070 sec/batch\n",
      "Epoch 20/50 Iteration: 353200 Avg. Training loss: 0.6594 0.0076 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 353400 Avg. Training loss: 0.8622 0.0080 sec/batch\n",
      "Epoch 20/50 Iteration: 353600 Avg. Training loss: 0.5452 0.0084 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 353800 Avg. Training loss: 0.8329 0.0093 sec/batch\n",
      "Epoch 20/50 Iteration: 354000 Avg. Training loss: 0.8400 0.0085 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 354200 Avg. Training loss: 0.8081 0.0090 sec/batch\n",
      "Epoch 20/50 Iteration: 354400 Avg. Training loss: 0.7997 0.0077 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 354600 Avg. Training loss: 0.6990 0.0095 sec/batch\n",
      "Epoch 20/50 Iteration: 354800 Avg. Training loss: 0.9435 0.0086 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 355000 Avg. Training loss: 0.8115 0.0090 sec/batch\n",
      "Epoch 20/50 Iteration: 355200 Avg. Training loss: 0.8661 0.0089 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 355400 Avg. Training loss: 0.5664 0.0080 sec/batch\n",
      "Epoch 20/50 Iteration: 355600 Avg. Training loss: 0.6234 0.0097 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 355800 Avg. Training loss: 0.8320 0.0079 sec/batch\n",
      "Epoch 20/50 Iteration: 356000 Avg. Training loss: 0.9991 0.0078 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 356200 Avg. Training loss: 0.6621 0.0076 sec/batch\n",
      "Epoch 20/50 Iteration: 356400 Avg. Training loss: 0.7110 0.0069 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 356600 Avg. Training loss: 0.6949 0.0065 sec/batch\n",
      "Epoch 20/50 Iteration: 356800 Avg. Training loss: 0.7133 0.0073 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 357000 Avg. Training loss: 0.6059 0.0071 sec/batch\n",
      "Epoch 20/50 Iteration: 357200 Avg. Training loss: 0.7288 0.0071 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 357400 Avg. Training loss: 0.6324 0.0067 sec/batch\n",
      "Epoch 20/50 Iteration: 357600 Avg. Training loss: 0.6153 0.0071 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 357800 Avg. Training loss: 0.7120 0.0074 sec/batch\n",
      "Epoch 20/50 Iteration: 358000 Avg. Training loss: 0.7845 0.0079 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 358200 Avg. Training loss: 0.6666 0.0075 sec/batch\n",
      "Epoch 20/50 Iteration: 358400 Avg. Training loss: 0.6726 0.0076 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 358600 Avg. Training loss: 0.9309 0.0083 sec/batch\n",
      "Epoch 20/50 Iteration: 358800 Avg. Training loss: 0.7904 0.0069 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 359000 Avg. Training loss: 0.6447 0.0085 sec/batch\n",
      "Epoch 20/50 Iteration: 359200 Avg. Training loss: 0.6037 0.0072 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 359400 Avg. Training loss: 0.7144 0.0072 sec/batch\n",
      "Epoch 20/50 Iteration: 359600 Avg. Training loss: 0.7827 0.0073 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 359800 Avg. Training loss: 0.7961 0.0081 sec/batch\n",
      "Epoch 20/50 Iteration: 360000 Avg. Training loss: 0.9096 0.0080 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 360200 Avg. Training loss: 0.8237 0.0084 sec/batch\n",
      "Epoch 20/50 Iteration: 360400 Avg. Training loss: 0.9072 0.0098 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 360600 Avg. Training loss: 0.7884 0.0077 sec/batch\n",
      "Epoch 20/50 Iteration: 360800 Avg. Training loss: 0.8565 0.0086 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 361000 Avg. Training loss: 0.8551 0.0082 sec/batch\n",
      "Epoch 20/50 Iteration: 361200 Avg. Training loss: 0.7962 0.0083 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 361400 Avg. Training loss: 0.8037 0.0097 sec/batch\n",
      "Epoch 20/50 Iteration: 361600 Avg. Training loss: 0.7849 0.0079 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 361800 Avg. Training loss: 0.8480 0.0082 sec/batch\n",
      "Epoch 20/50 Iteration: 362000 Avg. Training loss: 0.3673 0.0080 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 362200 Avg. Training loss: 0.6578 0.0082 sec/batch\n",
      "Epoch 20/50 Iteration: 362400 Avg. Training loss: 0.6915 0.0077 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 362600 Avg. Training loss: 0.8303 0.0082 sec/batch\n",
      "Epoch 20/50 Iteration: 362800 Avg. Training loss: 0.9945 0.0077 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 363000 Avg. Training loss: 0.7887 0.0068 sec/batch\n",
      "Epoch 20/50 Iteration: 363200 Avg. Training loss: 0.7160 0.0068 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 363400 Avg. Training loss: 0.8149 0.0070 sec/batch\n",
      "Epoch 20/50 Iteration: 363600 Avg. Training loss: 0.6887 0.0078 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 363800 Avg. Training loss: 0.6650 0.0072 sec/batch\n",
      "Epoch 21/50 Iteration: 364000 Avg. Training loss: 0.7352 0.0023 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 364200 Avg. Training loss: 0.9001 0.0074 sec/batch\n",
      "Epoch 21/50 Iteration: 364400 Avg. Training loss: 0.7359 0.0072 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 364600 Avg. Training loss: 0.6656 0.0069 sec/batch\n",
      "Epoch 21/50 Iteration: 364800 Avg. Training loss: 0.8090 0.0078 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 365000 Avg. Training loss: 0.7642 0.0074 sec/batch\n",
      "Epoch 21/50 Iteration: 365200 Avg. Training loss: 0.6835 0.0069 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 365400 Avg. Training loss: 0.8007 0.0074 sec/batch\n",
      "Epoch 21/50 Iteration: 365600 Avg. Training loss: 0.7418 0.0071 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 365800 Avg. Training loss: 0.7976 0.0065 sec/batch\n",
      "Epoch 21/50 Iteration: 366000 Avg. Training loss: 0.7323 0.0073 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 366200 Avg. Training loss: 0.9911 0.0074 sec/batch\n",
      "Epoch 21/50 Iteration: 366400 Avg. Training loss: 0.7377 0.0076 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 366600 Avg. Training loss: 0.5348 0.0073 sec/batch\n",
      "Epoch 21/50 Iteration: 366800 Avg. Training loss: 0.7882 0.0089 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 367000 Avg. Training loss: 0.6118 0.0078 sec/batch\n",
      "Epoch 21/50 Iteration: 367200 Avg. Training loss: 0.8449 0.0080 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 Iteration: 367400 Avg. Training loss: 0.6435 0.0090 sec/batch\n",
      "Epoch 21/50 Iteration: 367600 Avg. Training loss: 0.7012 0.0081 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 367800 Avg. Training loss: 0.8052 0.0094 sec/batch\n",
      "Epoch 21/50 Iteration: 368000 Avg. Training loss: 0.7445 0.0084 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 368200 Avg. Training loss: 0.6016 0.0076 sec/batch\n",
      "Epoch 21/50 Iteration: 368400 Avg. Training loss: 0.6134 0.0085 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 368600 Avg. Training loss: 0.5550 0.0083 sec/batch\n",
      "Epoch 21/50 Iteration: 368800 Avg. Training loss: 0.4587 0.0092 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 369000 Avg. Training loss: 0.8197 0.0085 sec/batch\n",
      "Epoch 21/50 Iteration: 369200 Avg. Training loss: 0.7459 0.0074 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 369400 Avg. Training loss: 0.8586 0.0083 sec/batch\n",
      "Epoch 21/50 Iteration: 369600 Avg. Training loss: 0.8460 0.0069 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 369800 Avg. Training loss: 0.7990 0.0075 sec/batch\n",
      "Epoch 21/50 Iteration: 370000 Avg. Training loss: 0.6807 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 370200 Avg. Training loss: 0.5675 0.0070 sec/batch\n",
      "Epoch 21/50 Iteration: 370400 Avg. Training loss: 0.6409 0.0072 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 370600 Avg. Training loss: 0.8143 0.0069 sec/batch\n",
      "Epoch 21/50 Iteration: 370800 Avg. Training loss: 0.7473 0.0069 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 371000 Avg. Training loss: 0.9410 0.0074 sec/batch\n",
      "Epoch 21/50 Iteration: 371200 Avg. Training loss: 0.7215 0.0071 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 371400 Avg. Training loss: 0.5941 0.0076 sec/batch\n",
      "Epoch 21/50 Iteration: 371600 Avg. Training loss: 0.8377 0.0068 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 371800 Avg. Training loss: 0.5025 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 372000 Avg. Training loss: 0.8392 0.0066 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 372200 Avg. Training loss: 0.7709 0.0077 sec/batch\n",
      "Epoch 21/50 Iteration: 372400 Avg. Training loss: 0.8040 0.0082 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 372600 Avg. Training loss: 0.8026 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 372800 Avg. Training loss: 0.7796 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 373000 Avg. Training loss: 0.7904 0.0069 sec/batch\n",
      "Epoch 21/50 Iteration: 373200 Avg. Training loss: 0.7495 0.0072 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 373400 Avg. Training loss: 1.0775 0.0080 sec/batch\n",
      "Epoch 21/50 Iteration: 373600 Avg. Training loss: 0.5588 0.0067 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 373800 Avg. Training loss: 0.5679 0.0069 sec/batch\n",
      "Epoch 21/50 Iteration: 374000 Avg. Training loss: 0.8390 0.0069 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 374200 Avg. Training loss: 0.8227 0.0073 sec/batch\n",
      "Epoch 21/50 Iteration: 374400 Avg. Training loss: 0.7619 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 374600 Avg. Training loss: 0.6953 0.0069 sec/batch\n",
      "Epoch 21/50 Iteration: 374800 Avg. Training loss: 0.6858 0.0068 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 375000 Avg. Training loss: 0.6835 0.0075 sec/batch\n",
      "Epoch 21/50 Iteration: 375200 Avg. Training loss: 0.7546 0.0069 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 375400 Avg. Training loss: 0.7244 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 375600 Avg. Training loss: 0.5800 0.0066 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 375800 Avg. Training loss: 0.7700 0.0070 sec/batch\n",
      "Epoch 21/50 Iteration: 376000 Avg. Training loss: 0.5989 0.0068 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 376200 Avg. Training loss: 0.7166 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 376400 Avg. Training loss: 0.6538 0.0069 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 376600 Avg. Training loss: 0.5796 0.0071 sec/batch\n",
      "Epoch 21/50 Iteration: 376800 Avg. Training loss: 0.8456 0.0082 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 377000 Avg. Training loss: 0.7731 0.0069 sec/batch\n",
      "Epoch 21/50 Iteration: 377200 Avg. Training loss: 0.6599 0.0085 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 377400 Avg. Training loss: 0.6223 0.0072 sec/batch\n",
      "Epoch 21/50 Iteration: 377600 Avg. Training loss: 0.7235 0.0071 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 377800 Avg. Training loss: 0.8926 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 378000 Avg. Training loss: 0.8188 0.0073 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 378200 Avg. Training loss: 0.9554 0.0072 sec/batch\n",
      "Epoch 21/50 Iteration: 378400 Avg. Training loss: 0.9005 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 378600 Avg. Training loss: 0.6901 0.0070 sec/batch\n",
      "Epoch 21/50 Iteration: 378800 Avg. Training loss: 0.5930 0.0066 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 379000 Avg. Training loss: 0.9229 0.0074 sec/batch\n",
      "Epoch 21/50 Iteration: 379200 Avg. Training loss: 0.6233 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 379400 Avg. Training loss: 0.8893 0.0073 sec/batch\n",
      "Epoch 21/50 Iteration: 379600 Avg. Training loss: 0.6824 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 379800 Avg. Training loss: 0.7640 0.0074 sec/batch\n",
      "Epoch 21/50 Iteration: 380000 Avg. Training loss: 0.8679 0.0076 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 380200 Avg. Training loss: 0.5781 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 380400 Avg. Training loss: 0.7608 0.0069 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 380600 Avg. Training loss: 0.6648 0.0066 sec/batch\n",
      "Epoch 21/50 Iteration: 380800 Avg. Training loss: 1.2077 0.0073 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 381000 Avg. Training loss: 0.8687 0.0076 sec/batch\n",
      "Epoch 21/50 Iteration: 381200 Avg. Training loss: 0.8530 0.0069 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 381400 Avg. Training loss: 0.7739 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 381600 Avg. Training loss: 0.7701 0.0072 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 381800 Avg. Training loss: 0.6455 0.0078 sec/batch\n",
      "Epoch 21/50 Iteration: 382000 Avg. Training loss: 0.7276 0.0072 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 382200 Avg. Training loss: 0.8254 0.0024 sec/batch\n",
      "Epoch 22/50 Iteration: 382400 Avg. Training loss: 0.8264 0.0076 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 382600 Avg. Training loss: 0.7066 0.0077 sec/batch\n",
      "Epoch 22/50 Iteration: 382800 Avg. Training loss: 0.6549 0.0070 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 383000 Avg. Training loss: 1.0879 0.0078 sec/batch\n",
      "Epoch 22/50 Iteration: 383200 Avg. Training loss: 0.8009 0.0074 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 383400 Avg. Training loss: 0.6927 0.0068 sec/batch\n",
      "Epoch 22/50 Iteration: 383600 Avg. Training loss: 0.6260 0.0072 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 383800 Avg. Training loss: 0.5242 0.0072 sec/batch\n",
      "Epoch 22/50 Iteration: 384000 Avg. Training loss: 0.7624 0.0065 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 384200 Avg. Training loss: 0.7574 0.0068 sec/batch\n",
      "Epoch 22/50 Iteration: 384400 Avg. Training loss: 0.8130 0.0069 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 384600 Avg. Training loss: 0.8187 0.0074 sec/batch\n",
      "Epoch 22/50 Iteration: 384800 Avg. Training loss: 0.5487 0.0068 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 385000 Avg. Training loss: 0.6970 0.0067 sec/batch\n",
      "Epoch 22/50 Iteration: 385200 Avg. Training loss: 0.6706 0.0068 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 385400 Avg. Training loss: 0.7218 0.0071 sec/batch\n",
      "Epoch 22/50 Iteration: 385600 Avg. Training loss: 0.7031 0.0076 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 385800 Avg. Training loss: 0.7296 0.0067 sec/batch\n",
      "Epoch 22/50 Iteration: 386000 Avg. Training loss: 0.7784 0.0068 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 386200 Avg. Training loss: 0.8060 0.0073 sec/batch\n",
      "Epoch 22/50 Iteration: 386400 Avg. Training loss: 0.7097 0.0067 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 386600 Avg. Training loss: 0.7521 0.0076 sec/batch\n",
      "Epoch 22/50 Iteration: 386800 Avg. Training loss: 0.5021 0.0065 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 387000 Avg. Training loss: 0.5314 0.0066 sec/batch\n",
      "Epoch 22/50 Iteration: 387200 Avg. Training loss: 0.6990 0.0071 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 387400 Avg. Training loss: 0.6411 0.0066 sec/batch\n",
      "Epoch 22/50 Iteration: 387600 Avg. Training loss: 0.8191 0.0076 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 387800 Avg. Training loss: 0.7669 0.0069 sec/batch\n",
      "Epoch 22/50 Iteration: 388000 Avg. Training loss: 0.7660 0.0075 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 388200 Avg. Training loss: 0.5615 0.0069 sec/batch\n",
      "Epoch 22/50 Iteration: 388400 Avg. Training loss: 0.8633 0.0069 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 388600 Avg. Training loss: 0.6642 0.0070 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 Iteration: 388800 Avg. Training loss: 0.7694 0.0067 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 389000 Avg. Training loss: 0.8832 0.0068 sec/batch\n",
      "Epoch 22/50 Iteration: 389200 Avg. Training loss: 0.8801 0.0070 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 389400 Avg. Training loss: 0.8938 0.0069 sec/batch\n",
      "Epoch 22/50 Iteration: 389600 Avg. Training loss: 0.5048 0.0072 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 389800 Avg. Training loss: 0.7202 0.0066 sec/batch\n",
      "Epoch 22/50 Iteration: 390000 Avg. Training loss: 0.5249 0.0068 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 390200 Avg. Training loss: 0.6461 0.0066 sec/batch\n",
      "Epoch 22/50 Iteration: 390400 Avg. Training loss: 0.7298 0.0077 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 390600 Avg. Training loss: 0.7196 0.0079 sec/batch\n",
      "Epoch 22/50 Iteration: 390800 Avg. Training loss: 0.8532 0.0065 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 391000 Avg. Training loss: 0.8178 0.0067 sec/batch\n",
      "Epoch 22/50 Iteration: 391200 Avg. Training loss: 0.8068 0.0069 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 391400 Avg. Training loss: 0.6890 0.0071 sec/batch\n",
      "Epoch 22/50 Iteration: 391600 Avg. Training loss: 0.8385 0.0078 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 391800 Avg. Training loss: 0.5338 0.0068 sec/batch\n",
      "Epoch 22/50 Iteration: 392000 Avg. Training loss: 0.6385 0.0068 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 392200 Avg. Training loss: 0.8833 0.0069 sec/batch\n",
      "Epoch 22/50 Iteration: 392400 Avg. Training loss: 0.6479 0.0072 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 392600 Avg. Training loss: 0.8352 0.0071 sec/batch\n",
      "Epoch 22/50 Iteration: 392800 Avg. Training loss: 0.7743 0.0068 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 393000 Avg. Training loss: 0.8061 0.0066 sec/batch\n",
      "Epoch 22/50 Iteration: 393200 Avg. Training loss: 0.6922 0.0073 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 393400 Avg. Training loss: 0.6244 0.0071 sec/batch\n",
      "Epoch 22/50 Iteration: 393600 Avg. Training loss: 0.6752 0.0068 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 393800 Avg. Training loss: 0.5176 0.0068 sec/batch\n",
      "Epoch 22/50 Iteration: 394000 Avg. Training loss: 0.8505 0.0069 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 394200 Avg. Training loss: 0.5934 0.0070 sec/batch\n",
      "Epoch 22/50 Iteration: 394400 Avg. Training loss: 0.5705 0.0072 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 394600 Avg. Training loss: 0.7379 0.0073 sec/batch\n",
      "Epoch 22/50 Iteration: 394800 Avg. Training loss: 0.7454 0.0070 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 395000 Avg. Training loss: 0.8502 0.0080 sec/batch\n",
      "Epoch 22/50 Iteration: 395200 Avg. Training loss: 0.7187 0.0066 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 395400 Avg. Training loss: 0.6657 0.0083 sec/batch\n",
      "Epoch 22/50 Iteration: 395600 Avg. Training loss: 0.5713 0.0071 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 395800 Avg. Training loss: 0.7429 0.0070 sec/batch\n",
      "Epoch 22/50 Iteration: 396000 Avg. Training loss: 0.6843 0.0067 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 396200 Avg. Training loss: 0.8442 0.0071 sec/batch\n",
      "Epoch 22/50 Iteration: 396400 Avg. Training loss: 0.9165 0.0071 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 396600 Avg. Training loss: 0.8791 0.0069 sec/batch\n",
      "Epoch 22/50 Iteration: 396800 Avg. Training loss: 0.6263 0.0069 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 397000 Avg. Training loss: 0.6481 0.0082 sec/batch\n",
      "Epoch 22/50 Iteration: 397200 Avg. Training loss: 0.9097 0.0070 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 397400 Avg. Training loss: 0.9828 0.0070 sec/batch\n",
      "Epoch 22/50 Iteration: 397600 Avg. Training loss: 0.8678 0.0072 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 397800 Avg. Training loss: 0.6536 0.0067 sec/batch\n",
      "Epoch 22/50 Iteration: 398000 Avg. Training loss: 0.7741 0.0070 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 398200 Avg. Training loss: 0.9375 0.0073 sec/batch\n",
      "Epoch 22/50 Iteration: 398400 Avg. Training loss: 0.5892 0.0067 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 398600 Avg. Training loss: 0.7325 0.0070 sec/batch\n",
      "Epoch 22/50 Iteration: 398800 Avg. Training loss: 0.6118 0.0066 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 399000 Avg. Training loss: 0.9359 0.0072 sec/batch\n",
      "Epoch 22/50 Iteration: 399200 Avg. Training loss: 1.0251 0.0074 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 399400 Avg. Training loss: 0.7723 0.0070 sec/batch\n",
      "Epoch 22/50 Iteration: 399600 Avg. Training loss: 0.6766 0.0071 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 399800 Avg. Training loss: 0.6421 0.0071 sec/batch\n",
      "Epoch 22/50 Iteration: 400000 Avg. Training loss: 0.6020 0.0078 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 400200 Avg. Training loss: 0.7153 0.0071 sec/batch\n",
      "Epoch 23/50 Iteration: 400400 Avg. Training loss: 0.6925 0.0025 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 400600 Avg. Training loss: 0.7920 0.0074 sec/batch\n",
      "Epoch 23/50 Iteration: 400800 Avg. Training loss: 0.8791 0.0071 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 401000 Avg. Training loss: 0.6902 0.0069 sec/batch\n",
      "Epoch 23/50 Iteration: 401200 Avg. Training loss: 0.8662 0.0078 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 401400 Avg. Training loss: 0.8230 0.0073 sec/batch\n",
      "Epoch 23/50 Iteration: 401600 Avg. Training loss: 0.7131 0.0067 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 401800 Avg. Training loss: 0.8164 0.0073 sec/batch\n",
      "Epoch 23/50 Iteration: 402000 Avg. Training loss: 0.5654 0.0071 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 402200 Avg. Training loss: 0.7154 0.0066 sec/batch\n",
      "Epoch 23/50 Iteration: 402400 Avg. Training loss: 0.7294 0.0066 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 402600 Avg. Training loss: 0.9985 0.0068 sec/batch\n",
      "Epoch 23/50 Iteration: 402800 Avg. Training loss: 0.6899 0.0072 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 403000 Avg. Training loss: 0.4933 0.0068 sec/batch\n",
      "Epoch 23/50 Iteration: 403200 Avg. Training loss: 0.8871 0.0070 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 403400 Avg. Training loss: 0.6869 0.0070 sec/batch\n",
      "Epoch 23/50 Iteration: 403600 Avg. Training loss: 0.6702 0.0072 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 403800 Avg. Training loss: 0.8682 0.0075 sec/batch\n",
      "Epoch 23/50 Iteration: 404000 Avg. Training loss: 0.6597 0.0066 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 404200 Avg. Training loss: 0.6850 0.0068 sec/batch\n",
      "Epoch 23/50 Iteration: 404400 Avg. Training loss: 0.8663 0.0070 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 404600 Avg. Training loss: 0.5939 0.0066 sec/batch\n",
      "Epoch 23/50 Iteration: 404800 Avg. Training loss: 0.6392 0.0073 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 405000 Avg. Training loss: 0.4146 0.0065 sec/batch\n",
      "Epoch 23/50 Iteration: 405200 Avg. Training loss: 0.5897 0.0066 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 405400 Avg. Training loss: 0.7888 0.0072 sec/batch\n",
      "Epoch 23/50 Iteration: 405600 Avg. Training loss: 0.5820 0.0066 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 405800 Avg. Training loss: 1.0069 0.0077 sec/batch\n",
      "Epoch 23/50 Iteration: 406000 Avg. Training loss: 0.9061 0.0068 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 406200 Avg. Training loss: 0.8742 0.0075 sec/batch\n",
      "Epoch 23/50 Iteration: 406400 Avg. Training loss: 0.5835 0.0069 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 406600 Avg. Training loss: 0.7958 0.0070 sec/batch\n",
      "Epoch 23/50 Iteration: 406800 Avg. Training loss: 0.6561 0.0070 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 407000 Avg. Training loss: 0.8313 0.0068 sec/batch\n",
      "Epoch 23/50 Iteration: 407200 Avg. Training loss: 0.8210 0.0067 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 407400 Avg. Training loss: 0.9512 0.0070 sec/batch\n",
      "Epoch 23/50 Iteration: 407600 Avg. Training loss: 0.9026 0.0069 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 407800 Avg. Training loss: 0.6710 0.0073 sec/batch\n",
      "Epoch 23/50 Iteration: 408000 Avg. Training loss: 0.7403 0.0066 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 408200 Avg. Training loss: 0.4665 0.0065 sec/batch\n",
      "Epoch 23/50 Iteration: 408400 Avg. Training loss: 0.5648 0.0065 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 408600 Avg. Training loss: 1.0725 0.0077 sec/batch\n",
      "Epoch 23/50 Iteration: 408800 Avg. Training loss: 0.7947 0.0078 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 409000 Avg. Training loss: 0.6730 0.0064 sec/batch\n",
      "Epoch 23/50 Iteration: 409200 Avg. Training loss: 0.6522 0.0068 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 409400 Avg. Training loss: 0.8583 0.0069 sec/batch\n",
      "Epoch 23/50 Iteration: 409600 Avg. Training loss: 0.8030 0.0070 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 409800 Avg. Training loss: 0.9433 0.0078 sec/batch\n",
      "Epoch 23/50 Iteration: 410000 Avg. Training loss: 0.5878 0.0067 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 Iteration: 410200 Avg. Training loss: 0.5503 0.0069 sec/batch\n",
      "Epoch 23/50 Iteration: 410400 Avg. Training loss: 0.7714 0.0069 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 410600 Avg. Training loss: 0.7912 0.0072 sec/batch\n",
      "Epoch 23/50 Iteration: 410800 Avg. Training loss: 0.7810 0.0071 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 411000 Avg. Training loss: 0.8865 0.0066 sec/batch\n",
      "Epoch 23/50 Iteration: 411200 Avg. Training loss: 0.8844 0.0065 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 411400 Avg. Training loss: 0.6729 0.0072 sec/batch\n",
      "Epoch 23/50 Iteration: 411600 Avg. Training loss: 0.6526 0.0068 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 411800 Avg. Training loss: 0.7203 0.0066 sec/batch\n",
      "Epoch 23/50 Iteration: 412000 Avg. Training loss: 0.6428 0.0065 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 412200 Avg. Training loss: 0.6784 0.0067 sec/batch\n",
      "Epoch 23/50 Iteration: 412400 Avg. Training loss: 0.6380 0.0068 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 412600 Avg. Training loss: 0.6545 0.0068 sec/batch\n",
      "Epoch 23/50 Iteration: 412800 Avg. Training loss: 0.7320 0.0067 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 413000 Avg. Training loss: 0.5889 0.0071 sec/batch\n",
      "Epoch 23/50 Iteration: 413200 Avg. Training loss: 0.9017 0.0080 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 413400 Avg. Training loss: 0.5581 0.0068 sec/batch\n",
      "Epoch 23/50 Iteration: 413600 Avg. Training loss: 0.7669 0.0083 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 413800 Avg. Training loss: 0.6688 0.0071 sec/batch\n",
      "Epoch 23/50 Iteration: 414000 Avg. Training loss: 0.8080 0.0070 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 414200 Avg. Training loss: 0.7524 0.0065 sec/batch\n",
      "Epoch 23/50 Iteration: 414400 Avg. Training loss: 0.6744 0.0071 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 414600 Avg. Training loss: 0.9860 0.0070 sec/batch\n",
      "Epoch 23/50 Iteration: 414800 Avg. Training loss: 0.7353 0.0069 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 415000 Avg. Training loss: 0.8883 0.0068 sec/batch\n",
      "Epoch 23/50 Iteration: 415200 Avg. Training loss: 0.7815 0.0068 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 415400 Avg. Training loss: 0.9104 0.0070 sec/batch\n",
      "Epoch 23/50 Iteration: 415600 Avg. Training loss: 0.8644 0.0068 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 415800 Avg. Training loss: 0.7189 0.0072 sec/batch\n",
      "Epoch 23/50 Iteration: 416000 Avg. Training loss: 0.8742 0.0066 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 416200 Avg. Training loss: 0.7612 0.0070 sec/batch\n",
      "Epoch 23/50 Iteration: 416400 Avg. Training loss: 0.8584 0.0072 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 416600 Avg. Training loss: 0.5640 0.0072 sec/batch\n",
      "Epoch 23/50 Iteration: 416800 Avg. Training loss: 0.6911 0.0072 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 417000 Avg. Training loss: 0.7486 0.0066 sec/batch\n",
      "Epoch 23/50 Iteration: 417200 Avg. Training loss: 0.7407 0.0071 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 417400 Avg. Training loss: 0.9307 0.0073 sec/batch\n",
      "Epoch 23/50 Iteration: 417600 Avg. Training loss: 0.9262 0.0067 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 417800 Avg. Training loss: 0.4915 0.0066 sec/batch\n",
      "Epoch 23/50 Iteration: 418000 Avg. Training loss: 0.8308 0.0069 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 418200 Avg. Training loss: 0.6460 0.0077 sec/batch\n",
      "Epoch 23/50 Iteration: 418400 Avg. Training loss: 0.7320 0.0070 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 418600 Avg. Training loss: 0.8450 0.0027 sec/batch\n",
      "Epoch 24/50 Iteration: 418800 Avg. Training loss: 0.9497 0.0072 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 419000 Avg. Training loss: 0.7039 0.0070 sec/batch\n",
      "Epoch 24/50 Iteration: 419200 Avg. Training loss: 0.7613 0.0069 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 419400 Avg. Training loss: 0.9736 0.0077 sec/batch\n",
      "Epoch 24/50 Iteration: 419600 Avg. Training loss: 0.7801 0.0073 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 419800 Avg. Training loss: 0.7044 0.0068 sec/batch\n",
      "Epoch 24/50 Iteration: 420000 Avg. Training loss: 0.7497 0.0073 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 420200 Avg. Training loss: 0.7031 0.0070 sec/batch\n",
      "Epoch 24/50 Iteration: 420400 Avg. Training loss: 0.8106 0.0066 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 420600 Avg. Training loss: 0.8047 0.0067 sec/batch\n",
      "Epoch 24/50 Iteration: 420800 Avg. Training loss: 0.9319 0.0068 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 421000 Avg. Training loss: 0.6699 0.0074 sec/batch\n",
      "Epoch 24/50 Iteration: 421200 Avg. Training loss: 0.5831 0.0067 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 421400 Avg. Training loss: 0.8143 0.0068 sec/batch\n",
      "Epoch 24/50 Iteration: 421600 Avg. Training loss: 0.6471 0.0068 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 421800 Avg. Training loss: 0.8441 0.0070 sec/batch\n",
      "Epoch 24/50 Iteration: 422000 Avg. Training loss: 0.8603 0.0074 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 422200 Avg. Training loss: 0.9087 0.0068 sec/batch\n",
      "Epoch 24/50 Iteration: 422400 Avg. Training loss: 0.9817 0.0068 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 422600 Avg. Training loss: 0.7029 0.0069 sec/batch\n",
      "Epoch 24/50 Iteration: 422800 Avg. Training loss: 0.6019 0.0066 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 423000 Avg. Training loss: 0.7061 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 423200 Avg. Training loss: 0.4519 0.0067 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 423400 Avg. Training loss: 0.6326 0.0066 sec/batch\n",
      "Epoch 24/50 Iteration: 423600 Avg. Training loss: 0.7484 0.0070 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 423800 Avg. Training loss: 0.8064 0.0067 sec/batch\n",
      "Epoch 24/50 Iteration: 424000 Avg. Training loss: 0.9192 0.0077 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 424200 Avg. Training loss: 0.8393 0.0068 sec/batch\n",
      "Epoch 24/50 Iteration: 424400 Avg. Training loss: 0.8174 0.0074 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 424600 Avg. Training loss: 0.5901 0.0068 sec/batch\n",
      "Epoch 24/50 Iteration: 424800 Avg. Training loss: 0.8167 0.0141 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 425000 Avg. Training loss: 0.7226 0.0081 sec/batch\n",
      "Epoch 24/50 Iteration: 425200 Avg. Training loss: 0.8826 0.0068 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 425400 Avg. Training loss: 0.5313 0.0067 sec/batch\n",
      "Epoch 24/50 Iteration: 425600 Avg. Training loss: 0.7918 0.0070 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 425800 Avg. Training loss: 0.9205 0.0069 sec/batch\n",
      "Epoch 24/50 Iteration: 426000 Avg. Training loss: 0.5278 0.0072 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 426200 Avg. Training loss: 0.6199 0.0067 sec/batch\n",
      "Epoch 24/50 Iteration: 426400 Avg. Training loss: 0.4749 0.0067 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 426600 Avg. Training loss: 0.7362 0.0066 sec/batch\n",
      "Epoch 24/50 Iteration: 426800 Avg. Training loss: 0.7740 0.0078 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 427000 Avg. Training loss: 0.7745 0.0077 sec/batch\n",
      "Epoch 24/50 Iteration: 427200 Avg. Training loss: 0.8556 0.0065 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 427400 Avg. Training loss: 0.6690 0.0067 sec/batch\n",
      "Epoch 24/50 Iteration: 427600 Avg. Training loss: 0.7846 0.0069 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 427800 Avg. Training loss: 0.7971 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 428000 Avg. Training loss: 0.9479 0.0077 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 428200 Avg. Training loss: 0.5453 0.0067 sec/batch\n",
      "Epoch 24/50 Iteration: 428400 Avg. Training loss: 0.7106 0.0068 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 428600 Avg. Training loss: 0.9844 0.0069 sec/batch\n",
      "Epoch 24/50 Iteration: 428800 Avg. Training loss: 0.8033 0.0072 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 429000 Avg. Training loss: 0.7316 0.0070 sec/batch\n",
      "Epoch 24/50 Iteration: 429200 Avg. Training loss: 0.6805 0.0066 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 429400 Avg. Training loss: 0.6628 0.0065 sec/batch\n",
      "Epoch 24/50 Iteration: 429600 Avg. Training loss: 0.7381 0.0072 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 429800 Avg. Training loss: 0.7671 0.0070 sec/batch\n",
      "Epoch 24/50 Iteration: 430000 Avg. Training loss: 0.7303 0.0067 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 430200 Avg. Training loss: 0.6079 0.0066 sec/batch\n",
      "Epoch 24/50 Iteration: 430400 Avg. Training loss: 0.6891 0.0068 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 430600 Avg. Training loss: 0.6071 0.0067 sec/batch\n",
      "Epoch 24/50 Iteration: 430800 Avg. Training loss: 0.6415 0.0069 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 431000 Avg. Training loss: 0.7247 0.0069 sec/batch\n",
      "Epoch 24/50 Iteration: 431200 Avg. Training loss: 0.6186 0.0071 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 431400 Avg. Training loss: 0.8882 0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 Iteration: 431600 Avg. Training loss: 0.7768 0.0067 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 431800 Avg. Training loss: 0.6953 0.0084 sec/batch\n",
      "Epoch 24/50 Iteration: 432000 Avg. Training loss: 0.7497 0.0070 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 432200 Avg. Training loss: 0.8377 0.0071 sec/batch\n",
      "Epoch 24/50 Iteration: 432400 Avg. Training loss: 0.7455 0.0066 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 432600 Avg. Training loss: 1.0015 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 432800 Avg. Training loss: 0.8511 0.0070 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 433000 Avg. Training loss: 0.8126 0.0070 sec/batch\n",
      "Epoch 24/50 Iteration: 433200 Avg. Training loss: 0.7718 0.0068 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 433400 Avg. Training loss: 0.7436 0.0066 sec/batch\n",
      "Epoch 24/50 Iteration: 433600 Avg. Training loss: 0.7382 0.0074 sec/batch\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "keypath = 'data/pros_1__cus_key.npy'\n",
    "datapath  ='data/pros_1__cus.npy'\n",
    "n_embedding = 10\n",
    "n_sampled = 3\n",
    "epochs = 50\n",
    "batch_size = 1000\n",
    "window_size = 1000\n",
    "ch_save = \"checkpoints_close/text8.ckpt\"\n",
    "savename='data/w2v_mat_cus_10_1000'\n",
    "\n",
    "Tdl = Train_data_load()\n",
    "\n",
    "Tdl.auto_train(datapath,keypath,n_embedding ,\\\n",
    "n_sampled,\\\n",
    "epochs,\\\n",
    "batch_size,\\\n",
    "window_size,\\\n",
    "ch_save,\\\n",
    "savename=savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "keypath = 'data/pros_1__shop_key.npy'\n",
    "datapath  ='data/pros_1__shop.npy'\n",
    "n_embedding = 3\n",
    "n_sampled = 5\n",
    "epochs = 20\n",
    "batch_size = 1000\n",
    "window_size = 10\n",
    "ch_save = \"checkpoints_close/text9.ckpt\"\n",
    "savename='data/w2v_mat_shop_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tdl = Train_data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tdl.auto_train(datapath,keypath,n_embedding ,\\\n",
    "n_sampled,\\\n",
    "epochs,\\\n",
    "batch_size,\\\n",
    "window_size,\\\n",
    "ch_save,\\\n",
    "savename=savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_data('shop',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
