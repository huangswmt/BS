{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wangls/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from data_process.process_data import *\n",
    "\n",
    "from skip_grame.skip_gram import *\n",
    "\n",
    "from visualize.visualize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.10067114093959731\n",
      "0.20134228187919462\n",
      "0.30201342281879195\n",
      "0.40268456375838924\n",
      "0.5033557046979866\n",
      "0.6040268456375839\n",
      "0.7046979865771812\n",
      "0.8053691275167785\n",
      "0.9060402684563759\n"
     ]
    }
   ],
   "source": [
    "DPS = Data_Prep_shop(auto = False)\n",
    "DPS.shop_name_clean()\n",
    "DPS.frequancy_filter()\n",
    "DPS.depart_group_of_cus()\n",
    "DPS.save_cus_result('pros_1_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('data/pros_1__cus2.npy',allow_pickle=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DPS = Data_Prep_shop(auto = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 Iteration: 200 Avg. Training loss: 1.5636 0.0159 sec/batch\n",
      "Epoch 1/50 Iteration: 400 Avg. Training loss: 1.5788 0.0142 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 600 Avg. Training loss: 1.4762 0.0144 sec/batch\n",
      "Epoch 1/50 Iteration: 800 Avg. Training loss: 1.5375 0.0144 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 1000 Avg. Training loss: 1.5921 0.0142 sec/batch\n",
      "Epoch 1/50 Iteration: 1200 Avg. Training loss: 1.4357 0.0138 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 1400 Avg. Training loss: 1.6590 0.0146 sec/batch\n",
      "Epoch 1/50 Iteration: 1600 Avg. Training loss: 1.3910 0.0141 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 1800 Avg. Training loss: 1.5602 0.0139 sec/batch\n",
      "Epoch 1/50 Iteration: 2000 Avg. Training loss: 1.6203 0.0135 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 2200 Avg. Training loss: 1.5181 0.0138 sec/batch\n",
      "Epoch 1/50 Iteration: 2400 Avg. Training loss: 1.4986 0.0146 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 2600 Avg. Training loss: 1.5487 0.0148 sec/batch\n",
      "Epoch 1/50 Iteration: 2800 Avg. Training loss: 1.6439 0.0149 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 3000 Avg. Training loss: 1.4753 0.0149 sec/batch\n",
      "Epoch 1/50 Iteration: 3200 Avg. Training loss: 1.6447 0.0148 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 3400 Avg. Training loss: 1.6122 0.0152 sec/batch\n",
      "Epoch 1/50 Iteration: 3600 Avg. Training loss: 1.5255 0.0144 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 3800 Avg. Training loss: 1.6489 0.0148 sec/batch\n",
      "Epoch 1/50 Iteration: 4000 Avg. Training loss: 1.4293 0.0148 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 4200 Avg. Training loss: 1.6917 0.0139 sec/batch\n",
      "Epoch 1/50 Iteration: 4400 Avg. Training loss: 1.5717 0.0150 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 4600 Avg. Training loss: 1.5756 0.0162 sec/batch\n",
      "Epoch 1/50 Iteration: 4800 Avg. Training loss: 1.5003 0.0143 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 5000 Avg. Training loss: 1.4937 0.0149 sec/batch\n",
      "Epoch 1/50 Iteration: 5200 Avg. Training loss: 1.6637 0.0148 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 5400 Avg. Training loss: 1.6459 0.0150 sec/batch\n",
      "Epoch 1/50 Iteration: 5600 Avg. Training loss: 1.5526 0.0150 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 5800 Avg. Training loss: 1.5115 0.0146 sec/batch\n",
      "Epoch 1/50 Iteration: 6000 Avg. Training loss: 1.4600 0.0136 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 6200 Avg. Training loss: 1.4163 0.0138 sec/batch\n",
      "Epoch 1/50 Iteration: 6400 Avg. Training loss: 1.6504 0.0137 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 6600 Avg. Training loss: 1.3730 0.0138 sec/batch\n",
      "Epoch 1/50 Iteration: 6800 Avg. Training loss: 1.5392 0.0136 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 7000 Avg. Training loss: 1.4105 0.0146 sec/batch\n",
      "Epoch 1/50 Iteration: 7200 Avg. Training loss: 1.6105 0.0141 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 7400 Avg. Training loss: 1.5739 0.0147 sec/batch\n",
      "Epoch 1/50 Iteration: 7600 Avg. Training loss: 1.5331 0.0141 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 7800 Avg. Training loss: 1.3686 0.0140 sec/batch\n",
      "Epoch 1/50 Iteration: 8000 Avg. Training loss: 1.5329 0.0142 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 8200 Avg. Training loss: 1.4671 0.0142 sec/batch\n",
      "Epoch 1/50 Iteration: 8400 Avg. Training loss: 1.5401 0.0155 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 8600 Avg. Training loss: 1.7773 0.0137 sec/batch\n",
      "Epoch 1/50 Iteration: 8800 Avg. Training loss: 1.5987 0.0137 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 9000 Avg. Training loss: 1.3084 0.0139 sec/batch\n",
      "Epoch 1/50 Iteration: 9200 Avg. Training loss: 1.4405 0.0138 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 9400 Avg. Training loss: 1.4549 0.0148 sec/batch\n",
      "Epoch 1/50 Iteration: 9600 Avg. Training loss: 1.5503 0.0140 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 9800 Avg. Training loss: 1.3991 0.0139 sec/batch\n",
      "Epoch 1/50 Iteration: 10000 Avg. Training loss: 1.4725 0.0141 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 10200 Avg. Training loss: 1.6288 0.0146 sec/batch\n",
      "Epoch 1/50 Iteration: 10400 Avg. Training loss: 1.5897 0.0140 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 10600 Avg. Training loss: 1.3922 0.0141 sec/batch\n",
      "Epoch 1/50 Iteration: 10800 Avg. Training loss: 1.4806 0.0141 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 11000 Avg. Training loss: 1.4952 0.0142 sec/batch\n",
      "Epoch 1/50 Iteration: 11200 Avg. Training loss: 1.4878 0.0149 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 11400 Avg. Training loss: 1.5033 0.0138 sec/batch\n",
      "Epoch 1/50 Iteration: 11600 Avg. Training loss: 1.3949 0.0139 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 11800 Avg. Training loss: 1.3791 0.0138 sec/batch\n",
      "Epoch 1/50 Iteration: 12000 Avg. Training loss: 1.3355 0.0140 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 12200 Avg. Training loss: 1.4746 0.0142 sec/batch\n",
      "Epoch 1/50 Iteration: 12400 Avg. Training loss: 1.6599 0.0140 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 12600 Avg. Training loss: 1.4697 0.0142 sec/batch\n",
      "Epoch 1/50 Iteration: 12800 Avg. Training loss: 1.2625 0.0147 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 13000 Avg. Training loss: 1.4538 0.0140 sec/batch\n",
      "Epoch 1/50 Iteration: 13200 Avg. Training loss: 1.6865 0.0146 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 13400 Avg. Training loss: 1.4990 0.0142 sec/batch\n",
      "Epoch 1/50 Iteration: 13600 Avg. Training loss: 1.5090 0.0146 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 13800 Avg. Training loss: 1.6163 0.0141 sec/batch\n",
      "Epoch 1/50 Iteration: 14000 Avg. Training loss: 1.5534 0.0141 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 14200 Avg. Training loss: 1.5862 0.0138 sec/batch\n",
      "Epoch 1/50 Iteration: 14400 Avg. Training loss: 1.5045 0.0145 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 14600 Avg. Training loss: 1.3698 0.0138 sec/batch\n",
      "Epoch 1/50 Iteration: 14800 Avg. Training loss: 1.7375 0.0136 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 15000 Avg. Training loss: 1.4831 0.0141 sec/batch\n",
      "Epoch 1/50 Iteration: 15200 Avg. Training loss: 1.6658 0.0143 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 15400 Avg. Training loss: 1.4455 0.0142 sec/batch\n",
      "Epoch 1/50 Iteration: 15600 Avg. Training loss: 1.4618 0.0142 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 15800 Avg. Training loss: 1.4234 0.0137 sec/batch\n",
      "Epoch 1/50 Iteration: 16000 Avg. Training loss: 1.5157 0.0145 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 16200 Avg. Training loss: 1.5314 0.0142 sec/batch\n",
      "Epoch 1/50 Iteration: 16400 Avg. Training loss: 1.3890 0.0140 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 16600 Avg. Training loss: 1.6026 0.0136 sec/batch\n",
      "Epoch 1/50 Iteration: 16800 Avg. Training loss: 1.4856 0.0140 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 17000 Avg. Training loss: 1.5537 0.0157 sec/batch\n",
      "Epoch 1/50 Iteration: 17200 Avg. Training loss: 1.5644 0.0142 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 17400 Avg. Training loss: 1.5280 0.0144 sec/batch\n",
      "Epoch 1/50 Iteration: 17600 Avg. Training loss: 1.4729 0.0143 sec/batch\n",
      "error\n",
      "Epoch 1/50 Iteration: 17800 Avg. Training loss: 1.4114 0.0145 sec/batch\n",
      "Epoch 1/50 Iteration: 18000 Avg. Training loss: 1.4596 0.0151 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 18200 Avg. Training loss: 1.5220 0.0003 sec/batch\n",
      "Epoch 2/50 Iteration: 18400 Avg. Training loss: 1.5812 0.0143 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 18600 Avg. Training loss: 1.4515 0.0144 sec/batch\n",
      "Epoch 2/50 Iteration: 18800 Avg. Training loss: 1.2967 0.0141 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 19000 Avg. Training loss: 1.6642 0.0150 sec/batch\n",
      "Epoch 2/50 Iteration: 28000 Avg. Training loss: 1.2820 0.0136 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 28200 Avg. Training loss: 1.3759 0.0141 sec/batch\n",
      "Epoch 2/50 Iteration: 28400 Avg. Training loss: 1.4043 0.0145 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 28600 Avg. Training loss: 1.4029 0.0143 sec/batch\n",
      "Epoch 2/50 Iteration: 28800 Avg. Training loss: 1.2860 0.0146 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 29000 Avg. Training loss: 1.2325 0.0149 sec/batch\n",
      "Epoch 2/50 Iteration: 29200 Avg. Training loss: 1.4336 0.0151 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 29400 Avg. Training loss: 1.3106 0.0151 sec/batch\n",
      "Epoch 2/50 Iteration: 29600 Avg. Training loss: 1.4205 0.0141 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 29800 Avg. Training loss: 1.3243 0.0146 sec/batch\n",
      "Epoch 2/50 Iteration: 30000 Avg. Training loss: 1.3252 0.0144 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 30200 Avg. Training loss: 1.3057 0.0141 sec/batch\n",
      "Epoch 2/50 Iteration: 30400 Avg. Training loss: 1.3440 0.0140 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 30600 Avg. Training loss: 1.4754 0.0139 sec/batch\n",
      "Epoch 2/50 Iteration: 30800 Avg. Training loss: 1.5333 0.0139 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 Iteration: 31000 Avg. Training loss: 1.3338 0.0148 sec/batch\n",
      "Epoch 2/50 Iteration: 31200 Avg. Training loss: 1.4182 0.0143 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 31400 Avg. Training loss: 1.3563 0.0148 sec/batch\n",
      "Epoch 2/50 Iteration: 31600 Avg. Training loss: 1.2980 0.0144 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 31800 Avg. Training loss: 1.3262 0.0138 sec/batch\n",
      "Epoch 2/50 Iteration: 32000 Avg. Training loss: 1.5113 0.0134 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 32200 Avg. Training loss: 1.4011 0.0139 sec/batch\n",
      "Epoch 2/50 Iteration: 32400 Avg. Training loss: 1.4175 0.0138 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 32600 Avg. Training loss: 1.3764 0.0140 sec/batch\n",
      "Epoch 2/50 Iteration: 32800 Avg. Training loss: 1.3989 0.0139 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 33000 Avg. Training loss: 1.3284 0.0217 sec/batch\n",
      "Epoch 2/50 Iteration: 33200 Avg. Training loss: 1.4910 0.0141 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 33400 Avg. Training loss: 1.4367 0.0142 sec/batch\n",
      "Epoch 2/50 Iteration: 33600 Avg. Training loss: 1.3601 0.0137 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 33800 Avg. Training loss: 1.4691 0.0138 sec/batch\n",
      "Epoch 2/50 Iteration: 34000 Avg. Training loss: 1.3316 0.0137 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 34200 Avg. Training loss: 1.5165 0.0139 sec/batch\n",
      "Epoch 2/50 Iteration: 34400 Avg. Training loss: 1.2169 0.0139 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 34600 Avg. Training loss: 1.1841 0.0137 sec/batch\n",
      "Epoch 2/50 Iteration: 34800 Avg. Training loss: 1.4730 0.0135 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 35000 Avg. Training loss: 1.4120 0.0133 sec/batch\n",
      "Epoch 2/50 Iteration: 35200 Avg. Training loss: 1.5035 0.0144 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 35400 Avg. Training loss: 1.5158 0.0138 sec/batch\n",
      "Epoch 2/50 Iteration: 35600 Avg. Training loss: 1.2918 0.0136 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 35800 Avg. Training loss: 1.3670 0.0139 sec/batch\n",
      "Epoch 2/50 Iteration: 36000 Avg. Training loss: 1.1499 0.0144 sec/batch\n",
      "error\n",
      "Epoch 2/50 Iteration: 36200 Avg. Training loss: 1.4497 0.0142 sec/batch\n",
      "Epoch 3/50 Iteration: 36400 Avg. Training loss: 1.3674 0.0004 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 36600 Avg. Training loss: 1.4733 0.0140 sec/batch\n",
      "Epoch 3/50 Iteration: 36800 Avg. Training loss: 1.3497 0.0142 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 37000 Avg. Training loss: 1.1572 0.0139 sec/batch\n",
      "Epoch 3/50 Iteration: 37200 Avg. Training loss: 1.3947 0.0143 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 37400 Avg. Training loss: 1.3388 0.0144 sec/batch\n",
      "Epoch 3/50 Iteration: 37600 Avg. Training loss: 1.2728 0.0138 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 37800 Avg. Training loss: 1.5579 0.0144 sec/batch\n",
      "Epoch 3/50 Iteration: 38000 Avg. Training loss: 1.1754 0.0141 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 38200 Avg. Training loss: 1.3218 0.0136 sec/batch\n",
      "Epoch 3/50 Iteration: 38400 Avg. Training loss: 1.3271 0.0138 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 38600 Avg. Training loss: 1.3973 0.0139 sec/batch\n",
      "Epoch 3/50 Iteration: 38800 Avg. Training loss: 1.2129 0.0138 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 39000 Avg. Training loss: 1.2765 0.0137 sec/batch\n",
      "Epoch 3/50 Iteration: 39200 Avg. Training loss: 1.3542 0.0137 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 39400 Avg. Training loss: 1.3606 0.0140 sec/batch\n",
      "Epoch 3/50 Iteration: 39600 Avg. Training loss: 1.3498 0.0137 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 39800 Avg. Training loss: 1.3764 0.0145 sec/batch\n",
      "Epoch 3/50 Iteration: 40000 Avg. Training loss: 1.3530 0.0143 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 40200 Avg. Training loss: 1.3113 0.0138 sec/batch\n",
      "Epoch 3/50 Iteration: 40400 Avg. Training loss: 1.3836 0.0139 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 40600 Avg. Training loss: 1.2763 0.0142 sec/batch\n",
      "Epoch 3/50 Iteration: 40800 Avg. Training loss: 1.3162 0.0152 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 41000 Avg. Training loss: 1.1495 0.0151 sec/batch\n",
      "Epoch 3/50 Iteration: 41200 Avg. Training loss: 1.2818 0.0149 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 41400 Avg. Training loss: 1.3177 0.0149 sec/batch\n",
      "Epoch 3/50 Iteration: 41600 Avg. Training loss: 1.2904 0.0148 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 41800 Avg. Training loss: 1.3490 0.0149 sec/batch\n",
      "Epoch 3/50 Iteration: 42000 Avg. Training loss: 1.4582 0.0159 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 42200 Avg. Training loss: 1.2230 0.0166 sec/batch\n",
      "Epoch 3/50 Iteration: 42400 Avg. Training loss: 1.2037 0.0164 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 42600 Avg. Training loss: 1.3102 0.0163 sec/batch\n",
      "Epoch 3/50 Iteration: 42800 Avg. Training loss: 1.3700 0.0167 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 43000 Avg. Training loss: 1.3225 0.0162 sec/batch\n",
      "Epoch 3/50 Iteration: 43200 Avg. Training loss: 1.2628 0.0158 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 43400 Avg. Training loss: 1.3351 0.0169 sec/batch\n",
      "Epoch 3/50 Iteration: 43600 Avg. Training loss: 1.3797 0.0162 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 43800 Avg. Training loss: 1.2693 0.0166 sec/batch\n",
      "Epoch 3/50 Iteration: 44000 Avg. Training loss: 1.2348 0.0161 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 44200 Avg. Training loss: 1.2417 0.0159 sec/batch\n",
      "Epoch 3/50 Iteration: 44400 Avg. Training loss: 1.2522 0.0161 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 44600 Avg. Training loss: 1.2552 0.0163 sec/batch\n",
      "Epoch 3/50 Iteration: 44800 Avg. Training loss: 1.4795 0.0172 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 45000 Avg. Training loss: 1.3594 0.0158 sec/batch\n",
      "Epoch 3/50 Iteration: 45200 Avg. Training loss: 1.3686 0.0156 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 45400 Avg. Training loss: 1.2793 0.0159 sec/batch\n",
      "Epoch 3/50 Iteration: 45600 Avg. Training loss: 1.3212 0.0160 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 45800 Avg. Training loss: 1.3238 0.0175 sec/batch\n",
      "Epoch 3/50 Iteration: 46000 Avg. Training loss: 1.3965 0.0155 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 46200 Avg. Training loss: 1.1886 0.0159 sec/batch\n",
      "Epoch 3/50 Iteration: 46400 Avg. Training loss: 1.4355 0.0159 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 46600 Avg. Training loss: 1.3337 0.0165 sec/batch\n",
      "Epoch 3/50 Iteration: 46800 Avg. Training loss: 1.2327 0.0159 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 47000 Avg. Training loss: 1.3198 0.0159 sec/batch\n",
      "Epoch 3/50 Iteration: 47200 Avg. Training loss: 1.2056 0.0155 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 47400 Avg. Training loss: 1.2939 0.0161 sec/batch\n",
      "Epoch 3/50 Iteration: 47600 Avg. Training loss: 1.1162 0.0162 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 47800 Avg. Training loss: 1.2891 0.0162 sec/batch\n",
      "Epoch 3/50 Iteration: 48000 Avg. Training loss: 1.1931 0.0159 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 48200 Avg. Training loss: 1.2104 0.0152 sec/batch\n",
      "Epoch 3/50 Iteration: 48400 Avg. Training loss: 1.2240 0.0153 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 48600 Avg. Training loss: 1.3076 0.0159 sec/batch\n",
      "Epoch 3/50 Iteration: 48800 Avg. Training loss: 1.3842 0.0158 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 49000 Avg. Training loss: 1.3907 0.0157 sec/batch\n",
      "Epoch 3/50 Iteration: 49200 Avg. Training loss: 1.2266 0.0163 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 49400 Avg. Training loss: 1.3019 0.0160 sec/batch\n",
      "Epoch 3/50 Iteration: 49600 Avg. Training loss: 1.4232 0.0167 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 49800 Avg. Training loss: 1.2615 0.0162 sec/batch\n",
      "Epoch 3/50 Iteration: 50000 Avg. Training loss: 1.3180 0.0152 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 50200 Avg. Training loss: 1.3377 0.0146 sec/batch\n",
      "Epoch 3/50 Iteration: 50400 Avg. Training loss: 1.3074 0.0153 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 50600 Avg. Training loss: 1.2866 0.0149 sec/batch\n",
      "Epoch 3/50 Iteration: 50800 Avg. Training loss: 1.4807 0.0156 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 51000 Avg. Training loss: 1.2655 0.0156 sec/batch\n",
      "Epoch 3/50 Iteration: 51200 Avg. Training loss: 1.3799 0.0153 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 51400 Avg. Training loss: 1.4910 0.0157 sec/batch\n",
      "Epoch 3/50 Iteration: 51600 Avg. Training loss: 1.4947 0.0159 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 51800 Avg. Training loss: 1.3315 0.0158 sec/batch\n",
      "Epoch 3/50 Iteration: 52000 Avg. Training loss: 1.3670 0.0158 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 52200 Avg. Training loss: 1.3383 0.0161 sec/batch\n",
      "Epoch 3/50 Iteration: 52400 Avg. Training loss: 1.4444 0.0167 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 52600 Avg. Training loss: 1.3122 0.0155 sec/batch\n",
      "Epoch 3/50 Iteration: 52800 Avg. Training loss: 1.2142 0.0165 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 Iteration: 53000 Avg. Training loss: 1.4210 0.0160 sec/batch\n",
      "Epoch 3/50 Iteration: 53200 Avg. Training loss: 1.3002 0.0157 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 53400 Avg. Training loss: 1.3714 0.0163 sec/batch\n",
      "Epoch 3/50 Iteration: 53600 Avg. Training loss: 1.5221 0.0153 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 53800 Avg. Training loss: 1.2802 0.0156 sec/batch\n",
      "Epoch 3/50 Iteration: 54000 Avg. Training loss: 1.1581 0.0156 sec/batch\n",
      "error\n",
      "Epoch 3/50 Iteration: 54200 Avg. Training loss: 1.2335 0.0162 sec/batch\n",
      "Epoch 3/50 Iteration: 54400 Avg. Training loss: 1.1423 0.0160 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 54600 Avg. Training loss: 1.3138 0.0008 sec/batch\n",
      "Epoch 4/50 Iteration: 54800 Avg. Training loss: 1.2878 0.0162 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 55000 Avg. Training loss: 1.3301 0.0156 sec/batch\n",
      "Epoch 4/50 Iteration: 55200 Avg. Training loss: 1.0815 0.0159 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 55400 Avg. Training loss: 1.3724 0.0165 sec/batch\n",
      "Epoch 4/50 Iteration: 55600 Avg. Training loss: 1.3251 0.0160 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 55800 Avg. Training loss: 1.1459 0.0153 sec/batch\n",
      "Epoch 4/50 Iteration: 56000 Avg. Training loss: 1.2935 0.0157 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 56200 Avg. Training loss: 1.1123 0.0158 sec/batch\n",
      "Epoch 4/50 Iteration: 56400 Avg. Training loss: 1.2824 0.0151 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 56600 Avg. Training loss: 1.3863 0.0156 sec/batch\n",
      "Epoch 4/50 Iteration: 56800 Avg. Training loss: 1.4455 0.0152 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 57000 Avg. Training loss: 1.0473 0.0157 sec/batch\n",
      "Epoch 4/50 Iteration: 57200 Avg. Training loss: 1.3602 0.0160 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 57400 Avg. Training loss: 1.1708 0.0160 sec/batch\n",
      "Epoch 4/50 Iteration: 57600 Avg. Training loss: 1.2453 0.0157 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 57800 Avg. Training loss: 1.3872 0.0155 sec/batch\n",
      "Epoch 4/50 Iteration: 58000 Avg. Training loss: 1.2604 0.0158 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 58200 Avg. Training loss: 1.2879 0.0157 sec/batch\n",
      "Epoch 4/50 Iteration: 58400 Avg. Training loss: 1.2760 0.0152 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 58600 Avg. Training loss: 1.2432 0.0152 sec/batch\n",
      "Epoch 4/50 Iteration: 58800 Avg. Training loss: 1.2638 0.0146 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 59000 Avg. Training loss: 1.1262 0.0149 sec/batch\n",
      "Epoch 4/50 Iteration: 59200 Avg. Training loss: 1.2237 0.0149 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 59400 Avg. Training loss: 1.0759 0.0148 sec/batch\n",
      "Epoch 4/50 Iteration: 59600 Avg. Training loss: 1.2801 0.0154 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 59800 Avg. Training loss: 1.2534 0.0151 sec/batch\n",
      "Epoch 4/50 Iteration: 60000 Avg. Training loss: 1.2720 0.0157 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 60200 Avg. Training loss: 1.2743 0.0155 sec/batch\n",
      "Epoch 4/50 Iteration: 60400 Avg. Training loss: 1.1567 0.0159 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 60600 Avg. Training loss: 1.2071 0.0149 sec/batch\n",
      "Epoch 4/50 Iteration: 60800 Avg. Training loss: 1.2272 0.0150 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 61000 Avg. Training loss: 1.2117 0.0145 sec/batch\n",
      "Epoch 4/50 Iteration: 61200 Avg. Training loss: 1.2797 0.0150 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 61400 Avg. Training loss: 1.3275 0.0151 sec/batch\n",
      "Epoch 4/50 Iteration: 61600 Avg. Training loss: 1.2158 0.0151 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 61800 Avg. Training loss: 1.2888 0.0151 sec/batch\n",
      "Epoch 4/50 Iteration: 62000 Avg. Training loss: 1.1518 0.0162 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 62200 Avg. Training loss: 1.2371 0.0156 sec/batch\n",
      "Epoch 4/50 Iteration: 62400 Avg. Training loss: 1.2410 0.0153 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 62600 Avg. Training loss: 1.2269 0.0158 sec/batch\n",
      "Epoch 4/50 Iteration: 62800 Avg. Training loss: 1.2589 0.0159 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 63000 Avg. Training loss: 1.2984 0.0171 sec/batch\n",
      "Epoch 4/50 Iteration: 63200 Avg. Training loss: 1.3824 0.0157 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 63400 Avg. Training loss: 1.2044 0.0152 sec/batch\n",
      "Epoch 4/50 Iteration: 63600 Avg. Training loss: 1.2696 0.0157 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 63800 Avg. Training loss: 1.2355 0.0154 sec/batch\n",
      "Epoch 4/50 Iteration: 64000 Avg. Training loss: 1.3176 0.0170 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 64200 Avg. Training loss: 1.2851 0.0161 sec/batch\n",
      "Epoch 4/50 Iteration: 64400 Avg. Training loss: 1.0728 0.0156 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 64600 Avg. Training loss: 1.3178 0.0161 sec/batch\n",
      "Epoch 4/50 Iteration: 64800 Avg. Training loss: 1.2893 0.0161 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 65000 Avg. Training loss: 1.2678 0.0160 sec/batch\n",
      "Epoch 4/50 Iteration: 65200 Avg. Training loss: 1.3308 0.0156 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 65400 Avg. Training loss: 1.2048 0.0160 sec/batch\n",
      "Epoch 4/50 Iteration: 65600 Avg. Training loss: 1.2465 0.0157 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 65800 Avg. Training loss: 1.3227 0.0156 sec/batch\n",
      "Epoch 4/50 Iteration: 66000 Avg. Training loss: 1.2733 0.0157 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 66200 Avg. Training loss: 1.1642 0.0154 sec/batch\n",
      "Epoch 4/50 Iteration: 66400 Avg. Training loss: 1.1900 0.0157 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 66600 Avg. Training loss: 1.0725 0.0141 sec/batch\n",
      "Epoch 4/50 Iteration: 66800 Avg. Training loss: 0.9734 0.0142 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 67000 Avg. Training loss: 1.2276 0.0145 sec/batch\n",
      "Epoch 4/50 Iteration: 67200 Avg. Training loss: 1.3266 0.0144 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 67400 Avg. Training loss: 1.1710 0.0152 sec/batch\n",
      "Epoch 4/50 Iteration: 67600 Avg. Training loss: 1.2003 0.0141 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 67800 Avg. Training loss: 1.4369 0.0156 sec/batch\n",
      "Epoch 4/50 Iteration: 68000 Avg. Training loss: 1.1994 0.0144 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 68200 Avg. Training loss: 1.1954 0.0147 sec/batch\n",
      "Epoch 4/50 Iteration: 68400 Avg. Training loss: 1.3729 0.0142 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 68600 Avg. Training loss: 1.2643 0.0144 sec/batch\n",
      "Epoch 4/50 Iteration: 68800 Avg. Training loss: 1.1355 0.0142 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 69000 Avg. Training loss: 1.2211 0.0139 sec/batch\n",
      "Epoch 4/50 Iteration: 69200 Avg. Training loss: 1.0504 0.0145 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 69400 Avg. Training loss: 1.1466 0.0140 sec/batch\n",
      "Epoch 4/50 Iteration: 69600 Avg. Training loss: 1.4479 0.0147 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 69800 Avg. Training loss: 1.2872 0.0146 sec/batch\n",
      "Epoch 4/50 Iteration: 70000 Avg. Training loss: 1.3179 0.0145 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 70200 Avg. Training loss: 1.4228 0.0144 sec/batch\n",
      "Epoch 4/50 Iteration: 70400 Avg. Training loss: 1.3286 0.0144 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 70600 Avg. Training loss: 1.3442 0.0146 sec/batch\n",
      "Epoch 4/50 Iteration: 70800 Avg. Training loss: 1.1327 0.0139 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 71000 Avg. Training loss: 1.1310 0.0145 sec/batch\n",
      "Epoch 4/50 Iteration: 71200 Avg. Training loss: 1.3693 0.0133 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 71400 Avg. Training loss: 1.2881 0.0140 sec/batch\n",
      "Epoch 4/50 Iteration: 71600 Avg. Training loss: 1.3852 0.0146 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 71800 Avg. Training loss: 1.3912 0.0132 sec/batch\n",
      "Epoch 4/50 Iteration: 72000 Avg. Training loss: 1.2921 0.0138 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 72200 Avg. Training loss: 1.0272 0.0138 sec/batch\n",
      "Epoch 4/50 Iteration: 72400 Avg. Training loss: 1.1263 0.0143 sec/batch\n",
      "error\n",
      "Epoch 4/50 Iteration: 72600 Avg. Training loss: 1.1316 0.0144 sec/batch\n",
      "Epoch 5/50 Iteration: 72800 Avg. Training loss: 1.1846 0.0008 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 73000 Avg. Training loss: 1.4160 0.0145 sec/batch\n",
      "Epoch 5/50 Iteration: 73200 Avg. Training loss: 1.1854 0.0143 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 73400 Avg. Training loss: 0.9522 0.0137 sec/batch\n",
      "Epoch 5/50 Iteration: 73600 Avg. Training loss: 1.3337 0.0148 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 73800 Avg. Training loss: 1.1944 0.0144 sec/batch\n",
      "Epoch 5/50 Iteration: 74000 Avg. Training loss: 1.1131 0.0139 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 74200 Avg. Training loss: 1.2826 0.0144 sec/batch\n",
      "Epoch 5/50 Iteration: 74400 Avg. Training loss: 1.0165 0.0138 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 74600 Avg. Training loss: 1.1886 0.0141 sec/batch\n",
      "Epoch 5/50 Iteration: 74800 Avg. Training loss: 1.3751 0.0139 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 Iteration: 75000 Avg. Training loss: 1.4221 0.0140 sec/batch\n",
      "Epoch 5/50 Iteration: 75200 Avg. Training loss: 1.1196 0.0138 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 75400 Avg. Training loss: 1.1970 0.0142 sec/batch\n",
      "Epoch 5/50 Iteration: 75600 Avg. Training loss: 1.2030 0.0140 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 75800 Avg. Training loss: 1.1818 0.0135 sec/batch\n",
      "Epoch 5/50 Iteration: 76000 Avg. Training loss: 1.2760 0.0142 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 76200 Avg. Training loss: 1.2281 0.0142 sec/batch\n",
      "Epoch 5/50 Iteration: 76400 Avg. Training loss: 1.3907 0.0138 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 76600 Avg. Training loss: 1.3451 0.0138 sec/batch\n",
      "Epoch 5/50 Iteration: 76800 Avg. Training loss: 1.2398 0.0143 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 77000 Avg. Training loss: 1.3356 0.0135 sec/batch\n",
      "Epoch 5/50 Iteration: 77200 Avg. Training loss: 1.0784 0.0143 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 77400 Avg. Training loss: 1.0873 0.0138 sec/batch\n",
      "Epoch 5/50 Iteration: 77600 Avg. Training loss: 1.0136 0.0138 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 77800 Avg. Training loss: 1.2531 0.0136 sec/batch\n",
      "Epoch 5/50 Iteration: 78000 Avg. Training loss: 1.1666 0.0134 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 78200 Avg. Training loss: 1.3375 0.0139 sec/batch\n",
      "Epoch 5/50 Iteration: 78400 Avg. Training loss: 1.1654 0.0140 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 78600 Avg. Training loss: 1.1540 0.0142 sec/batch\n",
      "Epoch 5/50 Iteration: 78800 Avg. Training loss: 1.1991 0.0133 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 79000 Avg. Training loss: 1.1587 0.0138 sec/batch\n",
      "Epoch 5/50 Iteration: 79200 Avg. Training loss: 1.1915 0.0139 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 79400 Avg. Training loss: 1.2175 0.0143 sec/batch\n",
      "Epoch 5/50 Iteration: 79600 Avg. Training loss: 1.2489 0.0141 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 79800 Avg. Training loss: 1.1795 0.0174 sec/batch\n",
      "Epoch 5/50 Iteration: 80000 Avg. Training loss: 1.2148 0.0141 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 80200 Avg. Training loss: 1.0422 0.0138 sec/batch\n",
      "Epoch 5/50 Iteration: 80400 Avg. Training loss: 1.1075 0.0139 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 80600 Avg. Training loss: 1.0675 0.0134 sec/batch\n",
      "Epoch 5/50 Iteration: 80800 Avg. Training loss: 1.2283 0.0136 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 81000 Avg. Training loss: 1.2045 0.0136 sec/batch\n",
      "Epoch 5/50 Iteration: 81200 Avg. Training loss: 1.2090 0.0149 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 81400 Avg. Training loss: 1.1211 0.0136 sec/batch\n",
      "Epoch 5/50 Iteration: 81600 Avg. Training loss: 1.3789 0.0141 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 81800 Avg. Training loss: 1.1829 0.0137 sec/batch\n",
      "Epoch 5/50 Iteration: 82000 Avg. Training loss: 1.2448 0.0136 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 82200 Avg. Training loss: 1.3269 0.0148 sec/batch\n",
      "Epoch 5/50 Iteration: 82400 Avg. Training loss: 1.0593 0.0139 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 82600 Avg. Training loss: 0.9952 0.0138 sec/batch\n",
      "Epoch 5/50 Iteration: 82800 Avg. Training loss: 1.3174 0.0140 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 83000 Avg. Training loss: 1.1980 0.0142 sec/batch\n",
      "Epoch 5/50 Iteration: 83200 Avg. Training loss: 1.2480 0.0139 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 83400 Avg. Training loss: 1.2041 0.0138 sec/batch\n",
      "Epoch 5/50 Iteration: 83600 Avg. Training loss: 1.2473 0.0135 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 83800 Avg. Training loss: 1.2381 0.0137 sec/batch\n",
      "Epoch 5/50 Iteration: 84000 Avg. Training loss: 1.1430 0.0142 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 84200 Avg. Training loss: 1.1608 0.0138 sec/batch\n",
      "Epoch 5/50 Iteration: 84400 Avg. Training loss: 1.0081 0.0139 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 84600 Avg. Training loss: 1.2770 0.0136 sec/batch\n",
      "Epoch 5/50 Iteration: 84800 Avg. Training loss: 1.0150 0.0139 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 85000 Avg. Training loss: 1.1418 0.0140 sec/batch\n",
      "Epoch 5/50 Iteration: 85200 Avg. Training loss: 1.2949 0.0140 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 85400 Avg. Training loss: 1.1810 0.0142 sec/batch\n",
      "Epoch 5/50 Iteration: 85600 Avg. Training loss: 1.0799 0.0145 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 85800 Avg. Training loss: 1.1704 0.0140 sec/batch\n",
      "Epoch 5/50 Iteration: 86000 Avg. Training loss: 1.3032 0.0147 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 86200 Avg. Training loss: 1.1480 0.0141 sec/batch\n",
      "Epoch 5/50 Iteration: 86400 Avg. Training loss: 1.2300 0.0142 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 86600 Avg. Training loss: 1.3117 0.0139 sec/batch\n",
      "Epoch 5/50 Iteration: 86800 Avg. Training loss: 1.2492 0.0143 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 87000 Avg. Training loss: 1.3164 0.0140 sec/batch\n",
      "Epoch 5/50 Iteration: 87200 Avg. Training loss: 1.3779 0.0141 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 87400 Avg. Training loss: 1.2321 0.0138 sec/batch\n",
      "Epoch 5/50 Iteration: 87600 Avg. Training loss: 1.1490 0.0135 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 87800 Avg. Training loss: 1.3975 0.0139 sec/batch\n",
      "Epoch 5/50 Iteration: 88000 Avg. Training loss: 1.3103 0.0142 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 88200 Avg. Training loss: 1.2995 0.0140 sec/batch\n",
      "Epoch 5/50 Iteration: 88400 Avg. Training loss: 1.2404 0.0140 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 88600 Avg. Training loss: 1.2359 0.0136 sec/batch\n",
      "Epoch 5/50 Iteration: 88800 Avg. Training loss: 1.3110 0.0142 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 89000 Avg. Training loss: 0.9804 0.0138 sec/batch\n",
      "Epoch 5/50 Iteration: 89200 Avg. Training loss: 1.0798 0.0142 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 89400 Avg. Training loss: 1.2757 0.0129 sec/batch\n",
      "Epoch 5/50 Iteration: 89600 Avg. Training loss: 1.2762 0.0140 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 89800 Avg. Training loss: 1.3301 0.0150 sec/batch\n",
      "Epoch 5/50 Iteration: 90000 Avg. Training loss: 1.4097 0.0139 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 90200 Avg. Training loss: 1.1728 0.0156 sec/batch\n",
      "Epoch 5/50 Iteration: 90400 Avg. Training loss: 1.0039 0.0140 sec/batch\n",
      "error\n",
      "Epoch 5/50 Iteration: 90600 Avg. Training loss: 1.0081 0.0143 sec/batch\n",
      "Epoch 5/50 Iteration: 90800 Avg. Training loss: 1.3381 0.0139 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 91000 Avg. Training loss: 1.1759 0.0011 sec/batch\n",
      "Epoch 6/50 Iteration: 91200 Avg. Training loss: 1.3311 0.0140 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 91400 Avg. Training loss: 1.1413 0.0145 sec/batch\n",
      "Epoch 6/50 Iteration: 91600 Avg. Training loss: 0.9567 0.0141 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 91800 Avg. Training loss: 1.3926 0.0149 sec/batch\n",
      "Epoch 6/50 Iteration: 92000 Avg. Training loss: 1.2375 0.0144 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 92200 Avg. Training loss: 1.1856 0.0140 sec/batch\n",
      "Epoch 6/50 Iteration: 92400 Avg. Training loss: 1.2387 0.0148 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 92600 Avg. Training loss: 0.9188 0.0144 sec/batch\n",
      "Epoch 6/50 Iteration: 92800 Avg. Training loss: 1.1054 0.0144 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 93000 Avg. Training loss: 1.2357 0.0142 sec/batch\n",
      "Epoch 6/50 Iteration: 93200 Avg. Training loss: 1.4574 0.0141 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 93400 Avg. Training loss: 1.1104 0.0145 sec/batch\n",
      "Epoch 6/50 Iteration: 93600 Avg. Training loss: 1.2034 0.0140 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 93800 Avg. Training loss: 1.0763 0.0147 sec/batch\n",
      "Epoch 6/50 Iteration: 94000 Avg. Training loss: 1.2708 0.0142 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 94200 Avg. Training loss: 1.3152 0.0144 sec/batch\n",
      "Epoch 6/50 Iteration: 94400 Avg. Training loss: 1.1031 0.0147 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 94600 Avg. Training loss: 1.2431 0.0146 sec/batch\n",
      "Epoch 6/50 Iteration: 94800 Avg. Training loss: 1.3351 0.0145 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 95000 Avg. Training loss: 1.1572 0.0145 sec/batch\n",
      "Epoch 6/50 Iteration: 95200 Avg. Training loss: 1.2118 0.0138 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 95400 Avg. Training loss: 1.0528 0.0147 sec/batch\n",
      "Epoch 6/50 Iteration: 95600 Avg. Training loss: 1.0363 0.0145 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 95800 Avg. Training loss: 1.0506 0.0142 sec/batch\n",
      "Epoch 6/50 Iteration: 96000 Avg. Training loss: 1.2178 0.0149 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 96200 Avg. Training loss: 1.2532 0.0141 sec/batch\n",
      "Epoch 6/50 Iteration: 96400 Avg. Training loss: 1.2357 0.0148 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 96600 Avg. Training loss: 1.2551 0.0146 sec/batch\n",
      "Epoch 6/50 Iteration: 96800 Avg. Training loss: 1.1865 0.0140 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 Iteration: 97000 Avg. Training loss: 0.9551 0.0137 sec/batch\n",
      "Epoch 6/50 Iteration: 97200 Avg. Training loss: 1.1291 0.0142 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 97400 Avg. Training loss: 1.2229 0.0136 sec/batch\n",
      "Epoch 6/50 Iteration: 97600 Avg. Training loss: 1.2766 0.0140 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 97800 Avg. Training loss: 1.2259 0.0136 sec/batch\n",
      "Epoch 6/50 Iteration: 98000 Avg. Training loss: 1.1799 0.0139 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 98200 Avg. Training loss: 1.2915 0.0135 sec/batch\n",
      "Epoch 6/50 Iteration: 98400 Avg. Training loss: 1.1757 0.0142 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 98600 Avg. Training loss: 0.9519 0.0137 sec/batch\n",
      "Epoch 6/50 Iteration: 98800 Avg. Training loss: 1.0923 0.0140 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 99000 Avg. Training loss: 1.0826 0.0144 sec/batch\n",
      "Epoch 6/50 Iteration: 99200 Avg. Training loss: 1.3187 0.0145 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 99400 Avg. Training loss: 1.3081 0.0156 sec/batch\n",
      "Epoch 6/50 Iteration: 99600 Avg. Training loss: 1.2812 0.0143 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 99800 Avg. Training loss: 1.3729 0.0144 sec/batch\n",
      "Epoch 6/50 Iteration: 100000 Avg. Training loss: 1.1208 0.0145 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 100200 Avg. Training loss: 1.2758 0.0142 sec/batch\n",
      "Epoch 6/50 Iteration: 100400 Avg. Training loss: 1.3416 0.0153 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 100600 Avg. Training loss: 1.2012 0.0149 sec/batch\n",
      "Epoch 6/50 Iteration: 100800 Avg. Training loss: 0.9376 0.0142 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 101000 Avg. Training loss: 1.2732 0.0146 sec/batch\n",
      "Epoch 6/50 Iteration: 101200 Avg. Training loss: 1.0940 0.0147 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 101400 Avg. Training loss: 1.3128 0.0146 sec/batch\n",
      "Epoch 6/50 Iteration: 101600 Avg. Training loss: 1.1546 0.0141 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 101800 Avg. Training loss: 1.0997 0.0145 sec/batch\n",
      "Epoch 6/50 Iteration: 102000 Avg. Training loss: 1.0915 0.0144 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 102200 Avg. Training loss: 1.0635 0.0145 sec/batch\n",
      "Epoch 6/50 Iteration: 102400 Avg. Training loss: 1.1467 0.0140 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 102600 Avg. Training loss: 1.0427 0.0141 sec/batch\n",
      "Epoch 6/50 Iteration: 102800 Avg. Training loss: 1.1879 0.0143 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 103000 Avg. Training loss: 1.0576 0.0143 sec/batch\n",
      "Epoch 6/50 Iteration: 103200 Avg. Training loss: 1.1829 0.0143 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 103400 Avg. Training loss: 1.1786 0.0143 sec/batch\n",
      "Epoch 6/50 Iteration: 103600 Avg. Training loss: 1.0163 0.0141 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 103800 Avg. Training loss: 1.1257 0.0152 sec/batch\n",
      "Epoch 6/50 Iteration: 104000 Avg. Training loss: 1.0717 0.0143 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 104200 Avg. Training loss: 1.3442 0.0153 sec/batch\n",
      "Epoch 6/50 Iteration: 104400 Avg. Training loss: 1.0783 0.0144 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 104600 Avg. Training loss: 1.1793 0.0148 sec/batch\n",
      "Epoch 6/50 Iteration: 104800 Avg. Training loss: 1.2737 0.0145 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 105000 Avg. Training loss: 1.1638 0.0145 sec/batch\n",
      "Epoch 6/50 Iteration: 105200 Avg. Training loss: 1.1108 0.0143 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 105400 Avg. Training loss: 1.3432 0.0146 sec/batch\n",
      "Epoch 6/50 Iteration: 105600 Avg. Training loss: 0.9946 0.0139 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 105800 Avg. Training loss: 1.2967 0.0139 sec/batch\n",
      "Epoch 6/50 Iteration: 106000 Avg. Training loss: 1.2399 0.0139 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 106200 Avg. Training loss: 1.2794 0.0141 sec/batch\n",
      "Epoch 6/50 Iteration: 106400 Avg. Training loss: 1.2377 0.0146 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 106600 Avg. Training loss: 1.1746 0.0145 sec/batch\n",
      "Epoch 6/50 Iteration: 106800 Avg. Training loss: 1.1930 0.0145 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 107000 Avg. Training loss: 1.3765 0.0148 sec/batch\n",
      "Epoch 6/50 Iteration: 107200 Avg. Training loss: 1.1315 0.0145 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 107400 Avg. Training loss: 1.0467 0.0145 sec/batch\n",
      "Epoch 6/50 Iteration: 107600 Avg. Training loss: 1.2455 0.0143 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 107800 Avg. Training loss: 1.2167 0.0147 sec/batch\n",
      "Epoch 6/50 Iteration: 108000 Avg. Training loss: 1.4132 0.0152 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 108200 Avg. Training loss: 1.4114 0.0143 sec/batch\n",
      "Epoch 6/50 Iteration: 108400 Avg. Training loss: 1.2569 0.0142 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 108600 Avg. Training loss: 1.2097 0.0147 sec/batch\n",
      "Epoch 6/50 Iteration: 108800 Avg. Training loss: 0.9644 0.0149 sec/batch\n",
      "error\n",
      "Epoch 6/50 Iteration: 109000 Avg. Training loss: 1.1360 0.0144 sec/batch\n",
      "Epoch 7/50 Iteration: 109200 Avg. Training loss: 1.2706 0.0013 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 109400 Avg. Training loss: 1.4697 0.0147 sec/batch\n",
      "Epoch 7/50 Iteration: 109600 Avg. Training loss: 0.9804 0.0153 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 109800 Avg. Training loss: 0.8599 0.0148 sec/batch\n",
      "Epoch 7/50 Iteration: 110000 Avg. Training loss: 1.3599 0.0152 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 110200 Avg. Training loss: 1.2001 0.0152 sec/batch\n",
      "Epoch 7/50 Iteration: 110400 Avg. Training loss: 1.0696 0.0147 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 110600 Avg. Training loss: 1.2459 0.0148 sec/batch\n",
      "Epoch 7/50 Iteration: 110800 Avg. Training loss: 0.9745 0.0147 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 111000 Avg. Training loss: 1.1036 0.0139 sec/batch\n",
      "Epoch 7/50 Iteration: 111200 Avg. Training loss: 1.2540 0.0147 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 111400 Avg. Training loss: 1.2838 0.0143 sec/batch\n",
      "Epoch 7/50 Iteration: 111600 Avg. Training loss: 1.1046 0.0140 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 111800 Avg. Training loss: 1.1395 0.0141 sec/batch\n",
      "Epoch 7/50 Iteration: 112000 Avg. Training loss: 1.1371 0.0144 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 112200 Avg. Training loss: 1.1545 0.0141 sec/batch\n",
      "Epoch 7/50 Iteration: 112400 Avg. Training loss: 1.2842 0.0140 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 112600 Avg. Training loss: 1.0877 0.0146 sec/batch\n",
      "Epoch 7/50 Iteration: 112800 Avg. Training loss: 1.2031 0.0141 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 113000 Avg. Training loss: 1.1867 0.0142 sec/batch\n",
      "Epoch 7/50 Iteration: 113200 Avg. Training loss: 1.1402 0.0141 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 113400 Avg. Training loss: 1.0416 0.0141 sec/batch\n",
      "Epoch 7/50 Iteration: 113600 Avg. Training loss: 1.1136 0.0145 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 113800 Avg. Training loss: 0.9932 0.0142 sec/batch\n",
      "Epoch 7/50 Iteration: 114000 Avg. Training loss: 1.1218 0.0136 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 114200 Avg. Training loss: 1.1152 0.0146 sec/batch\n",
      "Epoch 7/50 Iteration: 114400 Avg. Training loss: 1.1036 0.0140 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 114600 Avg. Training loss: 1.1399 0.0144 sec/batch\n",
      "Epoch 7/50 Iteration: 114800 Avg. Training loss: 1.1679 0.0143 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 115000 Avg. Training loss: 1.1000 0.0148 sec/batch\n",
      "Epoch 7/50 Iteration: 115200 Avg. Training loss: 0.9049 0.0136 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 115400 Avg. Training loss: 1.1453 0.0143 sec/batch\n",
      "Epoch 7/50 Iteration: 115600 Avg. Training loss: 1.0041 0.0141 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 115800 Avg. Training loss: 1.3451 0.0136 sec/batch\n",
      "Epoch 7/50 Iteration: 116000 Avg. Training loss: 1.2387 0.0137 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 116200 Avg. Training loss: 1.2064 0.0142 sec/batch\n",
      "Epoch 7/50 Iteration: 116400 Avg. Training loss: 1.1602 0.0148 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 116600 Avg. Training loss: 1.0684 0.0147 sec/batch\n",
      "Epoch 7/50 Iteration: 116800 Avg. Training loss: 1.1122 0.0177 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 117000 Avg. Training loss: 1.0115 0.0148 sec/batch\n",
      "Epoch 7/50 Iteration: 117200 Avg. Training loss: 1.1505 0.0147 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 117400 Avg. Training loss: 1.2764 0.0146 sec/batch\n",
      "Epoch 7/50 Iteration: 117600 Avg. Training loss: 1.2854 0.0158 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 117800 Avg. Training loss: 1.1508 0.0142 sec/batch\n",
      "Epoch 7/50 Iteration: 118000 Avg. Training loss: 1.1018 0.0145 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 118200 Avg. Training loss: 1.1351 0.0148 sec/batch\n",
      "Epoch 7/50 Iteration: 118400 Avg. Training loss: 1.1085 0.0147 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 Iteration: 118600 Avg. Training loss: 1.2510 0.0158 sec/batch\n",
      "Epoch 7/50 Iteration: 118800 Avg. Training loss: 1.0172 0.0147 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 119000 Avg. Training loss: 1.0085 0.0146 sec/batch\n",
      "Epoch 7/50 Iteration: 119200 Avg. Training loss: 1.3501 0.0150 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 119400 Avg. Training loss: 1.1430 0.0152 sec/batch\n",
      "Epoch 7/50 Iteration: 119600 Avg. Training loss: 1.1895 0.0146 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 119800 Avg. Training loss: 1.1986 0.0146 sec/batch\n",
      "Epoch 7/50 Iteration: 120000 Avg. Training loss: 0.9853 0.0146 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 120200 Avg. Training loss: 1.1092 0.0152 sec/batch\n",
      "Epoch 7/50 Iteration: 120400 Avg. Training loss: 1.0716 0.0148 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 120600 Avg. Training loss: 1.3141 0.0148 sec/batch\n",
      "Epoch 7/50 Iteration: 120800 Avg. Training loss: 0.9827 0.0150 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 121000 Avg. Training loss: 1.0530 0.0151 sec/batch\n",
      "Epoch 7/50 Iteration: 121200 Avg. Training loss: 1.0404 0.0148 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 121400 Avg. Training loss: 1.0767 0.0152 sec/batch\n",
      "Epoch 7/50 Iteration: 121600 Avg. Training loss: 1.1203 0.0148 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 121800 Avg. Training loss: 1.2216 0.0148 sec/batch\n",
      "Epoch 7/50 Iteration: 122000 Avg. Training loss: 1.2064 0.0151 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 122200 Avg. Training loss: 1.1798 0.0163 sec/batch\n",
      "Epoch 7/50 Iteration: 122400 Avg. Training loss: 1.1957 0.0160 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 122600 Avg. Training loss: 0.9585 0.0150 sec/batch\n",
      "Epoch 7/50 Iteration: 122800 Avg. Training loss: 1.2154 0.0146 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 123000 Avg. Training loss: 1.2523 0.0151 sec/batch\n",
      "Epoch 7/50 Iteration: 123200 Avg. Training loss: 1.2565 0.0151 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 123400 Avg. Training loss: 1.3322 0.0151 sec/batch\n",
      "Epoch 7/50 Iteration: 123600 Avg. Training loss: 1.1149 0.0149 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 123800 Avg. Training loss: 1.0686 0.0147 sec/batch\n",
      "Epoch 7/50 Iteration: 124000 Avg. Training loss: 1.0861 0.0148 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 124200 Avg. Training loss: 1.3713 0.0146 sec/batch\n",
      "Epoch 7/50 Iteration: 124400 Avg. Training loss: 1.3375 0.0150 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 124600 Avg. Training loss: 1.2857 0.0149 sec/batch\n",
      "Epoch 7/50 Iteration: 124800 Avg. Training loss: 1.1106 0.0149 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 125000 Avg. Training loss: 1.1831 0.0149 sec/batch\n",
      "Epoch 7/50 Iteration: 125200 Avg. Training loss: 1.1902 0.0149 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 125400 Avg. Training loss: 0.7378 0.0145 sec/batch\n",
      "Epoch 7/50 Iteration: 125600 Avg. Training loss: 1.2241 0.0150 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 125800 Avg. Training loss: 1.1560 0.0146 sec/batch\n",
      "Epoch 7/50 Iteration: 126000 Avg. Training loss: 1.0685 0.0145 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 126200 Avg. Training loss: 1.4371 0.0150 sec/batch\n",
      "Epoch 7/50 Iteration: 126400 Avg. Training loss: 1.3557 0.0143 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 126600 Avg. Training loss: 1.1716 0.0142 sec/batch\n",
      "Epoch 7/50 Iteration: 126800 Avg. Training loss: 1.0199 0.0146 sec/batch\n",
      "error\n",
      "Epoch 7/50 Iteration: 127000 Avg. Training loss: 1.1031 0.0152 sec/batch\n",
      "Epoch 7/50 Iteration: 127200 Avg. Training loss: 1.1879 0.0147 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 127400 Avg. Training loss: 1.0650 0.0016 sec/batch\n",
      "Epoch 8/50 Iteration: 127600 Avg. Training loss: 1.2793 0.0149 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 127800 Avg. Training loss: 1.1549 0.0149 sec/batch\n",
      "Epoch 8/50 Iteration: 128000 Avg. Training loss: 0.9381 0.0144 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 128200 Avg. Training loss: 1.4621 0.0155 sec/batch\n",
      "Epoch 8/50 Iteration: 128400 Avg. Training loss: 1.1840 0.0149 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 128600 Avg. Training loss: 0.9580 0.0145 sec/batch\n",
      "Epoch 8/50 Iteration: 128800 Avg. Training loss: 1.2534 0.0145 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 129000 Avg. Training loss: 1.0519 0.0145 sec/batch\n",
      "Epoch 8/50 Iteration: 129200 Avg. Training loss: 1.1529 0.0148 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 129400 Avg. Training loss: 1.2956 0.0145 sec/batch\n",
      "Epoch 8/50 Iteration: 129600 Avg. Training loss: 1.3726 0.0143 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 129800 Avg. Training loss: 0.9868 0.0158 sec/batch\n",
      "Epoch 8/50 Iteration: 130000 Avg. Training loss: 0.9300 0.0146 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 130200 Avg. Training loss: 1.0866 0.0146 sec/batch\n",
      "Epoch 8/50 Iteration: 130400 Avg. Training loss: 1.1985 0.0144 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 130600 Avg. Training loss: 1.1443 0.0149 sec/batch\n",
      "Epoch 8/50 Iteration: 130800 Avg. Training loss: 1.3125 0.0153 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 131000 Avg. Training loss: 1.1375 0.0146 sec/batch\n",
      "Epoch 8/50 Iteration: 131200 Avg. Training loss: 1.2087 0.0143 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 131400 Avg. Training loss: 1.0558 0.0149 sec/batch\n",
      "Epoch 8/50 Iteration: 131600 Avg. Training loss: 0.9625 0.0141 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 131800 Avg. Training loss: 1.0507 0.0146 sec/batch\n",
      "Epoch 8/50 Iteration: 132000 Avg. Training loss: 0.9433 0.0145 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 132200 Avg. Training loss: 1.0173 0.0149 sec/batch\n",
      "Epoch 8/50 Iteration: 132400 Avg. Training loss: 1.2282 0.0152 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 132600 Avg. Training loss: 1.1201 0.0148 sec/batch\n",
      "Epoch 8/50 Iteration: 132800 Avg. Training loss: 1.2193 0.0152 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 133000 Avg. Training loss: 1.1537 0.0156 sec/batch\n",
      "Epoch 8/50 Iteration: 133200 Avg. Training loss: 1.2356 0.0154 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 133400 Avg. Training loss: 1.0141 0.0145 sec/batch\n",
      "Epoch 8/50 Iteration: 133600 Avg. Training loss: 1.0359 0.0148 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 133800 Avg. Training loss: 1.0414 0.0149 sec/batch\n",
      "Epoch 8/50 Iteration: 134000 Avg. Training loss: 1.3943 0.0153 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 134200 Avg. Training loss: 1.1683 0.0153 sec/batch\n",
      "Epoch 8/50 Iteration: 134400 Avg. Training loss: 1.1538 0.0151 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 134600 Avg. Training loss: 1.1972 0.0151 sec/batch\n",
      "Epoch 8/50 Iteration: 134800 Avg. Training loss: 1.0953 0.0151 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 135000 Avg. Training loss: 1.0557 0.0142 sec/batch\n",
      "Epoch 8/50 Iteration: 135200 Avg. Training loss: 0.9111 0.0140 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 135400 Avg. Training loss: 1.2143 0.0142 sec/batch\n",
      "Epoch 8/50 Iteration: 135600 Avg. Training loss: 1.1540 0.0144 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 135800 Avg. Training loss: 1.0971 0.0157 sec/batch\n",
      "Epoch 8/50 Iteration: 136000 Avg. Training loss: 1.2311 0.0140 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 136200 Avg. Training loss: 1.2772 0.0144 sec/batch\n",
      "Epoch 8/50 Iteration: 136400 Avg. Training loss: 1.2197 0.0143 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 136600 Avg. Training loss: 1.1597 0.0142 sec/batch\n",
      "Epoch 8/50 Iteration: 136800 Avg. Training loss: 1.2226 0.0150 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 137000 Avg. Training loss: 1.0271 0.0141 sec/batch\n",
      "Epoch 8/50 Iteration: 137200 Avg. Training loss: 1.0096 0.0140 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 137400 Avg. Training loss: 1.2796 0.0148 sec/batch\n",
      "Epoch 8/50 Iteration: 137600 Avg. Training loss: 1.2715 0.0149 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 137800 Avg. Training loss: 1.1289 0.0142 sec/batch\n",
      "Epoch 8/50 Iteration: 138000 Avg. Training loss: 1.1409 0.0143 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 138200 Avg. Training loss: 1.2602 0.0139 sec/batch\n",
      "Epoch 8/50 Iteration: 138400 Avg. Training loss: 1.1309 0.0143 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 138600 Avg. Training loss: 1.0096 0.0148 sec/batch\n",
      "Epoch 8/50 Iteration: 138800 Avg. Training loss: 1.0649 0.0141 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 139000 Avg. Training loss: 1.0371 0.0143 sec/batch\n",
      "Epoch 8/50 Iteration: 139200 Avg. Training loss: 1.2392 0.0142 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 139400 Avg. Training loss: 0.9361 0.0140 sec/batch\n",
      "Epoch 8/50 Iteration: 139600 Avg. Training loss: 1.1546 0.0142 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 139800 Avg. Training loss: 1.0714 0.0144 sec/batch\n",
      "Epoch 8/50 Iteration: 140000 Avg. Training loss: 1.1759 0.0144 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 Iteration: 140200 Avg. Training loss: 0.9569 0.0151 sec/batch\n",
      "Epoch 8/50 Iteration: 140400 Avg. Training loss: 1.1332 0.0142 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 140600 Avg. Training loss: 1.0070 0.0154 sec/batch\n",
      "Epoch 8/50 Iteration: 140800 Avg. Training loss: 1.1010 0.0144 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 141000 Avg. Training loss: 1.2361 0.0144 sec/batch\n",
      "Epoch 8/50 Iteration: 141200 Avg. Training loss: 1.3178 0.0141 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 141400 Avg. Training loss: 1.2314 0.0146 sec/batch\n",
      "Epoch 8/50 Iteration: 141600 Avg. Training loss: 1.1684 0.0143 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 141800 Avg. Training loss: 1.4342 0.0141 sec/batch\n",
      "Epoch 8/50 Iteration: 142000 Avg. Training loss: 1.0046 0.0144 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 142200 Avg. Training loss: 1.0912 0.0147 sec/batch\n",
      "Epoch 8/50 Iteration: 142400 Avg. Training loss: 1.2642 0.0146 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 142600 Avg. Training loss: 1.3054 0.0144 sec/batch\n",
      "Epoch 8/50 Iteration: 142800 Avg. Training loss: 1.1163 0.0144 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 143000 Avg. Training loss: 1.2689 0.0145 sec/batch\n",
      "Epoch 8/50 Iteration: 143200 Avg. Training loss: 1.0837 0.0144 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 143400 Avg. Training loss: 1.2747 0.0146 sec/batch\n",
      "Epoch 8/50 Iteration: 143600 Avg. Training loss: 0.9854 0.0143 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 143800 Avg. Training loss: 1.1620 0.0144 sec/batch\n",
      "Epoch 8/50 Iteration: 144000 Avg. Training loss: 1.2667 0.0140 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 144200 Avg. Training loss: 1.2243 0.0145 sec/batch\n",
      "Epoch 8/50 Iteration: 144400 Avg. Training loss: 1.3590 0.0148 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 144600 Avg. Training loss: 1.3895 0.0142 sec/batch\n",
      "Epoch 8/50 Iteration: 144800 Avg. Training loss: 1.0253 0.0146 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 145000 Avg. Training loss: 1.0541 0.0147 sec/batch\n",
      "Epoch 8/50 Iteration: 145200 Avg. Training loss: 1.0086 0.0149 sec/batch\n",
      "error\n",
      "Epoch 8/50 Iteration: 145400 Avg. Training loss: 1.0950 0.0147 sec/batch\n",
      "Epoch 9/50 Iteration: 145600 Avg. Training loss: 1.1831 0.0018 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 145800 Avg. Training loss: 1.2320 0.0150 sec/batch\n",
      "Epoch 9/50 Iteration: 146000 Avg. Training loss: 1.0787 0.0147 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 146200 Avg. Training loss: 0.9579 0.0146 sec/batch\n",
      "Epoch 9/50 Iteration: 146400 Avg. Training loss: 1.3286 0.0149 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 146600 Avg. Training loss: 1.1094 0.0147 sec/batch\n",
      "Epoch 9/50 Iteration: 146800 Avg. Training loss: 1.0971 0.0142 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 147000 Avg. Training loss: 1.2803 0.0150 sec/batch\n",
      "Epoch 9/50 Iteration: 147200 Avg. Training loss: 0.8799 0.0146 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 147400 Avg. Training loss: 1.1743 0.0146 sec/batch\n",
      "Epoch 9/50 Iteration: 147600 Avg. Training loss: 1.2427 0.0146 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 147800 Avg. Training loss: 1.3719 0.0144 sec/batch\n",
      "Epoch 9/50 Iteration: 148000 Avg. Training loss: 0.9527 0.0143 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 148200 Avg. Training loss: 1.1332 0.0147 sec/batch\n",
      "Epoch 9/50 Iteration: 148400 Avg. Training loss: 1.0806 0.0147 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 148600 Avg. Training loss: 1.1800 0.0145 sec/batch\n",
      "Epoch 9/50 Iteration: 148800 Avg. Training loss: 1.1439 0.0143 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 149000 Avg. Training loss: 1.0929 0.0147 sec/batch\n",
      "Epoch 9/50 Iteration: 149200 Avg. Training loss: 1.1814 0.0149 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 149400 Avg. Training loss: 1.3750 0.0142 sec/batch\n",
      "Epoch 9/50 Iteration: 149600 Avg. Training loss: 1.1975 0.0145 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 149800 Avg. Training loss: 0.9822 0.0143 sec/batch\n",
      "Epoch 9/50 Iteration: 150000 Avg. Training loss: 1.0317 0.0145 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 150200 Avg. Training loss: 0.8595 0.0137 sec/batch\n",
      "Epoch 9/50 Iteration: 150400 Avg. Training loss: 0.9325 0.0141 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 150600 Avg. Training loss: 1.0902 0.0142 sec/batch\n",
      "Epoch 9/50 Iteration: 150800 Avg. Training loss: 0.9928 0.0140 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 151000 Avg. Training loss: 1.0955 0.0150 sec/batch\n",
      "Epoch 9/50 Iteration: 151200 Avg. Training loss: 1.2584 0.0143 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 151400 Avg. Training loss: 1.2794 0.0148 sec/batch\n",
      "Epoch 9/50 Iteration: 151600 Avg. Training loss: 0.9803 0.0144 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 151800 Avg. Training loss: 1.0418 0.0143 sec/batch\n",
      "Epoch 9/50 Iteration: 152000 Avg. Training loss: 1.0571 0.0146 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 152200 Avg. Training loss: 1.2266 0.0144 sec/batch\n",
      "Epoch 9/50 Iteration: 152400 Avg. Training loss: 1.1613 0.0141 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 152600 Avg. Training loss: 1.2355 0.0146 sec/batch\n",
      "Epoch 9/50 Iteration: 152800 Avg. Training loss: 1.1360 0.0143 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 153000 Avg. Training loss: 0.9408 0.0151 sec/batch\n",
      "Epoch 9/50 Iteration: 153200 Avg. Training loss: 0.9221 0.0142 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 153400 Avg. Training loss: 0.8739 0.0138 sec/batch\n",
      "Epoch 9/50 Iteration: 153600 Avg. Training loss: 1.0620 0.0144 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 153800 Avg. Training loss: 1.1813 0.0143 sec/batch\n",
      "Epoch 9/50 Iteration: 154000 Avg. Training loss: 1.2976 0.0158 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 154200 Avg. Training loss: 1.0865 0.0146 sec/batch\n",
      "Epoch 9/50 Iteration: 154400 Avg. Training loss: 1.1768 0.0140 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 154600 Avg. Training loss: 1.0622 0.0147 sec/batch\n",
      "Epoch 9/50 Iteration: 154800 Avg. Training loss: 1.2221 0.0144 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 155000 Avg. Training loss: 1.3848 0.0150 sec/batch\n",
      "Epoch 9/50 Iteration: 155200 Avg. Training loss: 1.0479 0.0139 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 155400 Avg. Training loss: 0.8881 0.0137 sec/batch\n",
      "Epoch 9/50 Iteration: 155600 Avg. Training loss: 1.3911 0.0144 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 155800 Avg. Training loss: 1.1839 0.0154 sec/batch\n",
      "Epoch 9/50 Iteration: 156000 Avg. Training loss: 1.0823 0.0146 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 156200 Avg. Training loss: 1.2081 0.0147 sec/batch\n",
      "Epoch 9/50 Iteration: 156400 Avg. Training loss: 1.0356 0.0140 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 156600 Avg. Training loss: 1.0916 0.0142 sec/batch\n",
      "Epoch 9/50 Iteration: 156800 Avg. Training loss: 1.2020 0.0145 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 157000 Avg. Training loss: 1.1856 0.0138 sec/batch\n",
      "Epoch 9/50 Iteration: 157200 Avg. Training loss: 0.9486 0.0145 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 157400 Avg. Training loss: 1.1536 0.0182 sec/batch\n",
      "Epoch 9/50 Iteration: 157600 Avg. Training loss: 1.0066 0.0147 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 157800 Avg. Training loss: 1.0330 0.0142 sec/batch\n",
      "Epoch 9/50 Iteration: 158000 Avg. Training loss: 1.1711 0.0140 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 158200 Avg. Training loss: 1.1693 0.0143 sec/batch\n",
      "Epoch 9/50 Iteration: 158400 Avg. Training loss: 1.1711 0.0148 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 158600 Avg. Training loss: 1.1782 0.0146 sec/batch\n",
      "Epoch 9/50 Iteration: 158800 Avg. Training loss: 1.1043 0.0159 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 159000 Avg. Training loss: 0.9087 0.0145 sec/batch\n",
      "Epoch 9/50 Iteration: 159200 Avg. Training loss: 1.2524 0.0143 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 159400 Avg. Training loss: 1.3105 0.0143 sec/batch\n",
      "Epoch 9/50 Iteration: 159600 Avg. Training loss: 1.3265 0.0144 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 159800 Avg. Training loss: 1.2234 0.0141 sec/batch\n",
      "Epoch 9/50 Iteration: 160000 Avg. Training loss: 1.4340 0.0143 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 160200 Avg. Training loss: 1.1717 0.0145 sec/batch\n",
      "Epoch 9/50 Iteration: 160400 Avg. Training loss: 0.9335 0.0142 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 160600 Avg. Training loss: 1.2477 0.0142 sec/batch\n",
      "Epoch 9/50 Iteration: 160800 Avg. Training loss: 1.2529 0.0145 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 161000 Avg. Training loss: 1.2441 0.0142 sec/batch\n",
      "Epoch 9/50 Iteration: 161200 Avg. Training loss: 1.2113 0.0143 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 161400 Avg. Training loss: 1.2075 0.0143 sec/batch\n",
      "Epoch 9/50 Iteration: 161600 Avg. Training loss: 1.3989 0.0104 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 Iteration: 161800 Avg. Training loss: 0.8232 0.0079 sec/batch\n",
      "Epoch 9/50 Iteration: 162000 Avg. Training loss: 1.0698 0.0079 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 162200 Avg. Training loss: 1.1672 0.0077 sec/batch\n",
      "Epoch 9/50 Iteration: 162400 Avg. Training loss: 1.1533 0.0079 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 162600 Avg. Training loss: 1.4775 0.0089 sec/batch\n",
      "Epoch 9/50 Iteration: 162800 Avg. Training loss: 1.3166 0.0081 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 163000 Avg. Training loss: 1.0095 0.0083 sec/batch\n",
      "Epoch 9/50 Iteration: 163200 Avg. Training loss: 1.1767 0.0082 sec/batch\n",
      "error\n",
      "Epoch 9/50 Iteration: 163400 Avg. Training loss: 0.9545 0.0087 sec/batch\n",
      "Epoch 9/50 Iteration: 163600 Avg. Training loss: 1.2616 0.0083 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 163800 Avg. Training loss: 1.1353 0.0012 sec/batch\n",
      "Epoch 10/50 Iteration: 164000 Avg. Training loss: 1.4417 0.0084 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 164200 Avg. Training loss: 1.1602 0.0086 sec/batch\n",
      "Epoch 10/50 Iteration: 164400 Avg. Training loss: 0.9774 0.0082 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 164600 Avg. Training loss: 1.2686 0.0089 sec/batch\n",
      "Epoch 10/50 Iteration: 164800 Avg. Training loss: 1.1535 0.0084 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 165000 Avg. Training loss: 1.0777 0.0080 sec/batch\n",
      "Epoch 10/50 Iteration: 165200 Avg. Training loss: 1.3019 0.0086 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 165400 Avg. Training loss: 0.8187 0.0083 sec/batch\n",
      "Epoch 10/50 Iteration: 165600 Avg. Training loss: 1.2296 0.0079 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 165800 Avg. Training loss: 1.2560 0.0079 sec/batch\n",
      "Epoch 10/50 Iteration: 166000 Avg. Training loss: 1.3624 0.0080 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 166200 Avg. Training loss: 1.0196 0.0084 sec/batch\n",
      "Epoch 10/50 Iteration: 166400 Avg. Training loss: 1.0946 0.0080 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 166600 Avg. Training loss: 1.1733 0.0081 sec/batch\n",
      "Epoch 10/50 Iteration: 166800 Avg. Training loss: 1.1561 0.0081 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 167000 Avg. Training loss: 1.0492 0.0082 sec/batch\n",
      "Epoch 10/50 Iteration: 167200 Avg. Training loss: 1.0590 0.0087 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 167400 Avg. Training loss: 1.2089 0.0081 sec/batch\n",
      "Epoch 10/50 Iteration: 167600 Avg. Training loss: 1.4186 0.0079 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 167800 Avg. Training loss: 1.1374 0.0083 sec/batch\n",
      "Epoch 10/50 Iteration: 168000 Avg. Training loss: 1.0905 0.0078 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 168200 Avg. Training loss: 1.0109 0.0083 sec/batch\n",
      "Epoch 10/50 Iteration: 168400 Avg. Training loss: 1.0873 0.0078 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 168600 Avg. Training loss: 1.1125 0.0080 sec/batch\n",
      "Epoch 10/50 Iteration: 168800 Avg. Training loss: 1.0988 0.0084 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 169000 Avg. Training loss: 1.1163 0.0078 sec/batch\n",
      "Epoch 10/50 Iteration: 169200 Avg. Training loss: 1.2314 0.0083 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 169400 Avg. Training loss: 1.3009 0.0081 sec/batch\n",
      "Epoch 10/50 Iteration: 169600 Avg. Training loss: 1.1266 0.0083 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 169800 Avg. Training loss: 0.9751 0.0079 sec/batch\n",
      "Epoch 10/50 Iteration: 170000 Avg. Training loss: 0.9826 0.0080 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 170200 Avg. Training loss: 1.0134 0.0079 sec/batch\n",
      "Epoch 10/50 Iteration: 170400 Avg. Training loss: 1.2166 0.0079 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 170600 Avg. Training loss: 1.1144 0.0079 sec/batch\n",
      "Epoch 10/50 Iteration: 170800 Avg. Training loss: 1.2740 0.0075 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 171000 Avg. Training loss: 1.3216 0.0073 sec/batch\n",
      "Epoch 10/50 Iteration: 171200 Avg. Training loss: 1.1697 0.0078 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 171400 Avg. Training loss: 0.9700 0.0072 sec/batch\n",
      "Epoch 10/50 Iteration: 171600 Avg. Training loss: 0.8878 0.0071 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 171800 Avg. Training loss: 1.1059 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 172000 Avg. Training loss: 1.2382 0.0076 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 172200 Avg. Training loss: 1.2379 0.0088 sec/batch\n",
      "Epoch 10/50 Iteration: 172400 Avg. Training loss: 1.0901 0.0070 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 172600 Avg. Training loss: 1.2945 0.0072 sec/batch\n",
      "Epoch 10/50 Iteration: 172800 Avg. Training loss: 1.2057 0.0073 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 173000 Avg. Training loss: 1.1813 0.0072 sec/batch\n",
      "Epoch 10/50 Iteration: 173200 Avg. Training loss: 1.1592 0.0086 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 173400 Avg. Training loss: 0.9507 0.0072 sec/batch\n",
      "Epoch 10/50 Iteration: 173600 Avg. Training loss: 0.7618 0.0071 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 173800 Avg. Training loss: 1.3436 0.0072 sec/batch\n",
      "Epoch 10/50 Iteration: 174000 Avg. Training loss: 1.2667 0.0076 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 174200 Avg. Training loss: 1.1388 0.0074 sec/batch\n",
      "Epoch 10/50 Iteration: 174400 Avg. Training loss: 1.4034 0.0073 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 174600 Avg. Training loss: 1.2425 0.0070 sec/batch\n",
      "Epoch 10/50 Iteration: 174800 Avg. Training loss: 1.0328 0.0075 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 175000 Avg. Training loss: 1.0278 0.0075 sec/batch\n",
      "Epoch 10/50 Iteration: 175200 Avg. Training loss: 1.0800 0.0071 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 175400 Avg. Training loss: 1.0362 0.0071 sec/batch\n",
      "Epoch 10/50 Iteration: 175600 Avg. Training loss: 1.1772 0.0072 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 175800 Avg. Training loss: 1.0696 0.0073 sec/batch\n",
      "Epoch 10/50 Iteration: 176000 Avg. Training loss: 1.1324 0.0073 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 176200 Avg. Training loss: 1.2050 0.0074 sec/batch\n",
      "Epoch 10/50 Iteration: 176400 Avg. Training loss: 1.0109 0.0074 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 176600 Avg. Training loss: 1.2259 0.0084 sec/batch\n",
      "Epoch 10/50 Iteration: 176800 Avg. Training loss: 1.1405 0.0073 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 177000 Avg. Training loss: 1.3248 0.0088 sec/batch\n",
      "Epoch 10/50 Iteration: 177200 Avg. Training loss: 1.0277 0.0073 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 177400 Avg. Training loss: 1.2452 0.0074 sec/batch\n",
      "Epoch 10/50 Iteration: 177600 Avg. Training loss: 1.4838 0.0075 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 177800 Avg. Training loss: 1.2083 0.0081 sec/batch\n",
      "Epoch 10/50 Iteration: 178000 Avg. Training loss: 1.2166 0.0086 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 178200 Avg. Training loss: 1.2512 0.0081 sec/batch\n",
      "Epoch 10/50 Iteration: 178400 Avg. Training loss: 1.0516 0.0080 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 178600 Avg. Training loss: 1.0166 0.0077 sec/batch\n",
      "Epoch 10/50 Iteration: 178800 Avg. Training loss: 1.1515 0.0079 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 179000 Avg. Training loss: 1.3031 0.0079 sec/batch\n",
      "Epoch 10/50 Iteration: 179200 Avg. Training loss: 1.1213 0.0079 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 179400 Avg. Training loss: 1.1801 0.0078 sec/batch\n",
      "Epoch 10/50 Iteration: 179600 Avg. Training loss: 1.1375 0.0077 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 179800 Avg. Training loss: 1.1973 0.0082 sec/batch\n",
      "Epoch 10/50 Iteration: 180000 Avg. Training loss: 0.7821 0.0076 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 180200 Avg. Training loss: 1.0968 0.0079 sec/batch\n",
      "Epoch 10/50 Iteration: 180400 Avg. Training loss: 1.1288 0.0075 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 180600 Avg. Training loss: 1.1748 0.0078 sec/batch\n",
      "Epoch 10/50 Iteration: 180800 Avg. Training loss: 1.4330 0.0086 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 181000 Avg. Training loss: 1.1617 0.0077 sec/batch\n",
      "Epoch 10/50 Iteration: 181200 Avg. Training loss: 0.9876 0.0077 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 181400 Avg. Training loss: 1.0903 0.0078 sec/batch\n",
      "Epoch 10/50 Iteration: 181600 Avg. Training loss: 0.9051 0.0086 sec/batch\n",
      "error\n",
      "Epoch 10/50 Iteration: 181800 Avg. Training loss: 0.9991 0.0080 sec/batch\n",
      "Epoch 11/50 Iteration: 182000 Avg. Training loss: 1.0158 0.0012 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 182200 Avg. Training loss: 1.3943 0.0082 sec/batch\n",
      "Epoch 11/50 Iteration: 182400 Avg. Training loss: 1.1859 0.0082 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 182600 Avg. Training loss: 0.8858 0.0080 sec/batch\n",
      "Epoch 11/50 Iteration: 182800 Avg. Training loss: 1.3080 0.0086 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 183000 Avg. Training loss: 1.3629 0.0081 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 Iteration: 183200 Avg. Training loss: 1.0287 0.0077 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 183400 Avg. Training loss: 1.2697 0.0083 sec/batch\n",
      "Epoch 11/50 Iteration: 183600 Avg. Training loss: 0.7593 0.0079 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 183800 Avg. Training loss: 1.1888 0.0076 sec/batch\n",
      "Epoch 11/50 Iteration: 184000 Avg. Training loss: 1.1966 0.0077 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 184200 Avg. Training loss: 1.3656 0.0078 sec/batch\n",
      "Epoch 11/50 Iteration: 184400 Avg. Training loss: 1.1747 0.0081 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 184600 Avg. Training loss: 0.9185 0.0077 sec/batch\n",
      "Epoch 11/50 Iteration: 184800 Avg. Training loss: 1.1462 0.0077 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 185000 Avg. Training loss: 1.0614 0.0077 sec/batch\n",
      "Epoch 11/50 Iteration: 185200 Avg. Training loss: 1.2546 0.0079 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 185400 Avg. Training loss: 0.9823 0.0084 sec/batch\n",
      "Epoch 11/50 Iteration: 185600 Avg. Training loss: 1.1911 0.0079 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 185800 Avg. Training loss: 1.2317 0.0077 sec/batch\n",
      "Epoch 11/50 Iteration: 186000 Avg. Training loss: 1.1372 0.0080 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 186200 Avg. Training loss: 1.0398 0.0076 sec/batch\n",
      "Epoch 11/50 Iteration: 186400 Avg. Training loss: 0.9532 0.0082 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 186600 Avg. Training loss: 0.8987 0.0077 sec/batch\n",
      "Epoch 11/50 Iteration: 186800 Avg. Training loss: 0.9135 0.0077 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 187000 Avg. Training loss: 1.2449 0.0082 sec/batch\n",
      "Epoch 11/50 Iteration: 187200 Avg. Training loss: 1.2080 0.0075 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 187400 Avg. Training loss: 1.2960 0.0083 sec/batch\n",
      "Epoch 11/50 Iteration: 187600 Avg. Training loss: 1.2016 0.0079 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 187800 Avg. Training loss: 1.1381 0.0082 sec/batch\n",
      "Epoch 11/50 Iteration: 188000 Avg. Training loss: 0.9690 0.0076 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 188200 Avg. Training loss: 0.9754 0.0078 sec/batch\n",
      "Epoch 11/50 Iteration: 188400 Avg. Training loss: 1.0095 0.0077 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 188600 Avg. Training loss: 1.2891 0.0077 sec/batch\n",
      "Epoch 11/50 Iteration: 188800 Avg. Training loss: 1.3849 0.0075 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 189000 Avg. Training loss: 1.2927 0.0078 sec/batch\n",
      "Epoch 11/50 Iteration: 189200 Avg. Training loss: 1.3410 0.0077 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 189400 Avg. Training loss: 1.0666 0.0081 sec/batch\n",
      "Epoch 11/50 Iteration: 189600 Avg. Training loss: 1.1314 0.0075 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 189800 Avg. Training loss: 0.8481 0.0075 sec/batch\n",
      "Epoch 11/50 Iteration: 190000 Avg. Training loss: 1.1212 0.0074 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 190200 Avg. Training loss: 1.2179 0.0079 sec/batch\n",
      "Epoch 11/50 Iteration: 190400 Avg. Training loss: 1.1037 0.0092 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 190600 Avg. Training loss: 1.2769 0.0073 sec/batch\n",
      "Epoch 11/50 Iteration: 190800 Avg. Training loss: 1.3721 0.0076 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 191000 Avg. Training loss: 1.2880 0.0076 sec/batch\n",
      "Epoch 11/50 Iteration: 191200 Avg. Training loss: 1.0692 0.0077 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 191400 Avg. Training loss: 1.4512 0.0089 sec/batch\n",
      "Epoch 11/50 Iteration: 191600 Avg. Training loss: 1.1105 0.0076 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 191800 Avg. Training loss: 0.8375 0.0075 sec/batch\n",
      "Epoch 11/50 Iteration: 192000 Avg. Training loss: 1.2504 0.0077 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 192200 Avg. Training loss: 1.3115 0.0081 sec/batch\n",
      "Epoch 11/50 Iteration: 192400 Avg. Training loss: 1.0849 0.0077 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 192600 Avg. Training loss: 1.2873 0.0077 sec/batch\n",
      "Epoch 11/50 Iteration: 192800 Avg. Training loss: 1.2153 0.0074 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 193000 Avg. Training loss: 1.0457 0.0081 sec/batch\n",
      "Epoch 11/50 Iteration: 193200 Avg. Training loss: 1.0752 0.0085 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 193400 Avg. Training loss: 1.2532 0.0078 sec/batch\n",
      "Epoch 11/50 Iteration: 193600 Avg. Training loss: 0.9176 0.0076 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 193800 Avg. Training loss: 1.0222 0.0077 sec/batch\n",
      "Epoch 11/50 Iteration: 194000 Avg. Training loss: 0.8949 0.0077 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 194200 Avg. Training loss: 1.0728 0.0077 sec/batch\n",
      "Epoch 11/50 Iteration: 194400 Avg. Training loss: 1.2591 0.0079 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 194600 Avg. Training loss: 1.0417 0.0080 sec/batch\n",
      "Epoch 11/50 Iteration: 194800 Avg. Training loss: 1.3192 0.0087 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 195000 Avg. Training loss: 1.1934 0.0078 sec/batch\n",
      "Epoch 11/50 Iteration: 195200 Avg. Training loss: 1.2204 0.0092 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 195400 Avg. Training loss: 1.0530 0.0077 sec/batch\n",
      "Epoch 11/50 Iteration: 195600 Avg. Training loss: 1.1607 0.0078 sec/batch\n",
      "error\n",
      "Epoch 11/50 Iteration: 195800 Avg. Training loss: 1.3047 0.0074 sec/batch\n",
      "Epoch 13/50 Iteration: 224800 Avg. Training loss: 1.0806 0.0075 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 225000 Avg. Training loss: 1.3595 0.0074 sec/batch\n",
      "Epoch 13/50 Iteration: 225200 Avg. Training loss: 1.3863 0.0073 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 225400 Avg. Training loss: 1.1535 0.0076 sec/batch\n",
      "Epoch 13/50 Iteration: 225600 Avg. Training loss: 1.2697 0.0074 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 225800 Avg. Training loss: 0.9951 0.0078 sec/batch\n",
      "Epoch 13/50 Iteration: 226000 Avg. Training loss: 1.1582 0.0072 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 226200 Avg. Training loss: 0.8961 0.0072 sec/batch\n",
      "Epoch 13/50 Iteration: 226400 Avg. Training loss: 1.0299 0.0071 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 226600 Avg. Training loss: 1.1018 0.0078 sec/batch\n",
      "Epoch 13/50 Iteration: 226800 Avg. Training loss: 1.2865 0.0087 sec/batch\n",
      "error\n",
      "Epoch 13/50 Iteration: 227000 Avg. Training loss: 1.0676 0.0071 sec/batch\n",
      "Epoch 13/50 Iteration: 227200 Avg. Training loss: 1.1425 0.0073 sec/batch\n",
      "error\n",
      "Epoch 14/50 Iteration: 249800 Avg. Training loss: 1.0117 0.0092 sec/batch\n",
      "Epoch 14/50 Iteration: 250000 Avg. Training loss: 0.9792 0.0077 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 264000 Avg. Training loss: 1.1925 0.0077 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 264200 Avg. Training loss: 1.2956 0.0089 sec/batch\n",
      "Epoch 15/50 Iteration: 264400 Avg. Training loss: 1.0135 0.0076 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 264600 Avg. Training loss: 0.8659 0.0078 sec/batch\n",
      "Epoch 15/50 Iteration: 264800 Avg. Training loss: 1.0466 0.0077 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 265000 Avg. Training loss: 1.2800 0.0082 sec/batch\n",
      "Epoch 15/50 Iteration: 265200 Avg. Training loss: 0.9711 0.0079 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 265400 Avg. Training loss: 1.2218 0.0076 sec/batch\n",
      "Epoch 15/50 Iteration: 265600 Avg. Training loss: 1.0958 0.0075 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 265800 Avg. Training loss: 1.0424 0.0079 sec/batch\n",
      "Epoch 15/50 Iteration: 266000 Avg. Training loss: 1.2680 0.0079 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 266200 Avg. Training loss: 1.1285 0.0077 sec/batch\n",
      "Epoch 15/50 Iteration: 266400 Avg. Training loss: 0.8090 0.0075 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 266600 Avg. Training loss: 0.9345 0.0076 sec/batch\n",
      "Epoch 15/50 Iteration: 266800 Avg. Training loss: 0.9775 0.0077 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 267000 Avg. Training loss: 0.9147 0.0078 sec/batch\n",
      "Epoch 15/50 Iteration: 267200 Avg. Training loss: 1.1366 0.0078 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 267400 Avg. Training loss: 0.8855 0.0079 sec/batch\n",
      "Epoch 15/50 Iteration: 267600 Avg. Training loss: 1.2692 0.0088 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 267800 Avg. Training loss: 1.0409 0.0077 sec/batch\n",
      "Epoch 15/50 Iteration: 268000 Avg. Training loss: 1.1843 0.0091 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 268200 Avg. Training loss: 0.7954 0.0078 sec/batch\n",
      "Epoch 15/50 Iteration: 268400 Avg. Training loss: 1.1795 0.0078 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 268600 Avg. Training loss: 1.2700 0.0075 sec/batch\n",
      "Epoch 15/50 Iteration: 268800 Avg. Training loss: 1.3777 0.0079 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 269000 Avg. Training loss: 1.3042 0.0079 sec/batch\n",
      "Epoch 15/50 Iteration: 269200 Avg. Training loss: 1.4495 0.0077 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 269400 Avg. Training loss: 0.8971 0.0078 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 Iteration: 269600 Avg. Training loss: 1.1535 0.0076 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 269800 Avg. Training loss: 1.3892 0.0078 sec/batch\n",
      "Epoch 15/50 Iteration: 270000 Avg. Training loss: 1.0666 0.0078 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 270200 Avg. Training loss: 1.1759 0.0082 sec/batch\n",
      "Epoch 15/50 Iteration: 270400 Avg. Training loss: 0.9780 0.0078 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 270600 Avg. Training loss: 1.2077 0.0080 sec/batch\n",
      "Epoch 15/50 Iteration: 270800 Avg. Training loss: 1.2746 0.0082 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 271000 Avg. Training loss: 0.8180 0.0082 sec/batch\n",
      "Epoch 15/50 Iteration: 271200 Avg. Training loss: 0.8735 0.0082 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 271400 Avg. Training loss: 1.0848 0.0074 sec/batch\n",
      "Epoch 15/50 Iteration: 271600 Avg. Training loss: 1.1907 0.0079 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 271800 Avg. Training loss: 1.6049 0.0086 sec/batch\n",
      "Epoch 15/50 Iteration: 272000 Avg. Training loss: 1.2749 0.0076 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 272200 Avg. Training loss: 0.9554 0.0077 sec/batch\n",
      "Epoch 15/50 Iteration: 272400 Avg. Training loss: 1.3200 0.0078 sec/batch\n",
      "error\n",
      "Epoch 15/50 Iteration: 272600 Avg. Training loss: 0.9620 0.0085 sec/batch\n",
      "Epoch 15/50 Iteration: 272800 Avg. Training loss: 1.1882 0.0079 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 273000 Avg. Training loss: 1.1430 0.0018 sec/batch\n",
      "Epoch 16/50 Iteration: 273200 Avg. Training loss: 1.2746 0.0082 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 273400 Avg. Training loss: 1.0111 0.0082 sec/batch\n",
      "Epoch 16/50 Iteration: 273600 Avg. Training loss: 1.0906 0.0078 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 273800 Avg. Training loss: 1.3334 0.0087 sec/batch\n",
      "Epoch 16/50 Iteration: 274000 Avg. Training loss: 1.1877 0.0083 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 274200 Avg. Training loss: 1.0340 0.0078 sec/batch\n",
      "Epoch 16/50 Iteration: 274400 Avg. Training loss: 1.2216 0.0083 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 274600 Avg. Training loss: 0.9691 0.0081 sec/batch\n",
      "Epoch 16/50 Iteration: 274800 Avg. Training loss: 1.2436 0.0076 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 275000 Avg. Training loss: 1.1691 0.0078 sec/batch\n",
      "Epoch 16/50 Iteration: 275200 Avg. Training loss: 1.1495 0.0078 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 275400 Avg. Training loss: 0.9241 0.0083 sec/batch\n",
      "Epoch 16/50 Iteration: 275600 Avg. Training loss: 0.8547 0.0077 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 275800 Avg. Training loss: 1.1359 0.0079 sec/batch\n",
      "Epoch 16/50 Iteration: 276000 Avg. Training loss: 1.1196 0.0079 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 276200 Avg. Training loss: 1.3272 0.0081 sec/batch\n",
      "Epoch 16/50 Iteration: 276400 Avg. Training loss: 1.1648 0.0084 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 276600 Avg. Training loss: 1.1835 0.0078 sec/batch\n",
      "Epoch 16/50 Iteration: 276800 Avg. Training loss: 1.3197 0.0077 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 277000 Avg. Training loss: 1.0762 0.0082 sec/batch\n",
      "Epoch 16/50 Iteration: 277200 Avg. Training loss: 0.9800 0.0077 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 277400 Avg. Training loss: 1.0173 0.0083 sec/batch\n",
      "Epoch 16/50 Iteration: 277600 Avg. Training loss: 0.9002 0.0077 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 277800 Avg. Training loss: 0.9002 0.0078 sec/batch\n",
      "Epoch 16/50 Iteration: 278000 Avg. Training loss: 1.2987 0.0082 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 278200 Avg. Training loss: 0.8111 0.0077 sec/batch\n",
      "Epoch 16/50 Iteration: 278400 Avg. Training loss: 1.3596 0.0086 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 278600 Avg. Training loss: 1.3624 0.0080 sec/batch\n",
      "Epoch 16/50 Iteration: 278800 Avg. Training loss: 1.1312 0.0086 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 279000 Avg. Training loss: 0.8428 0.0190 sec/batch\n",
      "Epoch 16/50 Iteration: 279200 Avg. Training loss: 1.0310 0.0089 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 279400 Avg. Training loss: 0.9864 0.0089 sec/batch\n",
      "Epoch 16/50 Iteration: 279600 Avg. Training loss: 1.3104 0.0078 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 279800 Avg. Training loss: 1.0476 0.0077 sec/batch\n",
      "Epoch 16/50 Iteration: 280000 Avg. Training loss: 1.1299 0.0081 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 280200 Avg. Training loss: 1.1869 0.0080 sec/batch\n",
      "Epoch 16/50 Iteration: 280400 Avg. Training loss: 0.8991 0.0083 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 280600 Avg. Training loss: 1.0139 0.0079 sec/batch\n",
      "Epoch 16/50 Iteration: 280800 Avg. Training loss: 1.0141 0.0078 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 281000 Avg. Training loss: 0.9625 0.0077 sec/batch\n",
      "Epoch 16/50 Iteration: 281200 Avg. Training loss: 1.2453 0.0085 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 281400 Avg. Training loss: 1.2434 0.0091 sec/batch\n",
      "Epoch 16/50 Iteration: 281600 Avg. Training loss: 1.1358 0.0077 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 281800 Avg. Training loss: 1.0236 0.0078 sec/batch\n",
      "Epoch 16/50 Iteration: 282000 Avg. Training loss: 1.2119 0.0079 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 282200 Avg. Training loss: 1.1429 0.0080 sec/batch\n",
      "Epoch 16/50 Iteration: 282400 Avg. Training loss: 1.3623 0.0088 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 282600 Avg. Training loss: 0.8214 0.0075 sec/batch\n",
      "Epoch 16/50 Iteration: 282800 Avg. Training loss: 0.7681 0.0075 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 283000 Avg. Training loss: 1.2144 0.0076 sec/batch\n",
      "Epoch 16/50 Iteration: 283200 Avg. Training loss: 1.3377 0.0080 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 283400 Avg. Training loss: 1.1187 0.0078 sec/batch\n",
      "Epoch 16/50 Iteration: 283600 Avg. Training loss: 1.0058 0.0075 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 283800 Avg. Training loss: 1.0206 0.0073 sec/batch\n",
      "Epoch 16/50 Iteration: 284000 Avg. Training loss: 1.0282 0.0078 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 284200 Avg. Training loss: 1.1591 0.0077 sec/batch\n",
      "Epoch 16/50 Iteration: 284400 Avg. Training loss: 1.1854 0.0074 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 284600 Avg. Training loss: 0.8966 0.0074 sec/batch\n",
      "Epoch 16/50 Iteration: 284800 Avg. Training loss: 1.0256 0.0074 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 285000 Avg. Training loss: 0.9382 0.0075 sec/batch\n",
      "Epoch 16/50 Iteration: 285200 Avg. Training loss: 1.1087 0.0075 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 285400 Avg. Training loss: 1.0322 0.0075 sec/batch\n",
      "Epoch 16/50 Iteration: 285600 Avg. Training loss: 1.0176 0.0075 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 285800 Avg. Training loss: 1.3307 0.0090 sec/batch\n",
      "Epoch 16/50 Iteration: 286000 Avg. Training loss: 0.9674 0.0079 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 286200 Avg. Training loss: 1.0906 0.0090 sec/batch\n",
      "Epoch 16/50 Iteration: 286400 Avg. Training loss: 0.8908 0.0076 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 286600 Avg. Training loss: 1.0515 0.0076 sec/batch\n",
      "Epoch 16/50 Iteration: 286800 Avg. Training loss: 1.1249 0.0072 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 287000 Avg. Training loss: 1.3168 0.0076 sec/batch\n",
      "Epoch 16/50 Iteration: 287200 Avg. Training loss: 1.2667 0.0076 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 287400 Avg. Training loss: 1.4959 0.0075 sec/batch\n",
      "Epoch 16/50 Iteration: 287600 Avg. Training loss: 0.9846 0.0074 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 287800 Avg. Training loss: 1.1144 0.0074 sec/batch\n",
      "Epoch 16/50 Iteration: 288000 Avg. Training loss: 1.4113 0.0077 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 288200 Avg. Training loss: 1.2983 0.0074 sec/batch\n",
      "Epoch 16/50 Iteration: 288400 Avg. Training loss: 1.2955 0.0076 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 288600 Avg. Training loss: 1.1903 0.0072 sec/batch\n",
      "Epoch 16/50 Iteration: 288800 Avg. Training loss: 1.2088 0.0074 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 289000 Avg. Training loss: 1.3237 0.0079 sec/batch\n",
      "Epoch 16/50 Iteration: 289200 Avg. Training loss: 0.7296 0.0074 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 289400 Avg. Training loss: 1.0312 0.0074 sec/batch\n",
      "Epoch 16/50 Iteration: 289600 Avg. Training loss: 1.1633 0.0072 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 289800 Avg. Training loss: 1.2187 0.0076 sec/batch\n",
      "Epoch 16/50 Iteration: 290000 Avg. Training loss: 1.4640 0.0082 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 290200 Avg. Training loss: 1.3419 0.0073 sec/batch\n",
      "Epoch 16/50 Iteration: 290400 Avg. Training loss: 0.9270 0.0072 sec/batch\n",
      "error\n",
      "Epoch 16/50 Iteration: 290600 Avg. Training loss: 1.1311 0.0077 sec/batch\n",
      "Epoch 16/50 Iteration: 290800 Avg. Training loss: 0.9951 0.0082 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 Iteration: 291000 Avg. Training loss: 1.1211 0.0077 sec/batch\n",
      "Epoch 17/50 Iteration: 291200 Avg. Training loss: 1.1983 0.0019 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 291400 Avg. Training loss: 1.3335 0.0078 sec/batch\n",
      "Epoch 17/50 Iteration: 291600 Avg. Training loss: 1.0274 0.0078 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 291800 Avg. Training loss: 0.8512 0.0076 sec/batch\n",
      "Epoch 17/50 Iteration: 292000 Avg. Training loss: 1.4141 0.0082 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 292200 Avg. Training loss: 1.1023 0.0080 sec/batch\n",
      "Epoch 17/50 Iteration: 292400 Avg. Training loss: 1.0503 0.0074 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 292600 Avg. Training loss: 1.1477 0.0080 sec/batch\n",
      "Epoch 17/50 Iteration: 292800 Avg. Training loss: 0.9094 0.0078 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 293000 Avg. Training loss: 1.1397 0.0073 sec/batch\n",
      "Epoch 17/50 Iteration: 293200 Avg. Training loss: 1.2762 0.0074 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 293400 Avg. Training loss: 1.2716 0.0076 sec/batch\n",
      "Epoch 17/50 Iteration: 293600 Avg. Training loss: 1.1190 0.0079 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 293800 Avg. Training loss: 0.7609 0.0074 sec/batch\n",
      "Epoch 17/50 Iteration: 294000 Avg. Training loss: 1.2178 0.0075 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 294200 Avg. Training loss: 1.0440 0.0075 sec/batch\n",
      "Epoch 17/50 Iteration: 294400 Avg. Training loss: 1.2852 0.0077 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 294600 Avg. Training loss: 0.8987 0.0082 sec/batch\n",
      "Epoch 17/50 Iteration: 294800 Avg. Training loss: 1.1573 0.0078 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 295000 Avg. Training loss: 1.1718 0.0076 sec/batch\n",
      "Epoch 17/50 Iteration: 295200 Avg. Training loss: 1.2370 0.0084 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 295400 Avg. Training loss: 0.9587 0.0075 sec/batch\n",
      "Epoch 17/50 Iteration: 295600 Avg. Training loss: 0.9864 0.0080 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 295800 Avg. Training loss: 0.7778 0.0073 sec/batch\n",
      "Epoch 17/50 Iteration: 296000 Avg. Training loss: 0.9216 0.0073 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 296200 Avg. Training loss: 1.4626 0.0078 sec/batch\n",
      "Epoch 17/50 Iteration: 296400 Avg. Training loss: 1.0606 0.0072 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 296600 Avg. Training loss: 1.3144 0.0081 sec/batch\n",
      "Epoch 17/50 Iteration: 296800 Avg. Training loss: 1.2281 0.0076 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 297000 Avg. Training loss: 1.2008 0.0082 sec/batch\n",
      "Epoch 17/50 Iteration: 297200 Avg. Training loss: 0.9218 0.0076 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 297400 Avg. Training loss: 1.0725 0.0075 sec/batch\n",
      "Epoch 17/50 Iteration: 297600 Avg. Training loss: 1.0436 0.0076 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 297800 Avg. Training loss: 1.1166 0.0075 sec/batch\n",
      "Epoch 17/50 Iteration: 298000 Avg. Training loss: 1.1206 0.0074 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 298200 Avg. Training loss: 1.1402 0.0077 sec/batch\n",
      "Epoch 17/50 Iteration: 298400 Avg. Training loss: 1.0448 0.0075 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 298600 Avg. Training loss: 0.8406 0.0080 sec/batch\n",
      "Epoch 17/50 Iteration: 298800 Avg. Training loss: 1.0833 0.0073 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 299000 Avg. Training loss: 0.7802 0.0073 sec/batch\n",
      "Epoch 17/50 Iteration: 299200 Avg. Training loss: 1.1432 0.0072 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 299400 Avg. Training loss: 1.3554 0.0080 sec/batch\n",
      "Epoch 17/50 Iteration: 299600 Avg. Training loss: 1.1384 0.0086 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 299800 Avg. Training loss: 1.2179 0.0073 sec/batch\n",
      "Epoch 17/50 Iteration: 300000 Avg. Training loss: 1.0227 0.0074 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 300200 Avg. Training loss: 1.0729 0.0076 sec/batch\n",
      "Epoch 17/50 Iteration: 300400 Avg. Training loss: 1.1220 0.0075 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 300600 Avg. Training loss: 1.3285 0.0086 sec/batch\n",
      "Epoch 17/50 Iteration: 300800 Avg. Training loss: 0.9885 0.0074 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 301000 Avg. Training loss: 0.8090 0.0073 sec/batch\n",
      "Epoch 17/50 Iteration: 301200 Avg. Training loss: 1.0664 0.0075 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 301400 Avg. Training loss: 1.3243 0.0082 sec/batch\n",
      "Epoch 17/50 Iteration: 301600 Avg. Training loss: 1.1800 0.0081 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 301800 Avg. Training loss: 1.1197 0.0076 sec/batch\n",
      "Epoch 17/50 Iteration: 302000 Avg. Training loss: 1.1527 0.0072 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 302200 Avg. Training loss: 0.9800 0.0078 sec/batch\n",
      "Epoch 17/50 Iteration: 302400 Avg. Training loss: 1.1377 0.0076 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 302600 Avg. Training loss: 1.0336 0.0075 sec/batch\n",
      "Epoch 17/50 Iteration: 302800 Avg. Training loss: 0.8204 0.0073 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 303000 Avg. Training loss: 1.0009 0.0075 sec/batch\n",
      "Epoch 17/50 Iteration: 303200 Avg. Training loss: 0.7399 0.0074 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 303400 Avg. Training loss: 0.9868 0.0073 sec/batch\n",
      "Epoch 17/50 Iteration: 303600 Avg. Training loss: 1.0654 0.0076 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 303800 Avg. Training loss: 0.9623 0.0076 sec/batch\n",
      "Epoch 17/50 Iteration: 304000 Avg. Training loss: 1.2067 0.0086 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 304200 Avg. Training loss: 1.2741 0.0075 sec/batch\n",
      "Epoch 17/50 Iteration: 304400 Avg. Training loss: 1.1191 0.0089 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 304600 Avg. Training loss: 0.9207 0.0076 sec/batch\n",
      "Epoch 17/50 Iteration: 304800 Avg. Training loss: 1.4013 0.0076 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 305000 Avg. Training loss: 1.0285 0.0074 sec/batch\n",
      "Epoch 17/50 Iteration: 305200 Avg. Training loss: 1.3247 0.0078 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 305400 Avg. Training loss: 1.2154 0.0079 sec/batch\n",
      "Epoch 17/50 Iteration: 305600 Avg. Training loss: 1.2865 0.0076 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 305800 Avg. Training loss: 0.8407 0.0075 sec/batch\n",
      "Epoch 17/50 Iteration: 306000 Avg. Training loss: 1.0582 0.0073 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 306200 Avg. Training loss: 1.2489 0.0075 sec/batch\n",
      "Epoch 17/50 Iteration: 306400 Avg. Training loss: 1.3580 0.0075 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 306600 Avg. Training loss: 1.2074 0.0077 sec/batch\n",
      "Epoch 17/50 Iteration: 306800 Avg. Training loss: 1.0535 0.0074 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 307000 Avg. Training loss: 1.2066 0.0076 sec/batch\n",
      "Epoch 17/50 Iteration: 307200 Avg. Training loss: 1.2559 0.0080 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 307400 Avg. Training loss: 0.8688 0.0075 sec/batch\n",
      "Epoch 17/50 Iteration: 307600 Avg. Training loss: 0.9123 0.0076 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 307800 Avg. Training loss: 1.0657 0.0073 sec/batch\n",
      "Epoch 17/50 Iteration: 308000 Avg. Training loss: 1.2623 0.0077 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 308200 Avg. Training loss: 1.6014 0.0082 sec/batch\n",
      "Epoch 17/50 Iteration: 308400 Avg. Training loss: 1.2872 0.0074 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 308600 Avg. Training loss: 1.1196 0.0073 sec/batch\n",
      "Epoch 17/50 Iteration: 308800 Avg. Training loss: 1.1563 0.0075 sec/batch\n",
      "error\n",
      "Epoch 17/50 Iteration: 309000 Avg. Training loss: 0.9291 0.0083 sec/batch\n",
      "Epoch 17/50 Iteration: 309200 Avg. Training loss: 1.0588 0.0077 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 309400 Avg. Training loss: 1.1754 0.0021 sec/batch\n",
      "Epoch 18/50 Iteration: 309600 Avg. Training loss: 1.1650 0.0079 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 309800 Avg. Training loss: 1.0775 0.0079 sec/batch\n",
      "Epoch 18/50 Iteration: 310000 Avg. Training loss: 0.9514 0.0076 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 310200 Avg. Training loss: 1.3384 0.0085 sec/batch\n",
      "Epoch 18/50 Iteration: 310400 Avg. Training loss: 1.3033 0.0079 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 310600 Avg. Training loss: 0.9681 0.0075 sec/batch\n",
      "Epoch 18/50 Iteration: 310800 Avg. Training loss: 1.0658 0.0080 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 311000 Avg. Training loss: 0.8640 0.0077 sec/batch\n",
      "Epoch 18/50 Iteration: 311200 Avg. Training loss: 0.9778 0.0073 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 311400 Avg. Training loss: 1.2368 0.0074 sec/batch\n",
      "Epoch 18/50 Iteration: 311600 Avg. Training loss: 1.3850 0.0074 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 311800 Avg. Training loss: 1.1276 0.0078 sec/batch\n",
      "Epoch 18/50 Iteration: 312000 Avg. Training loss: 0.6967 0.0073 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 312200 Avg. Training loss: 1.3107 0.0075 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 Iteration: 312400 Avg. Training loss: 1.0202 0.0074 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 312600 Avg. Training loss: 1.1308 0.0077 sec/batch\n",
      "Epoch 18/50 Iteration: 312800 Avg. Training loss: 1.1603 0.0081 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 313000 Avg. Training loss: 1.2956 0.0075 sec/batch\n",
      "Epoch 18/50 Iteration: 313200 Avg. Training loss: 1.2049 0.0074 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 313400 Avg. Training loss: 1.1559 0.0077 sec/batch\n",
      "Epoch 18/50 Iteration: 313600 Avg. Training loss: 0.8568 0.0072 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 313800 Avg. Training loss: 1.0182 0.0080 sec/batch\n",
      "Epoch 18/50 Iteration: 314000 Avg. Training loss: 0.8668 0.0074 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 314200 Avg. Training loss: 0.8644 0.0074 sec/batch\n",
      "Epoch 18/50 Iteration: 314400 Avg. Training loss: 1.1192 0.0077 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 314600 Avg. Training loss: 0.9469 0.0072 sec/batch\n",
      "Epoch 18/50 Iteration: 314800 Avg. Training loss: 1.2341 0.0081 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 315000 Avg. Training loss: 1.1939 0.0075 sec/batch\n",
      "Epoch 18/50 Iteration: 315200 Avg. Training loss: 1.1282 0.0080 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 315400 Avg. Training loss: 1.1703 0.0075 sec/batch\n",
      "Epoch 18/50 Iteration: 315600 Avg. Training loss: 1.0632 0.0075 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 315800 Avg. Training loss: 0.8432 0.0078 sec/batch\n",
      "Epoch 18/50 Iteration: 316000 Avg. Training loss: 1.1505 0.0076 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 316200 Avg. Training loss: 1.1398 0.0074 sec/batch\n",
      "Epoch 18/50 Iteration: 316400 Avg. Training loss: 1.1806 0.0078 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 316600 Avg. Training loss: 1.1315 0.0075 sec/batch\n",
      "Epoch 18/50 Iteration: 316800 Avg. Training loss: 0.9466 0.0079 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 317000 Avg. Training loss: 0.9395 0.0073 sec/batch\n",
      "Epoch 18/50 Iteration: 317200 Avg. Training loss: 0.9519 0.0079 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 317400 Avg. Training loss: 1.0237 0.0076 sec/batch\n",
      "Epoch 18/50 Iteration: 317600 Avg. Training loss: 1.3468 0.0081 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 317800 Avg. Training loss: 1.2232 0.0086 sec/batch\n",
      "Epoch 18/50 Iteration: 318000 Avg. Training loss: 1.2966 0.0072 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 318200 Avg. Training loss: 1.0306 0.0074 sec/batch\n",
      "Epoch 18/50 Iteration: 318400 Avg. Training loss: 1.2641 0.0075 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 318600 Avg. Training loss: 1.0258 0.0075 sec/batch\n",
      "Epoch 18/50 Iteration: 318800 Avg. Training loss: 1.4908 0.0086 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 319000 Avg. Training loss: 0.8581 0.0074 sec/batch\n",
      "Epoch 18/50 Iteration: 319200 Avg. Training loss: 0.8506 0.0074 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 319400 Avg. Training loss: 1.2059 0.0075 sec/batch\n",
      "Epoch 18/50 Iteration: 319600 Avg. Training loss: 1.1301 0.0079 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 319800 Avg. Training loss: 1.1375 0.0077 sec/batch\n",
      "Epoch 18/50 Iteration: 320000 Avg. Training loss: 1.0744 0.0074 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 320200 Avg. Training loss: 1.1571 0.0072 sec/batch\n",
      "Epoch 18/50 Iteration: 320400 Avg. Training loss: 1.0903 0.0078 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 320600 Avg. Training loss: 1.0966 0.0077 sec/batch\n",
      "Epoch 18/50 Iteration: 320800 Avg. Training loss: 1.0026 0.0074 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 321000 Avg. Training loss: 0.8312 0.0073 sec/batch\n",
      "Epoch 18/50 Iteration: 321200 Avg. Training loss: 1.1286 0.0075 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 321400 Avg. Training loss: 0.7253 0.0074 sec/batch\n",
      "Epoch 18/50 Iteration: 321600 Avg. Training loss: 1.2107 0.0076 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 321800 Avg. Training loss: 1.0638 0.0075 sec/batch\n",
      "Epoch 18/50 Iteration: 322000 Avg. Training loss: 1.0233 0.0077 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 322200 Avg. Training loss: 1.3099 0.0086 sec/batch\n",
      "Epoch 18/50 Iteration: 322400 Avg. Training loss: 1.1634 0.0072 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 322600 Avg. Training loss: 1.0539 0.0088 sec/batch\n",
      "Epoch 18/50 Iteration: 322800 Avg. Training loss: 0.8613 0.0074 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 323000 Avg. Training loss: 1.1899 0.0075 sec/batch\n",
      "Epoch 18/50 Iteration: 323200 Avg. Training loss: 1.0222 0.0071 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 323400 Avg. Training loss: 1.2340 0.0077 sec/batch\n",
      "Epoch 18/50 Iteration: 323600 Avg. Training loss: 1.2797 0.0075 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 323800 Avg. Training loss: 1.2527 0.0076 sec/batch\n",
      "Epoch 18/50 Iteration: 324000 Avg. Training loss: 1.0579 0.0073 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 324200 Avg. Training loss: 1.2018 0.0071 sec/batch\n",
      "Epoch 18/50 Iteration: 324400 Avg. Training loss: 1.2440 0.0076 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 324600 Avg. Training loss: 1.4241 0.0073 sec/batch\n",
      "Epoch 18/50 Iteration: 324800 Avg. Training loss: 1.4194 0.0076 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 325000 Avg. Training loss: 0.9968 0.0072 sec/batch\n",
      "Epoch 18/50 Iteration: 325200 Avg. Training loss: 1.1223 0.0074 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 325400 Avg. Training loss: 1.2748 0.0078 sec/batch\n",
      "Epoch 18/50 Iteration: 325600 Avg. Training loss: 0.8688 0.0072 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 325800 Avg. Training loss: 1.1949 0.0073 sec/batch\n",
      "Epoch 18/50 Iteration: 326000 Avg. Training loss: 0.9706 0.0071 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 326200 Avg. Training loss: 1.3703 0.0076 sec/batch\n",
      "Epoch 18/50 Iteration: 326400 Avg. Training loss: 1.3102 0.0080 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 326600 Avg. Training loss: 1.1529 0.0072 sec/batch\n",
      "Epoch 18/50 Iteration: 326800 Avg. Training loss: 0.7088 0.0071 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 327000 Avg. Training loss: 1.2392 0.0075 sec/batch\n",
      "Epoch 18/50 Iteration: 327200 Avg. Training loss: 1.0609 0.0082 sec/batch\n",
      "error\n",
      "Epoch 18/50 Iteration: 327400 Avg. Training loss: 1.0505 0.0076 sec/batch\n",
      "Epoch 19/50 Iteration: 327600 Avg. Training loss: 1.1782 0.0021 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 327800 Avg. Training loss: 1.4105 0.0079 sec/batch\n",
      "Epoch 19/50 Iteration: 328000 Avg. Training loss: 0.9838 0.0076 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 328200 Avg. Training loss: 1.0285 0.0074 sec/batch\n",
      "Epoch 19/50 Iteration: 328400 Avg. Training loss: 1.5458 0.0083 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 328600 Avg. Training loss: 1.2417 0.0078 sec/batch\n",
      "Epoch 19/50 Iteration: 328800 Avg. Training loss: 1.0551 0.0071 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 329000 Avg. Training loss: 1.2301 0.0079 sec/batch\n",
      "Epoch 19/50 Iteration: 329200 Avg. Training loss: 1.1355 0.0075 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 329400 Avg. Training loss: 1.1198 0.0070 sec/batch\n",
      "Epoch 19/50 Iteration: 329600 Avg. Training loss: 1.1086 0.0071 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 329800 Avg. Training loss: 1.4387 0.0075 sec/batch\n",
      "Epoch 19/50 Iteration: 330000 Avg. Training loss: 0.9742 0.0078 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 330200 Avg. Training loss: 0.9175 0.0072 sec/batch\n",
      "Epoch 19/50 Iteration: 330400 Avg. Training loss: 0.9495 0.0073 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 330600 Avg. Training loss: 1.0560 0.0075 sec/batch\n",
      "Epoch 19/50 Iteration: 330800 Avg. Training loss: 1.2508 0.0076 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 331000 Avg. Training loss: 1.1090 0.0080 sec/batch\n",
      "Epoch 19/50 Iteration: 331200 Avg. Training loss: 1.1489 0.0073 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 331400 Avg. Training loss: 1.2807 0.0071 sec/batch\n",
      "Epoch 19/50 Iteration: 331600 Avg. Training loss: 1.1012 0.0075 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 331800 Avg. Training loss: 0.8643 0.0071 sec/batch\n",
      "Epoch 19/50 Iteration: 332000 Avg. Training loss: 0.9432 0.0080 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 332200 Avg. Training loss: 0.7061 0.0075 sec/batch\n",
      "Epoch 19/50 Iteration: 332400 Avg. Training loss: 0.8451 0.0074 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 332600 Avg. Training loss: 1.0960 0.0079 sec/batch\n",
      "Epoch 19/50 Iteration: 332800 Avg. Training loss: 1.0245 0.0074 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 333000 Avg. Training loss: 1.3766 0.0087 sec/batch\n",
      "Epoch 19/50 Iteration: 333200 Avg. Training loss: 1.3438 0.0082 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 333400 Avg. Training loss: 1.1207 0.0081 sec/batch\n",
      "Epoch 19/50 Iteration: 333600 Avg. Training loss: 0.9359 0.0076 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 Iteration: 333800 Avg. Training loss: 1.2853 0.0076 sec/batch\n",
      "Epoch 19/50 Iteration: 334000 Avg. Training loss: 1.1107 0.0075 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 334200 Avg. Training loss: 1.2052 0.0076 sec/batch\n",
      "Epoch 19/50 Iteration: 334400 Avg. Training loss: 1.0955 0.0074 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 334600 Avg. Training loss: 1.2392 0.0078 sec/batch\n",
      "Epoch 19/50 Iteration: 334800 Avg. Training loss: 1.2520 0.0076 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 335000 Avg. Training loss: 0.8939 0.0080 sec/batch\n",
      "Epoch 19/50 Iteration: 335200 Avg. Training loss: 1.1966 0.0073 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 335400 Avg. Training loss: 0.7046 0.0073 sec/batch\n",
      "Epoch 19/50 Iteration: 335600 Avg. Training loss: 1.0829 0.0072 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 335800 Avg. Training loss: 1.2547 0.0084 sec/batch\n",
      "Epoch 19/50 Iteration: 336000 Avg. Training loss: 1.1947 0.0087 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 336200 Avg. Training loss: 1.3031 0.0073 sec/batch\n",
      "Epoch 19/50 Iteration: 336400 Avg. Training loss: 1.0670 0.0075 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 336600 Avg. Training loss: 1.0836 0.0076 sec/batch\n",
      "Epoch 19/50 Iteration: 336800 Avg. Training loss: 1.0290 0.0077 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 337000 Avg. Training loss: 1.2797 0.0088 sec/batch\n",
      "Epoch 19/50 Iteration: 337200 Avg. Training loss: 0.7226 0.0075 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 337400 Avg. Training loss: 0.8737 0.0075 sec/batch\n",
      "Epoch 19/50 Iteration: 337600 Avg. Training loss: 1.2880 0.0077 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 337800 Avg. Training loss: 1.4279 0.0081 sec/batch\n",
      "Epoch 19/50 Iteration: 338000 Avg. Training loss: 1.1237 0.0083 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 338200 Avg. Training loss: 1.1028 0.0078 sec/batch\n",
      "Epoch 19/50 Iteration: 338400 Avg. Training loss: 1.0891 0.0185 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 338600 Avg. Training loss: 0.9641 0.0085 sec/batch\n",
      "Epoch 19/50 Iteration: 338800 Avg. Training loss: 1.0080 0.0081 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 339000 Avg. Training loss: 0.9710 0.0075 sec/batch\n",
      "Epoch 19/50 Iteration: 339200 Avg. Training loss: 0.8846 0.0074 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 339400 Avg. Training loss: 0.9812 0.0084 sec/batch\n",
      "Epoch 19/50 Iteration: 339600 Avg. Training loss: 0.7909 0.0082 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 339800 Avg. Training loss: 0.9049 0.0077 sec/batch\n",
      "Epoch 19/50 Iteration: 340000 Avg. Training loss: 1.2085 0.0077 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 340200 Avg. Training loss: 1.0750 0.0078 sec/batch\n",
      "Epoch 19/50 Iteration: 340400 Avg. Training loss: 1.2442 0.0088 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 340600 Avg. Training loss: 1.0224 0.0076 sec/batch\n",
      "Epoch 19/50 Iteration: 340800 Avg. Training loss: 0.9228 0.0093 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 341000 Avg. Training loss: 0.8885 0.0078 sec/batch\n",
      "Epoch 19/50 Iteration: 341200 Avg. Training loss: 1.3217 0.0077 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 341400 Avg. Training loss: 1.2885 0.0074 sec/batch\n",
      "Epoch 19/50 Iteration: 341600 Avg. Training loss: 1.2999 0.0079 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 341800 Avg. Training loss: 1.2678 0.0078 sec/batch\n",
      "Epoch 19/50 Iteration: 342000 Avg. Training loss: 1.2711 0.0076 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 342200 Avg. Training loss: 1.0508 0.0076 sec/batch\n",
      "Epoch 19/50 Iteration: 342400 Avg. Training loss: 1.0039 0.0074 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 342600 Avg. Training loss: 1.1245 0.0078 sec/batch\n",
      "Epoch 19/50 Iteration: 342800 Avg. Training loss: 1.3530 0.0075 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 343000 Avg. Training loss: 1.1911 0.0079 sec/batch\n",
      "Epoch 19/50 Iteration: 343200 Avg. Training loss: 1.1861 0.0075 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 343400 Avg. Training loss: 1.0454 0.0077 sec/batch\n",
      "Epoch 19/50 Iteration: 343600 Avg. Training loss: 1.2242 0.0081 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 343800 Avg. Training loss: 0.8593 0.0075 sec/batch\n",
      "Epoch 19/50 Iteration: 344000 Avg. Training loss: 0.9160 0.0076 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 344200 Avg. Training loss: 1.0917 0.0074 sec/batch\n",
      "Epoch 19/50 Iteration: 344400 Avg. Training loss: 1.2634 0.0079 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 344600 Avg. Training loss: 1.5566 0.0084 sec/batch\n",
      "Epoch 19/50 Iteration: 344800 Avg. Training loss: 1.2649 0.0075 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 345000 Avg. Training loss: 0.9988 0.0075 sec/batch\n",
      "Epoch 19/50 Iteration: 345200 Avg. Training loss: 1.2460 0.0078 sec/batch\n",
      "error\n",
      "Epoch 19/50 Iteration: 345400 Avg. Training loss: 0.9719 0.0086 sec/batch\n",
      "Epoch 19/50 Iteration: 345600 Avg. Training loss: 1.0789 0.0078 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 345800 Avg. Training loss: 1.0844 0.0024 sec/batch\n",
      "Epoch 20/50 Iteration: 346000 Avg. Training loss: 1.3448 0.0081 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 346200 Avg. Training loss: 1.0191 0.0080 sec/batch\n",
      "Epoch 20/50 Iteration: 346400 Avg. Training loss: 1.1056 0.0077 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 346600 Avg. Training loss: 1.4861 0.0087 sec/batch\n",
      "Epoch 20/50 Iteration: 346800 Avg. Training loss: 1.4025 0.0080 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 347000 Avg. Training loss: 1.0042 0.0074 sec/batch\n",
      "Epoch 20/50 Iteration: 347200 Avg. Training loss: 1.0559 0.0082 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 347400 Avg. Training loss: 1.0166 0.0078 sec/batch\n",
      "Epoch 20/50 Iteration: 347600 Avg. Training loss: 1.2022 0.0074 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 347800 Avg. Training loss: 1.1372 0.0075 sec/batch\n",
      "Epoch 20/50 Iteration: 348000 Avg. Training loss: 1.5920 0.0079 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 348200 Avg. Training loss: 0.8921 0.0086 sec/batch\n",
      "Epoch 20/50 Iteration: 348400 Avg. Training loss: 0.8204 0.0074 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 348600 Avg. Training loss: 1.0510 0.0078 sec/batch\n",
      "Epoch 20/50 Iteration: 348800 Avg. Training loss: 0.9621 0.0077 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 349000 Avg. Training loss: 1.2947 0.0080 sec/batch\n",
      "Epoch 20/50 Iteration: 349200 Avg. Training loss: 1.2103 0.0084 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 349400 Avg. Training loss: 1.0306 0.0076 sec/batch\n",
      "Epoch 20/50 Iteration: 349600 Avg. Training loss: 1.2013 0.0075 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 349800 Avg. Training loss: 1.1216 0.0079 sec/batch\n",
      "Epoch 20/50 Iteration: 350000 Avg. Training loss: 0.9424 0.0072 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 350200 Avg. Training loss: 1.0590 0.0081 sec/batch\n",
      "Epoch 20/50 Iteration: 350400 Avg. Training loss: 0.9042 0.0072 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 350600 Avg. Training loss: 0.7906 0.0074 sec/batch\n",
      "Epoch 20/50 Iteration: 350800 Avg. Training loss: 1.1713 0.0078 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 351000 Avg. Training loss: 1.0566 0.0071 sec/batch\n",
      "Epoch 20/50 Iteration: 351200 Avg. Training loss: 1.1994 0.0079 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 351400 Avg. Training loss: 1.1781 0.0071 sec/batch\n",
      "Epoch 20/50 Iteration: 351600 Avg. Training loss: 1.0440 0.0075 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 351800 Avg. Training loss: 0.8986 0.0070 sec/batch\n",
      "Epoch 20/50 Iteration: 352000 Avg. Training loss: 0.9969 0.0072 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 352200 Avg. Training loss: 0.9072 0.0071 sec/batch\n",
      "Epoch 20/50 Iteration: 352400 Avg. Training loss: 1.0925 0.0069 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 352600 Avg. Training loss: 1.0444 0.0070 sec/batch\n",
      "Epoch 20/50 Iteration: 352800 Avg. Training loss: 1.1293 0.0072 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 353000 Avg. Training loss: 1.2657 0.0069 sec/batch\n",
      "Epoch 20/50 Iteration: 353200 Avg. Training loss: 1.0082 0.0075 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 353400 Avg. Training loss: 1.1005 0.0071 sec/batch\n",
      "Epoch 20/50 Iteration: 353600 Avg. Training loss: 0.8993 0.0070 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 353800 Avg. Training loss: 1.0043 0.0068 sec/batch\n",
      "Epoch 20/50 Iteration: 354000 Avg. Training loss: 1.1419 0.0078 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 354200 Avg. Training loss: 1.2552 0.0080 sec/batch\n",
      "Epoch 20/50 Iteration: 354400 Avg. Training loss: 1.0621 0.0068 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 354600 Avg. Training loss: 1.0299 0.0070 sec/batch\n",
      "Epoch 20/50 Iteration: 354800 Avg. Training loss: 1.0295 0.0070 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 355000 Avg. Training loss: 1.1480 0.0070 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 Iteration: 355200 Avg. Training loss: 1.4900 0.0081 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 355400 Avg. Training loss: 0.8506 0.0070 sec/batch\n",
      "Epoch 20/50 Iteration: 355600 Avg. Training loss: 0.9314 0.0069 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 355800 Avg. Training loss: 1.2428 0.0071 sec/batch\n",
      "Epoch 20/50 Iteration: 356000 Avg. Training loss: 1.3209 0.0074 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 356200 Avg. Training loss: 1.1421 0.0073 sec/batch\n",
      "Epoch 20/50 Iteration: 356400 Avg. Training loss: 1.1509 0.0069 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 356600 Avg. Training loss: 0.9661 0.0068 sec/batch\n",
      "Epoch 20/50 Iteration: 356800 Avg. Training loss: 1.1377 0.0074 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 357000 Avg. Training loss: 1.0526 0.0073 sec/batch\n",
      "Epoch 20/50 Iteration: 357200 Avg. Training loss: 1.1789 0.0069 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 357400 Avg. Training loss: 0.8600 0.0070 sec/batch\n",
      "Epoch 20/50 Iteration: 357600 Avg. Training loss: 0.9605 0.0071 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 357800 Avg. Training loss: 1.0177 0.0069 sec/batch\n",
      "Epoch 20/50 Iteration: 358000 Avg. Training loss: 1.0458 0.0071 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 358200 Avg. Training loss: 1.0139 0.0071 sec/batch\n",
      "Epoch 20/50 Iteration: 358400 Avg. Training loss: 0.8286 0.0073 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 358600 Avg. Training loss: 1.1890 0.0082 sec/batch\n",
      "Epoch 20/50 Iteration: 358800 Avg. Training loss: 1.0346 0.0070 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 359000 Avg. Training loss: 1.0144 0.0085 sec/batch\n",
      "Epoch 20/50 Iteration: 359200 Avg. Training loss: 0.8908 0.0072 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 359400 Avg. Training loss: 1.2395 0.0073 sec/batch\n",
      "Epoch 20/50 Iteration: 359600 Avg. Training loss: 1.0293 0.0068 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 359800 Avg. Training loss: 1.2658 0.0073 sec/batch\n",
      "Epoch 20/50 Iteration: 360000 Avg. Training loss: 1.1839 0.0073 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 360200 Avg. Training loss: 1.2866 0.0072 sec/batch\n",
      "Epoch 20/50 Iteration: 360400 Avg. Training loss: 1.2442 0.0071 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 360600 Avg. Training loss: 1.1196 0.0069 sec/batch\n",
      "Epoch 20/50 Iteration: 360800 Avg. Training loss: 1.2361 0.0072 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 361000 Avg. Training loss: 1.1299 0.0070 sec/batch\n",
      "Epoch 20/50 Iteration: 361200 Avg. Training loss: 1.1848 0.0073 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 361400 Avg. Training loss: 1.0304 0.0069 sec/batch\n",
      "Epoch 20/50 Iteration: 361600 Avg. Training loss: 1.0899 0.0071 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 361800 Avg. Training loss: 1.3245 0.0075 sec/batch\n",
      "Epoch 20/50 Iteration: 362000 Avg. Training loss: 0.8192 0.0071 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 362200 Avg. Training loss: 0.9505 0.0072 sec/batch\n",
      "Epoch 20/50 Iteration: 362400 Avg. Training loss: 1.1321 0.0068 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 362600 Avg. Training loss: 1.1591 0.0074 sec/batch\n",
      "Epoch 20/50 Iteration: 362800 Avg. Training loss: 1.4794 0.0078 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 363000 Avg. Training loss: 1.2014 0.0070 sec/batch\n",
      "Epoch 20/50 Iteration: 363200 Avg. Training loss: 1.0553 0.0069 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 363400 Avg. Training loss: 1.1766 0.0072 sec/batch\n",
      "Epoch 20/50 Iteration: 363600 Avg. Training loss: 1.0878 0.0080 sec/batch\n",
      "error\n",
      "Epoch 20/50 Iteration: 363800 Avg. Training loss: 1.1337 0.0074 sec/batch\n",
      "Epoch 21/50 Iteration: 364000 Avg. Training loss: 1.1152 0.0023 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 364200 Avg. Training loss: 1.3168 0.0075 sec/batch\n",
      "Epoch 21/50 Iteration: 364400 Avg. Training loss: 1.0873 0.0076 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 364600 Avg. Training loss: 1.1783 0.0076 sec/batch\n",
      "Epoch 21/50 Iteration: 364800 Avg. Training loss: 1.3877 0.0082 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 365000 Avg. Training loss: 1.1964 0.0076 sec/batch\n",
      "Epoch 21/50 Iteration: 365200 Avg. Training loss: 1.1305 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 365400 Avg. Training loss: 1.1671 0.0075 sec/batch\n",
      "Epoch 21/50 Iteration: 365600 Avg. Training loss: 0.9999 0.0073 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 365800 Avg. Training loss: 1.0122 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 366000 Avg. Training loss: 1.1813 0.0069 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 366200 Avg. Training loss: 1.5136 0.0071 sec/batch\n",
      "Epoch 21/50 Iteration: 366400 Avg. Training loss: 1.0314 0.0075 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 366600 Avg. Training loss: 0.7285 0.0070 sec/batch\n",
      "Epoch 21/50 Iteration: 366800 Avg. Training loss: 1.2059 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 367000 Avg. Training loss: 1.0981 0.0071 sec/batch\n",
      "Epoch 21/50 Iteration: 367200 Avg. Training loss: 1.1061 0.0073 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 367400 Avg. Training loss: 1.2809 0.0078 sec/batch\n",
      "Epoch 21/50 Iteration: 367600 Avg. Training loss: 1.1831 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 367800 Avg. Training loss: 1.2557 0.0070 sec/batch\n",
      "Epoch 21/50 Iteration: 368000 Avg. Training loss: 1.1786 0.0073 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 368200 Avg. Training loss: 1.0266 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 368400 Avg. Training loss: 0.8603 0.0075 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 368600 Avg. Training loss: 0.7460 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 368800 Avg. Training loss: 0.8923 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 369000 Avg. Training loss: 1.2543 0.0074 sec/batch\n",
      "Epoch 21/50 Iteration: 369200 Avg. Training loss: 0.9626 0.0069 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 369400 Avg. Training loss: 1.4142 0.0078 sec/batch\n",
      "Epoch 21/50 Iteration: 369600 Avg. Training loss: 1.1902 0.0071 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 369800 Avg. Training loss: 1.2322 0.0076 sec/batch\n",
      "Epoch 21/50 Iteration: 370000 Avg. Training loss: 0.7674 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 370200 Avg. Training loss: 1.0940 0.0073 sec/batch\n",
      "Epoch 21/50 Iteration: 370400 Avg. Training loss: 1.1446 0.0071 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 370600 Avg. Training loss: 1.2565 0.0071 sec/batch\n",
      "Epoch 21/50 Iteration: 370800 Avg. Training loss: 1.0291 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 371000 Avg. Training loss: 1.0100 0.0072 sec/batch\n",
      "Epoch 21/50 Iteration: 371200 Avg. Training loss: 1.1599 0.0073 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 371400 Avg. Training loss: 0.7388 0.0077 sec/batch\n",
      "Epoch 21/50 Iteration: 371600 Avg. Training loss: 1.0245 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 371800 Avg. Training loss: 0.8749 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 372000 Avg. Training loss: 0.9683 0.0068 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 372200 Avg. Training loss: 1.1827 0.0079 sec/batch\n",
      "Epoch 21/50 Iteration: 372400 Avg. Training loss: 1.4511 0.0081 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 372600 Avg. Training loss: 1.1933 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 372800 Avg. Training loss: 1.2369 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 373000 Avg. Training loss: 1.1889 0.0071 sec/batch\n",
      "Epoch 21/50 Iteration: 373200 Avg. Training loss: 1.2689 0.0072 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 373400 Avg. Training loss: 1.2554 0.0081 sec/batch\n",
      "Epoch 21/50 Iteration: 373600 Avg. Training loss: 0.7709 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 373800 Avg. Training loss: 0.8656 0.0070 sec/batch\n",
      "Epoch 21/50 Iteration: 374000 Avg. Training loss: 1.0401 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 374200 Avg. Training loss: 1.2135 0.0075 sec/batch\n",
      "Epoch 21/50 Iteration: 374400 Avg. Training loss: 1.2137 0.0073 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 374600 Avg. Training loss: 0.9146 0.0069 sec/batch\n",
      "Epoch 21/50 Iteration: 374800 Avg. Training loss: 1.1199 0.0067 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 375000 Avg. Training loss: 0.9756 0.0075 sec/batch\n",
      "Epoch 21/50 Iteration: 375200 Avg. Training loss: 0.9716 0.0072 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 375400 Avg. Training loss: 0.9438 0.0070 sec/batch\n",
      "Epoch 21/50 Iteration: 375600 Avg. Training loss: 0.7524 0.0068 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 375800 Avg. Training loss: 1.0007 0.0071 sec/batch\n",
      "Epoch 21/50 Iteration: 376000 Avg. Training loss: 0.8343 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 376200 Avg. Training loss: 1.0375 0.0070 sec/batch\n",
      "Epoch 21/50 Iteration: 376400 Avg. Training loss: 1.1148 0.0071 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 Iteration: 376600 Avg. Training loss: 0.9132 0.0073 sec/batch\n",
      "Epoch 21/50 Iteration: 376800 Avg. Training loss: 1.3267 0.0081 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 377000 Avg. Training loss: 1.0822 0.0069 sec/batch\n",
      "Epoch 21/50 Iteration: 377200 Avg. Training loss: 0.9437 0.0085 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 377400 Avg. Training loss: 0.8238 0.0073 sec/batch\n",
      "Epoch 21/50 Iteration: 377600 Avg. Training loss: 1.1152 0.0071 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 377800 Avg. Training loss: 1.0800 0.0068 sec/batch\n",
      "Epoch 21/50 Iteration: 378000 Avg. Training loss: 1.0708 0.0073 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 378200 Avg. Training loss: 1.3974 0.0073 sec/batch\n",
      "Epoch 21/50 Iteration: 378400 Avg. Training loss: 1.1736 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 378600 Avg. Training loss: 0.9953 0.0070 sec/batch\n",
      "Epoch 21/50 Iteration: 378800 Avg. Training loss: 0.9114 0.0067 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 379000 Avg. Training loss: 1.2219 0.0071 sec/batch\n",
      "Epoch 21/50 Iteration: 379200 Avg. Training loss: 1.3074 0.0070 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 379400 Avg. Training loss: 1.1720 0.0073 sec/batch\n",
      "Epoch 21/50 Iteration: 379600 Avg. Training loss: 1.0691 0.0069 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 379800 Avg. Training loss: 1.1025 0.0070 sec/batch\n",
      "Epoch 21/50 Iteration: 380000 Avg. Training loss: 1.3832 0.0073 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 380200 Avg. Training loss: 0.9031 0.0069 sec/batch\n",
      "Epoch 21/50 Iteration: 380400 Avg. Training loss: 1.0189 0.0069 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 380600 Avg. Training loss: 0.9972 0.0066 sec/batch\n",
      "Epoch 21/50 Iteration: 380800 Avg. Training loss: 1.2844 0.0073 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 381000 Avg. Training loss: 1.5362 0.0076 sec/batch\n",
      "Epoch 21/50 Iteration: 381200 Avg. Training loss: 1.2807 0.0073 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 381400 Avg. Training loss: 0.9259 0.0074 sec/batch\n",
      "Epoch 21/50 Iteration: 381600 Avg. Training loss: 1.3124 0.0072 sec/batch\n",
      "error\n",
      "Epoch 21/50 Iteration: 381800 Avg. Training loss: 1.0343 0.0079 sec/batch\n",
      "Epoch 21/50 Iteration: 382000 Avg. Training loss: 1.2778 0.0074 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 382200 Avg. Training loss: 1.2494 0.0025 sec/batch\n",
      "Epoch 22/50 Iteration: 382400 Avg. Training loss: 1.1965 0.0077 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 382600 Avg. Training loss: 1.0290 0.0076 sec/batch\n",
      "Epoch 22/50 Iteration: 382800 Avg. Training loss: 1.1061 0.0072 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 383000 Avg. Training loss: 1.2923 0.0081 sec/batch\n",
      "Epoch 22/50 Iteration: 383200 Avg. Training loss: 1.2400 0.0076 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 383400 Avg. Training loss: 0.8869 0.0072 sec/batch\n",
      "Epoch 22/50 Iteration: 383600 Avg. Training loss: 0.9473 0.0077 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 383800 Avg. Training loss: 0.9060 0.0073 sec/batch\n",
      "Epoch 22/50 Iteration: 384000 Avg. Training loss: 1.0265 0.0068 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 384200 Avg. Training loss: 0.9007 0.0070 sec/batch\n",
      "Epoch 22/50 Iteration: 384400 Avg. Training loss: 1.2896 0.0072 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 384600 Avg. Training loss: 1.0531 0.0076 sec/batch\n",
      "Epoch 22/50 Iteration: 384800 Avg. Training loss: 0.9904 0.0072 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 385000 Avg. Training loss: 1.2169 0.0072 sec/batch\n",
      "Epoch 22/50 Iteration: 385200 Avg. Training loss: 1.0692 0.0072 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 385400 Avg. Training loss: 1.2804 0.0075 sec/batch\n",
      "Epoch 22/50 Iteration: 385600 Avg. Training loss: 1.0449 0.0078 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 385800 Avg. Training loss: 1.2170 0.0071 sec/batch\n",
      "Epoch 22/50 Iteration: 386000 Avg. Training loss: 1.2026 0.0071 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 386200 Avg. Training loss: 1.1744 0.0074 sec/batch\n",
      "Epoch 22/50 Iteration: 386400 Avg. Training loss: 0.9206 0.0068 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 386600 Avg. Training loss: 0.9644 0.0077 sec/batch\n",
      "Epoch 22/50 Iteration: 386800 Avg. Training loss: 0.7189 0.0071 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 387000 Avg. Training loss: 0.8276 0.0074 sec/batch\n",
      "Epoch 22/50 Iteration: 387200 Avg. Training loss: 1.0621 0.0077 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 387400 Avg. Training loss: 1.0946 0.0073 sec/batch\n",
      "Epoch 22/50 Iteration: 387600 Avg. Training loss: 1.5026 0.0081 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 387800 Avg. Training loss: 1.2256 0.0074 sec/batch\n",
      "Epoch 22/50 Iteration: 388000 Avg. Training loss: 1.3143 0.0077 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 388200 Avg. Training loss: 0.8298 0.0074 sec/batch\n",
      "Epoch 22/50 Iteration: 388400 Avg. Training loss: 1.0441 0.0077 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 388600 Avg. Training loss: 1.0530 0.0078 sec/batch\n",
      "Epoch 22/50 Iteration: 388800 Avg. Training loss: 1.2701 0.0077 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 389000 Avg. Training loss: 1.0354 0.0074 sec/batch\n",
      "Epoch 22/50 Iteration: 389200 Avg. Training loss: 1.0574 0.0076 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 389400 Avg. Training loss: 1.3021 0.0075 sec/batch\n",
      "Epoch 22/50 Iteration: 389600 Avg. Training loss: 0.8067 0.0079 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 389800 Avg. Training loss: 1.0732 0.0074 sec/batch\n",
      "Epoch 22/50 Iteration: 390000 Avg. Training loss: 0.8478 0.0071 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 390200 Avg. Training loss: 1.3095 0.0073 sec/batch\n",
      "Epoch 22/50 Iteration: 390400 Avg. Training loss: 1.1653 0.0083 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 390600 Avg. Training loss: 1.0560 0.0085 sec/batch\n",
      "Epoch 22/50 Iteration: 390800 Avg. Training loss: 0.9872 0.0071 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 391000 Avg. Training loss: 1.2092 0.0074 sec/batch\n",
      "Epoch 22/50 Iteration: 391200 Avg. Training loss: 1.1957 0.0074 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 391400 Avg. Training loss: 0.9153 0.0079 sec/batch\n",
      "Epoch 22/50 Iteration: 391600 Avg. Training loss: 1.3457 0.0087 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 391800 Avg. Training loss: 0.8925 0.0076 sec/batch\n",
      "Epoch 22/50 Iteration: 392000 Avg. Training loss: 0.9734 0.0078 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 392200 Avg. Training loss: 1.1749 0.0078 sec/batch\n",
      "Epoch 22/50 Iteration: 392400 Avg. Training loss: 1.3092 0.0082 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 392600 Avg. Training loss: 1.0494 0.0079 sec/batch\n",
      "Epoch 22/50 Iteration: 392800 Avg. Training loss: 1.0104 0.0077 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 393000 Avg. Training loss: 1.0683 0.0075 sec/batch\n",
      "Epoch 22/50 Iteration: 393200 Avg. Training loss: 1.0476 0.0080 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 393400 Avg. Training loss: 1.1246 0.0078 sec/batch\n",
      "Epoch 22/50 Iteration: 393600 Avg. Training loss: 1.2566 0.0076 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 393800 Avg. Training loss: 0.7936 0.0075 sec/batch\n",
      "Epoch 22/50 Iteration: 394000 Avg. Training loss: 0.9123 0.0078 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 394200 Avg. Training loss: 0.7103 0.0077 sec/batch\n",
      "Epoch 22/50 Iteration: 394400 Avg. Training loss: 0.8916 0.0078 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 394600 Avg. Training loss: 1.1569 0.0078 sec/batch\n",
      "Epoch 22/50 Iteration: 394800 Avg. Training loss: 0.7443 0.0079 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 395000 Avg. Training loss: 1.2725 0.0088 sec/batch\n",
      "Epoch 22/50 Iteration: 395200 Avg. Training loss: 1.0432 0.0076 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 395400 Avg. Training loss: 1.0881 0.0092 sec/batch\n",
      "Epoch 22/50 Iteration: 395600 Avg. Training loss: 0.8435 0.0079 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 395800 Avg. Training loss: 1.2532 0.0078 sec/batch\n",
      "Epoch 22/50 Iteration: 396000 Avg. Training loss: 1.1550 0.0075 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 396200 Avg. Training loss: 1.3043 0.0081 sec/batch\n",
      "Epoch 22/50 Iteration: 396400 Avg. Training loss: 1.3764 0.0079 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 396600 Avg. Training loss: 1.3720 0.0079 sec/batch\n",
      "Epoch 22/50 Iteration: 396800 Avg. Training loss: 1.0991 0.0079 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 397000 Avg. Training loss: 0.9538 0.0080 sec/batch\n",
      "Epoch 22/50 Iteration: 397200 Avg. Training loss: 1.1133 0.0080 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 397400 Avg. Training loss: 1.3131 0.0076 sec/batch\n",
      "Epoch 22/50 Iteration: 397600 Avg. Training loss: 1.1352 0.0079 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 397800 Avg. Training loss: 1.1179 0.0074 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 Iteration: 398000 Avg. Training loss: 1.1221 0.0076 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 398200 Avg. Training loss: 1.1162 0.0080 sec/batch\n",
      "Epoch 22/50 Iteration: 398400 Avg. Training loss: 0.6569 0.0075 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 398600 Avg. Training loss: 0.9441 0.0075 sec/batch\n",
      "Epoch 22/50 Iteration: 398800 Avg. Training loss: 0.8696 0.0074 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 399000 Avg. Training loss: 1.1860 0.0079 sec/batch\n",
      "Epoch 22/50 Iteration: 399200 Avg. Training loss: 1.2950 0.0082 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 399400 Avg. Training loss: 1.1490 0.0075 sec/batch\n",
      "Epoch 22/50 Iteration: 399600 Avg. Training loss: 0.8927 0.0074 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 399800 Avg. Training loss: 1.0113 0.0079 sec/batch\n",
      "Epoch 22/50 Iteration: 400000 Avg. Training loss: 1.0284 0.0086 sec/batch\n",
      "error\n",
      "Epoch 22/50 Iteration: 400200 Avg. Training loss: 0.9842 0.0080 sec/batch\n",
      "Epoch 23/50 Iteration: 400400 Avg. Training loss: 1.2917 0.0028 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 400600 Avg. Training loss: 1.2554 0.0081 sec/batch\n",
      "Epoch 23/50 Iteration: 400800 Avg. Training loss: 0.8800 0.0079 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 401000 Avg. Training loss: 1.1491 0.0076 sec/batch\n",
      "Epoch 23/50 Iteration: 401200 Avg. Training loss: 1.6762 0.0085 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 401400 Avg. Training loss: 1.1893 0.0080 sec/batch\n",
      "Epoch 23/50 Iteration: 401600 Avg. Training loss: 0.9710 0.0075 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 401800 Avg. Training loss: 1.1918 0.0081 sec/batch\n",
      "Epoch 23/50 Iteration: 402000 Avg. Training loss: 1.0379 0.0078 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 402200 Avg. Training loss: 1.0031 0.0074 sec/batch\n",
      "Epoch 23/50 Iteration: 402400 Avg. Training loss: 0.9889 0.0074 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 402600 Avg. Training loss: 1.1153 0.0077 sec/batch\n",
      "Epoch 23/50 Iteration: 402800 Avg. Training loss: 1.0007 0.0081 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 403000 Avg. Training loss: 0.7535 0.0077 sec/batch\n",
      "Epoch 23/50 Iteration: 403200 Avg. Training loss: 1.1948 0.0079 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 403400 Avg. Training loss: 1.0666 0.0079 sec/batch\n",
      "Epoch 23/50 Iteration: 403600 Avg. Training loss: 1.1777 0.0079 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 403800 Avg. Training loss: 1.1200 0.0085 sec/batch\n",
      "Epoch 23/50 Iteration: 404000 Avg. Training loss: 1.1313 0.0076 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 404200 Avg. Training loss: 1.1730 0.0078 sec/batch\n",
      "Epoch 23/50 Iteration: 404400 Avg. Training loss: 1.0899 0.0078 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 404600 Avg. Training loss: 0.9442 0.0077 sec/batch\n",
      "Epoch 23/50 Iteration: 404800 Avg. Training loss: 0.9088 0.0083 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 405000 Avg. Training loss: 0.8690 0.0077 sec/batch\n",
      "Epoch 23/50 Iteration: 405200 Avg. Training loss: 0.9274 0.0078 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 405400 Avg. Training loss: 1.0811 0.0080 sec/batch\n",
      "Epoch 23/50 Iteration: 405600 Avg. Training loss: 1.1262 0.0074 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 405800 Avg. Training loss: 1.3840 0.0084 sec/batch\n",
      "Epoch 23/50 Iteration: 406000 Avg. Training loss: 1.2622 0.0075 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 406200 Avg. Training loss: 1.2369 0.0080 sec/batch\n",
      "Epoch 23/50 Iteration: 406400 Avg. Training loss: 0.8611 0.0075 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 406600 Avg. Training loss: 1.1355 0.0076 sec/batch\n",
      "Epoch 23/50 Iteration: 406800 Avg. Training loss: 1.1309 0.0075 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 407000 Avg. Training loss: 1.0784 0.0074 sec/batch\n",
      "Epoch 23/50 Iteration: 407200 Avg. Training loss: 1.0017 0.0074 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 407400 Avg. Training loss: 1.2463 0.0077 sec/batch\n",
      "Epoch 23/50 Iteration: 407600 Avg. Training loss: 1.1343 0.0075 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 407800 Avg. Training loss: 0.8565 0.0081 sec/batch\n",
      "Epoch 23/50 Iteration: 408000 Avg. Training loss: 1.2783 0.0074 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 408200 Avg. Training loss: 0.8561 0.0074 sec/batch\n",
      "Epoch 23/50 Iteration: 408400 Avg. Training loss: 1.0791 0.0071 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 408600 Avg. Training loss: 1.2744 0.0087 sec/batch\n",
      "Epoch 23/50 Iteration: 408800 Avg. Training loss: 1.2005 0.0085 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 409000 Avg. Training loss: 1.2496 0.0072 sec/batch\n",
      "Epoch 23/50 Iteration: 409200 Avg. Training loss: 1.1934 0.0075 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 409400 Avg. Training loss: 1.2013 0.0076 sec/batch\n",
      "Epoch 23/50 Iteration: 409600 Avg. Training loss: 1.3993 0.0076 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 409800 Avg. Training loss: 1.5091 0.0085 sec/batch\n",
      "Epoch 23/50 Iteration: 410000 Avg. Training loss: 0.6465 0.0074 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 410200 Avg. Training loss: 0.9584 0.0074 sec/batch\n",
      "Epoch 23/50 Iteration: 410400 Avg. Training loss: 1.4287 0.0073 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 410600 Avg. Training loss: 1.1974 0.0077 sec/batch\n",
      "Epoch 23/50 Iteration: 410800 Avg. Training loss: 1.2927 0.0074 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 411000 Avg. Training loss: 1.1236 0.0071 sec/batch\n",
      "Epoch 23/50 Iteration: 411200 Avg. Training loss: 1.0976 0.0070 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 411400 Avg. Training loss: 1.4152 0.0075 sec/batch\n",
      "Epoch 23/50 Iteration: 411600 Avg. Training loss: 1.1592 0.0073 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 411800 Avg. Training loss: 1.2721 0.0071 sec/batch\n",
      "Epoch 23/50 Iteration: 412000 Avg. Training loss: 0.9401 0.0073 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 412200 Avg. Training loss: 0.9179 0.0075 sec/batch\n",
      "Epoch 23/50 Iteration: 412400 Avg. Training loss: 0.9546 0.0077 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 412600 Avg. Training loss: 1.0080 0.0081 sec/batch\n",
      "Epoch 23/50 Iteration: 412800 Avg. Training loss: 1.1761 0.0080 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 413000 Avg. Training loss: 0.9516 0.0079 sec/batch\n",
      "Epoch 23/50 Iteration: 413200 Avg. Training loss: 1.3346 0.0087 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 413400 Avg. Training loss: 1.2071 0.0076 sec/batch\n",
      "Epoch 23/50 Iteration: 413600 Avg. Training loss: 1.1243 0.0091 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 413800 Avg. Training loss: 0.9625 0.0077 sec/batch\n",
      "Epoch 23/50 Iteration: 414000 Avg. Training loss: 1.0262 0.0077 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 414200 Avg. Training loss: 1.2248 0.0073 sec/batch\n",
      "Epoch 23/50 Iteration: 414400 Avg. Training loss: 1.0004 0.0078 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 414600 Avg. Training loss: 1.3988 0.0079 sec/batch\n",
      "Epoch 23/50 Iteration: 414800 Avg. Training loss: 1.4484 0.0075 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 415000 Avg. Training loss: 0.9714 0.0074 sec/batch\n",
      "Epoch 23/50 Iteration: 415200 Avg. Training loss: 1.1602 0.0072 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 415400 Avg. Training loss: 1.1148 0.0077 sec/batch\n",
      "Epoch 23/50 Iteration: 415600 Avg. Training loss: 1.3776 0.0075 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 415800 Avg. Training loss: 1.2224 0.0078 sec/batch\n",
      "Epoch 23/50 Iteration: 416000 Avg. Training loss: 1.2186 0.0071 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 416200 Avg. Training loss: 0.9788 0.0076 sec/batch\n",
      "Epoch 23/50 Iteration: 416400 Avg. Training loss: 1.2707 0.0080 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 416600 Avg. Training loss: 0.8699 0.0075 sec/batch\n",
      "Epoch 23/50 Iteration: 416800 Avg. Training loss: 0.9220 0.0075 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 417000 Avg. Training loss: 0.8702 0.0073 sec/batch\n",
      "Epoch 23/50 Iteration: 417200 Avg. Training loss: 1.1742 0.0078 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 417400 Avg. Training loss: 1.4371 0.0080 sec/batch\n",
      "Epoch 23/50 Iteration: 417600 Avg. Training loss: 1.2876 0.0074 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 417800 Avg. Training loss: 0.8957 0.0075 sec/batch\n",
      "Epoch 23/50 Iteration: 418000 Avg. Training loss: 1.0731 0.0077 sec/batch\n",
      "error\n",
      "Epoch 23/50 Iteration: 418200 Avg. Training loss: 0.9181 0.0084 sec/batch\n",
      "Epoch 23/50 Iteration: 418400 Avg. Training loss: 0.9925 0.0077 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 418600 Avg. Training loss: 1.1925 0.0029 sec/batch\n",
      "Epoch 24/50 Iteration: 418800 Avg. Training loss: 1.4195 0.0081 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 419000 Avg. Training loss: 1.0940 0.0077 sec/batch\n",
      "Epoch 24/50 Iteration: 419200 Avg. Training loss: 1.1028 0.0073 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 Iteration: 419400 Avg. Training loss: 1.6482 0.0081 sec/batch\n",
      "Epoch 24/50 Iteration: 419600 Avg. Training loss: 1.1375 0.0077 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 419800 Avg. Training loss: 0.9830 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 420000 Avg. Training loss: 1.0753 0.0077 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 420200 Avg. Training loss: 0.8888 0.0076 sec/batch\n",
      "Epoch 24/50 Iteration: 420400 Avg. Training loss: 1.1117 0.0070 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 420600 Avg. Training loss: 0.9677 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 420800 Avg. Training loss: 1.3462 0.0073 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 421000 Avg. Training loss: 1.2506 0.0077 sec/batch\n",
      "Epoch 24/50 Iteration: 421200 Avg. Training loss: 0.8945 0.0072 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 421400 Avg. Training loss: 1.1738 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 421600 Avg. Training loss: 0.9161 0.0074 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 421800 Avg. Training loss: 1.2488 0.0076 sec/batch\n",
      "Epoch 24/50 Iteration: 422000 Avg. Training loss: 1.0517 0.0081 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 422200 Avg. Training loss: 1.2677 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 422400 Avg. Training loss: 1.2707 0.0072 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 422600 Avg. Training loss: 1.1924 0.0074 sec/batch\n",
      "Epoch 24/50 Iteration: 422800 Avg. Training loss: 0.8312 0.0071 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 423000 Avg. Training loss: 0.9686 0.0077 sec/batch\n",
      "Epoch 24/50 Iteration: 423200 Avg. Training loss: 0.7811 0.0071 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 423400 Avg. Training loss: 0.9386 0.0070 sec/batch\n",
      "Epoch 24/50 Iteration: 423600 Avg. Training loss: 1.1606 0.0076 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 423800 Avg. Training loss: 0.9011 0.0071 sec/batch\n",
      "Epoch 24/50 Iteration: 424000 Avg. Training loss: 1.5147 0.0080 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 424200 Avg. Training loss: 1.1886 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 424400 Avg. Training loss: 1.1188 0.0079 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 424600 Avg. Training loss: 0.9671 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 424800 Avg. Training loss: 0.9369 0.0074 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 425000 Avg. Training loss: 1.0520 0.0075 sec/batch\n",
      "Epoch 24/50 Iteration: 425200 Avg. Training loss: 1.1201 0.0074 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 425400 Avg. Training loss: 1.0556 0.0071 sec/batch\n",
      "Epoch 24/50 Iteration: 425600 Avg. Training loss: 1.1224 0.0075 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 425800 Avg. Training loss: 1.3725 0.0075 sec/batch\n",
      "Epoch 24/50 Iteration: 426000 Avg. Training loss: 0.8680 0.0077 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 426200 Avg. Training loss: 1.2691 0.0070 sec/batch\n",
      "Epoch 24/50 Iteration: 426400 Avg. Training loss: 0.7487 0.0070 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 426600 Avg. Training loss: 1.0998 0.0069 sec/batch\n",
      "Epoch 24/50 Iteration: 426800 Avg. Training loss: 1.0289 0.0081 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 427000 Avg. Training loss: 1.1688 0.0081 sec/batch\n",
      "Epoch 24/50 Iteration: 427200 Avg. Training loss: 1.3160 0.0071 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 427400 Avg. Training loss: 0.9888 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 427600 Avg. Training loss: 1.0575 0.0072 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 427800 Avg. Training loss: 1.2454 0.0075 sec/batch\n",
      "Epoch 24/50 Iteration: 428000 Avg. Training loss: 1.4171 0.0082 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 428200 Avg. Training loss: 0.7198 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 428400 Avg. Training loss: 1.1406 0.0078 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 428600 Avg. Training loss: 1.2025 0.0078 sec/batch\n",
      "Epoch 24/50 Iteration: 428800 Avg. Training loss: 1.3125 0.0076 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 429000 Avg. Training loss: 1.1410 0.0074 sec/batch\n",
      "Epoch 24/50 Iteration: 429200 Avg. Training loss: 0.9771 0.0071 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 429400 Avg. Training loss: 1.0639 0.0071 sec/batch\n",
      "Epoch 24/50 Iteration: 429600 Avg. Training loss: 1.1982 0.0077 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 429800 Avg. Training loss: 1.0181 0.0075 sec/batch\n",
      "Epoch 24/50 Iteration: 430000 Avg. Training loss: 1.0643 0.0071 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 430200 Avg. Training loss: 0.7824 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 430400 Avg. Training loss: 1.0131 0.0074 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 430600 Avg. Training loss: 0.8922 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 430800 Avg. Training loss: 1.0973 0.0074 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 431000 Avg. Training loss: 1.2431 0.0072 sec/batch\n",
      "Epoch 24/50 Iteration: 431200 Avg. Training loss: 0.8666 0.0075 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 431400 Avg. Training loss: 1.6581 0.0085 sec/batch\n",
      "Epoch 24/50 Iteration: 431600 Avg. Training loss: 1.1701 0.0071 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 431800 Avg. Training loss: 1.0373 0.0089 sec/batch\n",
      "Epoch 24/50 Iteration: 432000 Avg. Training loss: 0.7683 0.0074 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 432200 Avg. Training loss: 1.3214 0.0074 sec/batch\n",
      "Epoch 24/50 Iteration: 432400 Avg. Training loss: 1.0997 0.0070 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 432600 Avg. Training loss: 1.0219 0.0076 sec/batch\n",
      "Epoch 24/50 Iteration: 432800 Avg. Training loss: 1.1407 0.0075 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 433000 Avg. Training loss: 1.2635 0.0074 sec/batch\n",
      "Epoch 24/50 Iteration: 433200 Avg. Training loss: 0.9977 0.0073 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 433400 Avg. Training loss: 1.0693 0.0071 sec/batch\n",
      "Epoch 24/50 Iteration: 433600 Avg. Training loss: 1.2161 0.0073 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 433800 Avg. Training loss: 1.2755 0.0074 sec/batch\n",
      "Epoch 24/50 Iteration: 434000 Avg. Training loss: 1.1405 0.0077 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 434200 Avg. Training loss: 0.8954 0.0070 sec/batch\n",
      "Epoch 24/50 Iteration: 434400 Avg. Training loss: 1.0930 0.0074 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 434600 Avg. Training loss: 1.5075 0.0076 sec/batch\n",
      "Epoch 24/50 Iteration: 434800 Avg. Training loss: 0.8901 0.0072 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 435000 Avg. Training loss: 1.0070 0.0073 sec/batch\n",
      "Epoch 24/50 Iteration: 435200 Avg. Training loss: 0.9552 0.0070 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 435400 Avg. Training loss: 1.2287 0.0077 sec/batch\n",
      "Epoch 24/50 Iteration: 435600 Avg. Training loss: 1.6674 0.0079 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 435800 Avg. Training loss: 1.1686 0.0071 sec/batch\n",
      "Epoch 24/50 Iteration: 436000 Avg. Training loss: 0.9054 0.0071 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 436200 Avg. Training loss: 1.0845 0.0074 sec/batch\n",
      "Epoch 24/50 Iteration: 436400 Avg. Training loss: 1.0242 0.0082 sec/batch\n",
      "error\n",
      "Epoch 24/50 Iteration: 436600 Avg. Training loss: 0.9878 0.0076 sec/batch\n",
      "Epoch 25/50 Iteration: 436800 Avg. Training loss: 1.2645 0.0029 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 437000 Avg. Training loss: 1.1907 0.0078 sec/batch\n",
      "Epoch 25/50 Iteration: 437200 Avg. Training loss: 0.9513 0.0076 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 437400 Avg. Training loss: 1.1518 0.0073 sec/batch\n",
      "Epoch 25/50 Iteration: 437600 Avg. Training loss: 1.4844 0.0083 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 437800 Avg. Training loss: 1.1681 0.0077 sec/batch\n",
      "Epoch 25/50 Iteration: 438000 Avg. Training loss: 0.9747 0.0074 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 438200 Avg. Training loss: 1.1546 0.0078 sec/batch\n",
      "Epoch 25/50 Iteration: 438400 Avg. Training loss: 0.9583 0.0076 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 438600 Avg. Training loss: 1.1262 0.0071 sec/batch\n",
      "Epoch 25/50 Iteration: 438800 Avg. Training loss: 1.1167 0.0073 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 439000 Avg. Training loss: 1.2979 0.0072 sec/batch\n",
      "Epoch 25/50 Iteration: 439200 Avg. Training loss: 1.1377 0.0078 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 439400 Avg. Training loss: 0.7737 0.0074 sec/batch\n",
      "Epoch 25/50 Iteration: 439600 Avg. Training loss: 1.1891 0.0072 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 439800 Avg. Training loss: 1.1817 0.0074 sec/batch\n",
      "Epoch 25/50 Iteration: 440000 Avg. Training loss: 0.9180 0.0076 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 440200 Avg. Training loss: 1.1119 0.0083 sec/batch\n",
      "Epoch 25/50 Iteration: 440400 Avg. Training loss: 1.1804 0.0078 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 440600 Avg. Training loss: 1.2994 0.0081 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 Iteration: 440800 Avg. Training loss: 1.1125 0.0079 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 441000 Avg. Training loss: 0.9569 0.0071 sec/batch\n",
      "Epoch 25/50 Iteration: 441200 Avg. Training loss: 0.9645 0.0076 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 441400 Avg. Training loss: 0.8152 0.0070 sec/batch\n",
      "Epoch 25/50 Iteration: 441600 Avg. Training loss: 0.9396 0.0072 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 441800 Avg. Training loss: 1.1497 0.0078 sec/batch\n",
      "Epoch 25/50 Iteration: 442000 Avg. Training loss: 0.9459 0.0074 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 442200 Avg. Training loss: 1.6377 0.0083 sec/batch\n",
      "Epoch 25/50 Iteration: 442400 Avg. Training loss: 1.1359 0.0073 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 442600 Avg. Training loss: 1.3050 0.0078 sec/batch\n",
      "Epoch 25/50 Iteration: 442800 Avg. Training loss: 0.9064 0.0073 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 443000 Avg. Training loss: 0.9422 0.0076 sec/batch\n",
      "Epoch 25/50 Iteration: 443200 Avg. Training loss: 0.9614 0.0074 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 443400 Avg. Training loss: 1.0955 0.0073 sec/batch\n",
      "Epoch 25/50 Iteration: 443600 Avg. Training loss: 0.9847 0.0073 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 443800 Avg. Training loss: 1.3531 0.0074 sec/batch\n",
      "Epoch 25/50 Iteration: 444000 Avg. Training loss: 1.4205 0.0072 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 444200 Avg. Training loss: 0.9667 0.0075 sec/batch\n",
      "Epoch 25/50 Iteration: 444400 Avg. Training loss: 1.0395 0.0076 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 444600 Avg. Training loss: 0.7881 0.0074 sec/batch\n",
      "Epoch 25/50 Iteration: 444800 Avg. Training loss: 1.1687 0.0070 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 445000 Avg. Training loss: 1.1055 0.0081 sec/batch\n",
      "Epoch 25/50 Iteration: 445200 Avg. Training loss: 1.2324 0.0080 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 445400 Avg. Training loss: 1.1968 0.0069 sec/batch\n",
      "Epoch 25/50 Iteration: 445600 Avg. Training loss: 1.2355 0.0071 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 445800 Avg. Training loss: 1.1064 0.0072 sec/batch\n",
      "Epoch 25/50 Iteration: 446000 Avg. Training loss: 1.1998 0.0075 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 446200 Avg. Training loss: 1.5090 0.0080 sec/batch\n",
      "Epoch 25/50 Iteration: 446400 Avg. Training loss: 0.7320 0.0072 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 446600 Avg. Training loss: 0.8928 0.0072 sec/batch\n",
      "Epoch 25/50 Iteration: 446800 Avg. Training loss: 1.3128 0.0072 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 447000 Avg. Training loss: 1.1645 0.0076 sec/batch\n",
      "Epoch 25/50 Iteration: 447200 Avg. Training loss: 1.1707 0.0075 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 447400 Avg. Training loss: 1.0601 0.0070 sec/batch\n",
      "Epoch 25/50 Iteration: 447600 Avg. Training loss: 1.1112 0.0070 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 447800 Avg. Training loss: 1.0221 0.0075 sec/batch\n",
      "Epoch 25/50 Iteration: 448000 Avg. Training loss: 1.1059 0.0073 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 448200 Avg. Training loss: 1.2326 0.0071 sec/batch\n",
      "Epoch 25/50 Iteration: 448400 Avg. Training loss: 0.8742 0.0069 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 448600 Avg. Training loss: 0.9346 0.0072 sec/batch\n",
      "Epoch 25/50 Iteration: 448800 Avg. Training loss: 0.8002 0.0071 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 449000 Avg. Training loss: 1.0951 0.0072 sec/batch\n",
      "Epoch 25/50 Iteration: 449200 Avg. Training loss: 1.2980 0.0074 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 449400 Avg. Training loss: 0.9387 0.0073 sec/batch\n",
      "Epoch 25/50 Iteration: 449600 Avg. Training loss: 1.4150 0.0083 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 449800 Avg. Training loss: 0.9929 0.0072 sec/batch\n",
      "Epoch 25/50 Iteration: 450000 Avg. Training loss: 1.1865 0.0088 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 450200 Avg. Training loss: 0.6890 0.0074 sec/batch\n",
      "Epoch 25/50 Iteration: 450400 Avg. Training loss: 1.3406 0.0074 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 450600 Avg. Training loss: 1.3326 0.0071 sec/batch\n",
      "Epoch 25/50 Iteration: 450800 Avg. Training loss: 1.0648 0.0076 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 451000 Avg. Training loss: 1.1527 0.0077 sec/batch\n",
      "Epoch 25/50 Iteration: 451200 Avg. Training loss: 1.4010 0.0074 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 451400 Avg. Training loss: 0.9437 0.0076 sec/batch\n",
      "Epoch 25/50 Iteration: 451600 Avg. Training loss: 1.0886 0.0071 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 451800 Avg. Training loss: 1.2094 0.0074 sec/batch\n",
      "Epoch 25/50 Iteration: 452000 Avg. Training loss: 1.2107 0.0073 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 452200 Avg. Training loss: 1.2124 0.0077 sec/batch\n",
      "Epoch 25/50 Iteration: 452400 Avg. Training loss: 0.9505 0.0069 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 452600 Avg. Training loss: 1.1584 0.0074 sec/batch\n",
      "Epoch 25/50 Iteration: 452800 Avg. Training loss: 1.3763 0.0076 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 453000 Avg. Training loss: 0.7346 0.0075 sec/batch\n",
      "Epoch 25/50 Iteration: 453200 Avg. Training loss: 0.8812 0.0073 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 453400 Avg. Training loss: 0.8086 0.0072 sec/batch\n",
      "Epoch 25/50 Iteration: 453600 Avg. Training loss: 1.3800 0.0080 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 453800 Avg. Training loss: 1.5091 0.0078 sec/batch\n",
      "Epoch 25/50 Iteration: 454000 Avg. Training loss: 1.0658 0.0071 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 454200 Avg. Training loss: 0.9338 0.0072 sec/batch\n",
      "Epoch 25/50 Iteration: 454400 Avg. Training loss: 1.1356 0.0074 sec/batch\n",
      "error\n",
      "Epoch 25/50 Iteration: 454600 Avg. Training loss: 0.9949 0.0081 sec/batch\n",
      "Epoch 25/50 Iteration: 454800 Avg. Training loss: 1.2535 0.0074 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 455000 Avg. Training loss: 1.2563 0.0030 sec/batch\n",
      "Epoch 26/50 Iteration: 455200 Avg. Training loss: 1.2125 0.0078 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 455400 Avg. Training loss: 0.9970 0.0077 sec/batch\n",
      "Epoch 26/50 Iteration: 455600 Avg. Training loss: 1.1768 0.0072 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 455800 Avg. Training loss: 1.6511 0.0082 sec/batch\n",
      "Epoch 26/50 Iteration: 456000 Avg. Training loss: 1.3082 0.0077 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 456200 Avg. Training loss: 1.1040 0.0073 sec/batch\n",
      "Epoch 26/50 Iteration: 456400 Avg. Training loss: 1.3354 0.0077 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 456600 Avg. Training loss: 0.9073 0.0076 sec/batch\n",
      "Epoch 26/50 Iteration: 456800 Avg. Training loss: 0.9673 0.0069 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 457000 Avg. Training loss: 1.0322 0.0070 sec/batch\n",
      "Epoch 26/50 Iteration: 457200 Avg. Training loss: 1.1927 0.0074 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 457400 Avg. Training loss: 1.0937 0.0077 sec/batch\n",
      "Epoch 26/50 Iteration: 457600 Avg. Training loss: 0.7321 0.0071 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 457800 Avg. Training loss: 1.0068 0.0072 sec/batch\n",
      "Epoch 26/50 Iteration: 458000 Avg. Training loss: 1.0038 0.0072 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 458200 Avg. Training loss: 1.2663 0.0076 sec/batch\n",
      "Epoch 26/50 Iteration: 458400 Avg. Training loss: 1.0596 0.0080 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 458600 Avg. Training loss: 0.9174 0.0072 sec/batch\n",
      "Epoch 26/50 Iteration: 458800 Avg. Training loss: 1.4587 0.0072 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 459000 Avg. Training loss: 1.2448 0.0074 sec/batch\n",
      "Epoch 26/50 Iteration: 459200 Avg. Training loss: 0.8267 0.0070 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 459400 Avg. Training loss: 0.9662 0.0079 sec/batch\n",
      "Epoch 26/50 Iteration: 459600 Avg. Training loss: 0.7463 0.0071 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 459800 Avg. Training loss: 1.0352 0.0072 sec/batch\n",
      "Epoch 26/50 Iteration: 460000 Avg. Training loss: 0.9881 0.0075 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 460200 Avg. Training loss: 0.8954 0.0071 sec/batch\n",
      "Epoch 26/50 Iteration: 460400 Avg. Training loss: 1.3330 0.0082 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 460600 Avg. Training loss: 1.0829 0.0077 sec/batch\n",
      "Epoch 26/50 Iteration: 460800 Avg. Training loss: 1.2719 0.0081 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 461000 Avg. Training loss: 0.9296 0.0073 sec/batch\n",
      "Epoch 26/50 Iteration: 461200 Avg. Training loss: 1.2449 0.0075 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 461400 Avg. Training loss: 0.9766 0.0073 sec/batch\n",
      "Epoch 26/50 Iteration: 461600 Avg. Training loss: 1.0684 0.0072 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 461800 Avg. Training loss: 0.9587 0.0073 sec/batch\n",
      "Epoch 26/50 Iteration: 462000 Avg. Training loss: 1.3536 0.0075 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 Iteration: 462200 Avg. Training loss: 1.3446 0.0075 sec/batch\n",
      "Epoch 26/50 Iteration: 462400 Avg. Training loss: 0.8787 0.0076 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 462600 Avg. Training loss: 1.2777 0.0071 sec/batch\n",
      "Epoch 26/50 Iteration: 462800 Avg. Training loss: 0.7436 0.0071 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 463000 Avg. Training loss: 0.9890 0.0073 sec/batch\n",
      "Epoch 26/50 Iteration: 463200 Avg. Training loss: 1.3721 0.0085 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 463400 Avg. Training loss: 1.5022 0.0079 sec/batch\n",
      "Epoch 26/50 Iteration: 463600 Avg. Training loss: 1.0950 0.0070 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 463800 Avg. Training loss: 1.0854 0.0072 sec/batch\n",
      "Epoch 26/50 Iteration: 464000 Avg. Training loss: 1.2072 0.0073 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 464200 Avg. Training loss: 1.2701 0.0075 sec/batch\n",
      "Epoch 26/50 Iteration: 464400 Avg. Training loss: 1.5317 0.0081 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 464600 Avg. Training loss: 0.8203 0.0072 sec/batch\n",
      "Epoch 26/50 Iteration: 464800 Avg. Training loss: 0.9355 0.0072 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 465000 Avg. Training loss: 1.2107 0.0074 sec/batch\n",
      "Epoch 26/50 Iteration: 465200 Avg. Training loss: 1.0906 0.0076 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 465400 Avg. Training loss: 1.2130 0.0075 sec/batch\n",
      "Epoch 26/50 Iteration: 465600 Avg. Training loss: 0.9746 0.0072 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 465800 Avg. Training loss: 1.0111 0.0069 sec/batch\n",
      "Epoch 26/50 Iteration: 466000 Avg. Training loss: 0.9673 0.0077 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 466200 Avg. Training loss: 0.9746 0.0076 sec/batch\n",
      "Epoch 26/50 Iteration: 466400 Avg. Training loss: 1.1107 0.0072 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 466600 Avg. Training loss: 0.7729 0.0071 sec/batch\n",
      "Epoch 26/50 Iteration: 466800 Avg. Training loss: 0.7993 0.0072 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 467000 Avg. Training loss: 0.8213 0.0071 sec/batch\n",
      "Epoch 26/50 Iteration: 467200 Avg. Training loss: 1.2883 0.0072 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 467400 Avg. Training loss: 1.0667 0.0073 sec/batch\n",
      "Epoch 26/50 Iteration: 467600 Avg. Training loss: 0.9109 0.0073 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 467800 Avg. Training loss: 1.3666 0.0083 sec/batch\n",
      "Epoch 26/50 Iteration: 468000 Avg. Training loss: 1.1392 0.0072 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 468200 Avg. Training loss: 0.9067 0.0087 sec/batch\n",
      "Epoch 26/50 Iteration: 468400 Avg. Training loss: 0.8013 0.0074 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 468600 Avg. Training loss: 1.0594 0.0073 sec/batch\n",
      "Epoch 26/50 Iteration: 468800 Avg. Training loss: 0.8507 0.0070 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 469000 Avg. Training loss: 1.1720 0.0075 sec/batch\n",
      "Epoch 26/50 Iteration: 469200 Avg. Training loss: 1.5454 0.0074 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 469400 Avg. Training loss: 1.4155 0.0075 sec/batch\n",
      "Epoch 26/50 Iteration: 469600 Avg. Training loss: 0.9815 0.0071 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 469800 Avg. Training loss: 1.2744 0.0072 sec/batch\n",
      "Epoch 26/50 Iteration: 470000 Avg. Training loss: 1.1074 0.0073 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 470200 Avg. Training loss: 1.1896 0.0072 sec/batch\n",
      "Epoch 26/50 Iteration: 470400 Avg. Training loss: 1.2615 0.0076 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 470600 Avg. Training loss: 0.9506 0.0070 sec/batch\n",
      "Epoch 26/50 Iteration: 470800 Avg. Training loss: 1.2364 0.0074 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 471000 Avg. Training loss: 1.2197 0.0075 sec/batch\n",
      "Epoch 26/50 Iteration: 471200 Avg. Training loss: 0.9673 0.0072 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 471400 Avg. Training loss: 0.9486 0.0072 sec/batch\n",
      "Epoch 26/50 Iteration: 471600 Avg. Training loss: 0.8577 0.0069 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 471800 Avg. Training loss: 1.3900 0.0078 sec/batch\n",
      "Epoch 26/50 Iteration: 472000 Avg. Training loss: 1.4085 0.0079 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 472200 Avg. Training loss: 1.2049 0.0073 sec/batch\n",
      "Epoch 26/50 Iteration: 472400 Avg. Training loss: 0.9429 0.0073 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 472600 Avg. Training loss: 1.1013 0.0074 sec/batch\n",
      "Epoch 26/50 Iteration: 472800 Avg. Training loss: 1.0605 0.0081 sec/batch\n",
      "error\n",
      "Epoch 26/50 Iteration: 473000 Avg. Training loss: 1.0282 0.0074 sec/batch\n",
      "Epoch 27/50 Iteration: 473200 Avg. Training loss: 1.2658 0.0031 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 473400 Avg. Training loss: 1.4357 0.0078 sec/batch\n",
      "Epoch 27/50 Iteration: 473600 Avg. Training loss: 1.0340 0.0075 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 473800 Avg. Training loss: 1.1248 0.0073 sec/batch\n",
      "Epoch 27/50 Iteration: 474000 Avg. Training loss: 1.6352 0.0081 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 474200 Avg. Training loss: 1.2328 0.0077 sec/batch\n",
      "Epoch 27/50 Iteration: 474400 Avg. Training loss: 1.0637 0.0072 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 474600 Avg. Training loss: 1.1526 0.0077 sec/batch\n",
      "Epoch 27/50 Iteration: 474800 Avg. Training loss: 1.0026 0.0075 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 475000 Avg. Training loss: 1.1726 0.0072 sec/batch\n",
      "Epoch 27/50 Iteration: 475200 Avg. Training loss: 1.2793 0.0072 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 475400 Avg. Training loss: 1.4197 0.0073 sec/batch\n",
      "Epoch 27/50 Iteration: 475600 Avg. Training loss: 0.9625 0.0078 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 475800 Avg. Training loss: 0.7748 0.0072 sec/batch\n",
      "Epoch 27/50 Iteration: 476000 Avg. Training loss: 1.2049 0.0073 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 476200 Avg. Training loss: 1.1360 0.0072 sec/batch\n",
      "Epoch 27/50 Iteration: 476400 Avg. Training loss: 1.4524 0.0075 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 476600 Avg. Training loss: 1.2089 0.0084 sec/batch\n",
      "Epoch 27/50 Iteration: 476800 Avg. Training loss: 1.1679 0.0077 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 477000 Avg. Training loss: 0.9981 0.0074 sec/batch\n",
      "Epoch 27/50 Iteration: 477200 Avg. Training loss: 1.1556 0.0072 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 477400 Avg. Training loss: 0.7529 0.0071 sec/batch\n",
      "Epoch 27/50 Iteration: 477600 Avg. Training loss: 1.1302 0.0077 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 477800 Avg. Training loss: 0.8257 0.0072 sec/batch\n",
      "Epoch 27/50 Iteration: 478000 Avg. Training loss: 0.8749 0.0071 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 478200 Avg. Training loss: 1.1125 0.0075 sec/batch\n",
      "Epoch 27/50 Iteration: 478400 Avg. Training loss: 0.9518 0.0071 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 478600 Avg. Training loss: 1.3730 0.0080 sec/batch\n",
      "Epoch 27/50 Iteration: 478800 Avg. Training loss: 1.0126 0.0072 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 479000 Avg. Training loss: 1.1897 0.0078 sec/batch\n",
      "Epoch 27/50 Iteration: 479200 Avg. Training loss: 1.0028 0.0072 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 479400 Avg. Training loss: 1.2105 0.0074 sec/batch\n",
      "Epoch 27/50 Iteration: 479600 Avg. Training loss: 1.0198 0.0073 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 479800 Avg. Training loss: 1.2418 0.0071 sec/batch\n",
      "Epoch 27/50 Iteration: 480000 Avg. Training loss: 1.2473 0.0072 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 480200 Avg. Training loss: 1.2157 0.0074 sec/batch\n",
      "Epoch 27/50 Iteration: 480400 Avg. Training loss: 1.1664 0.0074 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 480600 Avg. Training loss: 1.0570 0.0077 sec/batch\n",
      "Epoch 27/50 Iteration: 480800 Avg. Training loss: 1.2638 0.0071 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 481000 Avg. Training loss: 0.8590 0.0071 sec/batch\n",
      "Epoch 27/50 Iteration: 481200 Avg. Training loss: 1.1918 0.0071 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 481400 Avg. Training loss: 1.5622 0.0085 sec/batch\n",
      "Epoch 27/50 Iteration: 481600 Avg. Training loss: 1.1988 0.0082 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 481800 Avg. Training loss: 1.0337 0.0070 sec/batch\n",
      "Epoch 27/50 Iteration: 482000 Avg. Training loss: 1.1827 0.0072 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 482200 Avg. Training loss: 1.0551 0.0072 sec/batch\n",
      "Epoch 27/50 Iteration: 482400 Avg. Training loss: 1.2238 0.0077 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 482600 Avg. Training loss: 1.3140 0.0083 sec/batch\n",
      "Epoch 27/50 Iteration: 482800 Avg. Training loss: 0.6480 0.0072 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 483000 Avg. Training loss: 1.0145 0.0073 sec/batch\n",
      "Epoch 27/50 Iteration: 483200 Avg. Training loss: 1.3553 0.0075 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 483400 Avg. Training loss: 1.2052 0.0077 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 Iteration: 483600 Avg. Training loss: 1.1891 0.0074 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 483800 Avg. Training loss: 0.9562 0.0069 sec/batch\n",
      "Epoch 27/50 Iteration: 484000 Avg. Training loss: 0.9953 0.0068 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 484200 Avg. Training loss: 0.9978 0.0075 sec/batch\n",
      "Epoch 27/50 Iteration: 484400 Avg. Training loss: 1.0092 0.0072 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 484600 Avg. Training loss: 1.1468 0.0070 sec/batch\n",
      "Epoch 27/50 Iteration: 484800 Avg. Training loss: 0.7704 0.0067 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 485000 Avg. Training loss: 1.0442 0.0070 sec/batch\n",
      "Epoch 27/50 Iteration: 485200 Avg. Training loss: 0.7455 0.0071 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 485400 Avg. Training loss: 1.1230 0.0073 sec/batch\n",
      "Epoch 27/50 Iteration: 485600 Avg. Training loss: 1.1108 0.0071 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 485800 Avg. Training loss: 0.9072 0.0073 sec/batch\n",
      "Epoch 27/50 Iteration: 486000 Avg. Training loss: 1.3579 0.0082 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 486200 Avg. Training loss: 1.0125 0.0070 sec/batch\n",
      "Epoch 27/50 Iteration: 486400 Avg. Training loss: 0.9506 0.0086 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 486600 Avg. Training loss: 0.8288 0.0072 sec/batch\n",
      "Epoch 27/50 Iteration: 486800 Avg. Training loss: 1.1251 0.0074 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 487000 Avg. Training loss: 1.0370 0.0071 sec/batch\n",
      "Epoch 27/50 Iteration: 487200 Avg. Training loss: 1.3162 0.0076 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 487400 Avg. Training loss: 1.3769 0.0074 sec/batch\n",
      "Epoch 27/50 Iteration: 487600 Avg. Training loss: 1.0904 0.0073 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 487800 Avg. Training loss: 0.9504 0.0071 sec/batch\n",
      "Epoch 27/50 Iteration: 488000 Avg. Training loss: 1.1262 0.0069 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 488200 Avg. Training loss: 1.2838 0.0074 sec/batch\n",
      "Epoch 27/50 Iteration: 488400 Avg. Training loss: 1.0960 0.0070 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 488600 Avg. Training loss: 1.4204 0.0076 sec/batch\n",
      "Epoch 27/50 Iteration: 488800 Avg. Training loss: 0.9790 0.0068 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 489000 Avg. Training loss: 1.1104 0.0072 sec/batch\n",
      "Epoch 27/50 Iteration: 489200 Avg. Training loss: 1.3825 0.0073 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 489400 Avg. Training loss: 0.9135 0.0071 sec/batch\n",
      "Epoch 27/50 Iteration: 489600 Avg. Training loss: 0.9920 0.0071 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 489800 Avg. Training loss: 0.9737 0.0068 sec/batch\n",
      "Epoch 27/50 Iteration: 490000 Avg. Training loss: 1.5377 0.0076 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 490200 Avg. Training loss: 1.5628 0.0077 sec/batch\n",
      "Epoch 27/50 Iteration: 490400 Avg. Training loss: 1.1964 0.0070 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 490600 Avg. Training loss: 1.1493 0.0070 sec/batch\n",
      "Epoch 27/50 Iteration: 490800 Avg. Training loss: 0.9360 0.0072 sec/batch\n",
      "error\n",
      "Epoch 27/50 Iteration: 491000 Avg. Training loss: 0.9689 0.0080 sec/batch\n",
      "Epoch 27/50 Iteration: 491200 Avg. Training loss: 1.1032 0.0073 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 491400 Avg. Training loss: 1.3369 0.0032 sec/batch\n",
      "Epoch 28/50 Iteration: 491600 Avg. Training loss: 1.2740 0.0077 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 491800 Avg. Training loss: 1.0581 0.0074 sec/batch\n",
      "Epoch 28/50 Iteration: 492000 Avg. Training loss: 1.0578 0.0071 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 492200 Avg. Training loss: 1.3994 0.0080 sec/batch\n",
      "Epoch 28/50 Iteration: 492400 Avg. Training loss: 1.1459 0.0075 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 492600 Avg. Training loss: 0.9688 0.0071 sec/batch\n",
      "Epoch 28/50 Iteration: 492800 Avg. Training loss: 1.1011 0.0075 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 493000 Avg. Training loss: 0.9948 0.0079 sec/batch\n",
      "Epoch 28/50 Iteration: 493200 Avg. Training loss: 1.1325 0.0072 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 493400 Avg. Training loss: 1.1649 0.0070 sec/batch\n",
      "Epoch 28/50 Iteration: 493600 Avg. Training loss: 1.1588 0.0071 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 493800 Avg. Training loss: 1.2024 0.0076 sec/batch\n",
      "Epoch 28/50 Iteration: 494000 Avg. Training loss: 0.7448 0.0070 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 494200 Avg. Training loss: 1.2791 0.0071 sec/batch\n",
      "Epoch 28/50 Iteration: 494400 Avg. Training loss: 1.1478 0.0070 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 494600 Avg. Training loss: 1.3138 0.0074 sec/batch\n",
      "Epoch 28/50 Iteration: 494800 Avg. Training loss: 1.0999 0.0078 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 495000 Avg. Training loss: 1.4508 0.0070 sec/batch\n",
      "Epoch 28/50 Iteration: 495200 Avg. Training loss: 1.3084 0.0070 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 495400 Avg. Training loss: 0.9792 0.0072 sec/batch\n",
      "Epoch 28/50 Iteration: 495600 Avg. Training loss: 0.9450 0.0069 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 495800 Avg. Training loss: 1.1267 0.0076 sec/batch\n",
      "Epoch 28/50 Iteration: 496000 Avg. Training loss: 0.7618 0.0067 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 496200 Avg. Training loss: 1.0060 0.0070 sec/batch\n",
      "Epoch 28/50 Iteration: 496400 Avg. Training loss: 1.0941 0.0073 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 496600 Avg. Training loss: 0.9380 0.0070 sec/batch\n",
      "Epoch 28/50 Iteration: 496800 Avg. Training loss: 1.4656 0.0078 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 497000 Avg. Training loss: 1.1641 0.0069 sec/batch\n",
      "Epoch 28/50 Iteration: 497200 Avg. Training loss: 1.0920 0.0076 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 497400 Avg. Training loss: 1.0069 0.0069 sec/batch\n",
      "Epoch 28/50 Iteration: 497600 Avg. Training loss: 1.1127 0.0071 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 497800 Avg. Training loss: 0.9937 0.0072 sec/batch\n",
      "Epoch 28/50 Iteration: 498000 Avg. Training loss: 1.1219 0.0069 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 498200 Avg. Training loss: 1.1017 0.0070 sec/batch\n",
      "Epoch 28/50 Iteration: 498400 Avg. Training loss: 1.3102 0.0072 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 498600 Avg. Training loss: 1.3019 0.0071 sec/batch\n",
      "Epoch 28/50 Iteration: 498800 Avg. Training loss: 0.9602 0.0074 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 499000 Avg. Training loss: 1.1757 0.0069 sec/batch\n",
      "Epoch 28/50 Iteration: 499200 Avg. Training loss: 0.7627 0.0068 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 499400 Avg. Training loss: 1.0434 0.0069 sec/batch\n",
      "Epoch 28/50 Iteration: 499600 Avg. Training loss: 1.4577 0.0081 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 499800 Avg. Training loss: 1.1495 0.0078 sec/batch\n",
      "Epoch 28/50 Iteration: 500000 Avg. Training loss: 0.8752 0.0069 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 500200 Avg. Training loss: 1.0580 0.0071 sec/batch\n",
      "Epoch 28/50 Iteration: 500400 Avg. Training loss: 1.1168 0.0186 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 500600 Avg. Training loss: 1.1781 0.0082 sec/batch\n",
      "Epoch 28/50 Iteration: 500800 Avg. Training loss: 1.3014 0.0079 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 501000 Avg. Training loss: 0.6780 0.0070 sec/batch\n",
      "Epoch 28/50 Iteration: 501200 Avg. Training loss: 1.1050 0.0071 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 501400 Avg. Training loss: 1.3925 0.0072 sec/batch\n",
      "Epoch 28/50 Iteration: 501600 Avg. Training loss: 1.1587 0.0074 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 501800 Avg. Training loss: 1.1269 0.0077 sec/batch\n",
      "Epoch 28/50 Iteration: 502000 Avg. Training loss: 0.9472 0.0071 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 502200 Avg. Training loss: 1.0883 0.0071 sec/batch\n",
      "Epoch 28/50 Iteration: 502400 Avg. Training loss: 1.2388 0.0076 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 502600 Avg. Training loss: 1.0121 0.0073 sec/batch\n",
      "Epoch 28/50 Iteration: 502800 Avg. Training loss: 1.1114 0.0071 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 503000 Avg. Training loss: 0.8543 0.0069 sec/batch\n",
      "Epoch 28/50 Iteration: 503200 Avg. Training loss: 0.9156 0.0071 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 503400 Avg. Training loss: 0.7650 0.0072 sec/batch\n",
      "Epoch 28/50 Iteration: 503600 Avg. Training loss: 0.8672 0.0076 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 503800 Avg. Training loss: 1.1115 0.0076 sec/batch\n",
      "Epoch 28/50 Iteration: 504000 Avg. Training loss: 0.8457 0.0073 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 504200 Avg. Training loss: 1.3050 0.0081 sec/batch\n",
      "Epoch 28/50 Iteration: 504400 Avg. Training loss: 1.1093 0.0069 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 504600 Avg. Training loss: 0.9799 0.0086 sec/batch\n",
      "Epoch 28/50 Iteration: 504800 Avg. Training loss: 0.9194 0.0072 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 Iteration: 505000 Avg. Training loss: 1.3746 0.0071 sec/batch\n",
      "Epoch 28/50 Iteration: 505200 Avg. Training loss: 1.1012 0.0068 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 505400 Avg. Training loss: 1.2938 0.0073 sec/batch\n",
      "Epoch 28/50 Iteration: 505600 Avg. Training loss: 1.3148 0.0072 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 505800 Avg. Training loss: 1.3818 0.0071 sec/batch\n",
      "Epoch 28/50 Iteration: 506000 Avg. Training loss: 0.8740 0.0070 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 506200 Avg. Training loss: 1.2412 0.0069 sec/batch\n",
      "Epoch 28/50 Iteration: 506400 Avg. Training loss: 1.2844 0.0071 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 506600 Avg. Training loss: 1.2813 0.0077 sec/batch\n",
      "Epoch 28/50 Iteration: 506800 Avg. Training loss: 1.2606 0.0078 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 507000 Avg. Training loss: 0.8556 0.0070 sec/batch\n",
      "Epoch 28/50 Iteration: 507200 Avg. Training loss: 1.1736 0.0073 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 507400 Avg. Training loss: 1.6980 0.0077 sec/batch\n",
      "Epoch 28/50 Iteration: 507600 Avg. Training loss: 0.8504 0.0072 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 507800 Avg. Training loss: 0.8531 0.0071 sec/batch\n",
      "Epoch 28/50 Iteration: 508000 Avg. Training loss: 0.9955 0.0069 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 508200 Avg. Training loss: 1.6028 0.0078 sec/batch\n",
      "Epoch 28/50 Iteration: 508400 Avg. Training loss: 1.3752 0.0076 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 508600 Avg. Training loss: 1.2796 0.0070 sec/batch\n",
      "Epoch 28/50 Iteration: 508800 Avg. Training loss: 1.0361 0.0070 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 509000 Avg. Training loss: 1.0764 0.0075 sec/batch\n",
      "Epoch 28/50 Iteration: 509200 Avg. Training loss: 0.9202 0.0089 sec/batch\n",
      "error\n",
      "Epoch 28/50 Iteration: 509400 Avg. Training loss: 1.3131 0.0080 sec/batch\n",
      "Epoch 29/50 Iteration: 509600 Avg. Training loss: 1.3362 0.0034 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 509800 Avg. Training loss: 1.1770 0.0078 sec/batch\n",
      "Epoch 29/50 Iteration: 510000 Avg. Training loss: 1.0600 0.0074 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 510200 Avg. Training loss: 1.2020 0.0073 sec/batch\n",
      "Epoch 29/50 Iteration: 510400 Avg. Training loss: 1.5240 0.0081 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 510600 Avg. Training loss: 1.2424 0.0076 sec/batch\n",
      "Epoch 29/50 Iteration: 510800 Avg. Training loss: 1.0710 0.0072 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 511000 Avg. Training loss: 1.0427 0.0075 sec/batch\n",
      "Epoch 29/50 Iteration: 511200 Avg. Training loss: 0.9664 0.0076 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 511400 Avg. Training loss: 1.0749 0.0069 sec/batch\n",
      "Epoch 29/50 Iteration: 511600 Avg. Training loss: 1.0271 0.0070 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 511800 Avg. Training loss: 1.2673 0.0073 sec/batch\n",
      "Epoch 29/50 Iteration: 512000 Avg. Training loss: 1.0502 0.0077 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 512200 Avg. Training loss: 0.7996 0.0071 sec/batch\n",
      "Epoch 29/50 Iteration: 512400 Avg. Training loss: 1.1322 0.0072 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 512600 Avg. Training loss: 1.1209 0.0072 sec/batch\n",
      "Epoch 29/50 Iteration: 512800 Avg. Training loss: 1.2830 0.0075 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 513000 Avg. Training loss: 1.0507 0.0084 sec/batch\n",
      "Epoch 29/50 Iteration: 513200 Avg. Training loss: 1.3519 0.0074 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 513400 Avg. Training loss: 1.1924 0.0075 sec/batch\n",
      "Epoch 29/50 Iteration: 513600 Avg. Training loss: 1.2143 0.0076 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 513800 Avg. Training loss: 0.7319 0.0077 sec/batch\n",
      "Epoch 29/50 Iteration: 514000 Avg. Training loss: 1.0022 0.0081 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 514200 Avg. Training loss: 0.7694 0.0072 sec/batch\n",
      "Epoch 29/50 Iteration: 514400 Avg. Training loss: 1.0084 0.0073 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 514600 Avg. Training loss: 1.1303 0.0078 sec/batch\n",
      "Epoch 29/50 Iteration: 514800 Avg. Training loss: 0.9657 0.0074 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 515000 Avg. Training loss: 1.5114 0.0086 sec/batch\n",
      "Epoch 29/50 Iteration: 515200 Avg. Training loss: 1.3804 0.0078 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 515400 Avg. Training loss: 1.1352 0.0082 sec/batch\n",
      "Epoch 29/50 Iteration: 515600 Avg. Training loss: 0.7452 0.0074 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 515800 Avg. Training loss: 1.1328 0.0075 sec/batch\n",
      "Epoch 29/50 Iteration: 516000 Avg. Training loss: 1.1809 0.0076 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 516200 Avg. Training loss: 1.1620 0.0074 sec/batch\n",
      "Epoch 29/50 Iteration: 516400 Avg. Training loss: 1.1679 0.0074 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 516600 Avg. Training loss: 1.2781 0.0078 sec/batch\n",
      "Epoch 29/50 Iteration: 516800 Avg. Training loss: 1.0182 0.0077 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 517000 Avg. Training loss: 0.8933 0.0079 sec/batch\n",
      "Epoch 29/50 Iteration: 517200 Avg. Training loss: 1.1848 0.0072 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 517400 Avg. Training loss: 0.8104 0.0074 sec/batch\n",
      "Epoch 29/50 Iteration: 517600 Avg. Training loss: 1.0014 0.0073 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 517800 Avg. Training loss: 1.4037 0.0089 sec/batch\n",
      "Epoch 29/50 Iteration: 518000 Avg. Training loss: 1.1695 0.0081 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 518200 Avg. Training loss: 1.0007 0.0074 sec/batch\n",
      "Epoch 29/50 Iteration: 518400 Avg. Training loss: 0.9500 0.0074 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 518600 Avg. Training loss: 1.3585 0.0077 sec/batch\n",
      "Epoch 29/50 Iteration: 518800 Avg. Training loss: 1.2040 0.0079 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 519000 Avg. Training loss: 1.5664 0.0084 sec/batch\n",
      "Epoch 29/50 Iteration: 519200 Avg. Training loss: 0.6599 0.0075 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 519400 Avg. Training loss: 0.8932 0.0076 sec/batch\n",
      "Epoch 29/50 Iteration: 519600 Avg. Training loss: 1.1769 0.0076 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 519800 Avg. Training loss: 1.3233 0.0080 sec/batch\n",
      "Epoch 29/50 Iteration: 520000 Avg. Training loss: 1.2343 0.0078 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 520200 Avg. Training loss: 0.9632 0.0075 sec/batch\n",
      "Epoch 29/50 Iteration: 520400 Avg. Training loss: 1.0375 0.0073 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 520600 Avg. Training loss: 0.9429 0.0079 sec/batch\n",
      "Epoch 29/50 Iteration: 520800 Avg. Training loss: 1.0847 0.0077 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 521000 Avg. Training loss: 1.1323 0.0075 sec/batch\n",
      "Epoch 29/50 Iteration: 521200 Avg. Training loss: 0.8084 0.0073 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 521400 Avg. Training loss: 0.8822 0.0076 sec/batch\n",
      "Epoch 29/50 Iteration: 521600 Avg. Training loss: 0.8353 0.0074 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 521800 Avg. Training loss: 1.0340 0.0076 sec/batch\n",
      "Epoch 29/50 Iteration: 522000 Avg. Training loss: 1.1448 0.0077 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 522200 Avg. Training loss: 0.9067 0.0078 sec/batch\n",
      "Epoch 29/50 Iteration: 522400 Avg. Training loss: 1.5856 0.0087 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 522600 Avg. Training loss: 1.2574 0.0073 sec/batch\n",
      "Epoch 29/50 Iteration: 522800 Avg. Training loss: 1.0192 0.0090 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 523000 Avg. Training loss: 0.8955 0.0075 sec/batch\n",
      "Epoch 29/50 Iteration: 523200 Avg. Training loss: 1.1884 0.0074 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 523400 Avg. Training loss: 1.0867 0.0072 sec/batch\n",
      "Epoch 29/50 Iteration: 523600 Avg. Training loss: 1.2158 0.0076 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 523800 Avg. Training loss: 1.5047 0.0075 sec/batch\n",
      "Epoch 29/50 Iteration: 524000 Avg. Training loss: 1.0966 0.0073 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 524200 Avg. Training loss: 1.0853 0.0072 sec/batch\n",
      "Epoch 29/50 Iteration: 524400 Avg. Training loss: 0.9318 0.0069 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 524600 Avg. Training loss: 1.2814 0.0072 sec/batch\n",
      "Epoch 29/50 Iteration: 524800 Avg. Training loss: 1.4122 0.0072 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 525000 Avg. Training loss: 1.2503 0.0081 sec/batch\n",
      "Epoch 29/50 Iteration: 525200 Avg. Training loss: 1.1631 0.0075 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 525400 Avg. Training loss: 1.1854 0.0073 sec/batch\n",
      "Epoch 29/50 Iteration: 525600 Avg. Training loss: 1.4632 0.0077 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 525800 Avg. Training loss: 0.9401 0.0073 sec/batch\n",
      "Epoch 29/50 Iteration: 526000 Avg. Training loss: 0.9069 0.0072 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 526200 Avg. Training loss: 0.8159 0.0070 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 Iteration: 526400 Avg. Training loss: 1.4153 0.0078 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 526600 Avg. Training loss: 1.5995 0.0078 sec/batch\n",
      "Epoch 29/50 Iteration: 526800 Avg. Training loss: 1.1102 0.0070 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 527000 Avg. Training loss: 0.8526 0.0073 sec/batch\n",
      "Epoch 29/50 Iteration: 527200 Avg. Training loss: 1.0540 0.0072 sec/batch\n",
      "error\n",
      "Epoch 29/50 Iteration: 527400 Avg. Training loss: 1.1943 0.0082 sec/batch\n",
      "Epoch 29/50 Iteration: 527600 Avg. Training loss: 1.3180 0.0073 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 527800 Avg. Training loss: 1.2093 0.0036 sec/batch\n",
      "Epoch 30/50 Iteration: 528000 Avg. Training loss: 1.2131 0.0077 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 528200 Avg. Training loss: 1.1549 0.0075 sec/batch\n",
      "Epoch 30/50 Iteration: 528400 Avg. Training loss: 1.0880 0.0072 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 528600 Avg. Training loss: 1.4799 0.0082 sec/batch\n",
      "Epoch 30/50 Iteration: 528800 Avg. Training loss: 1.3337 0.0077 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 529000 Avg. Training loss: 1.0874 0.0073 sec/batch\n",
      "Epoch 30/50 Iteration: 529200 Avg. Training loss: 1.1610 0.0077 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 529400 Avg. Training loss: 0.9609 0.0075 sec/batch\n",
      "Epoch 30/50 Iteration: 529600 Avg. Training loss: 1.2230 0.0069 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 529800 Avg. Training loss: 1.1178 0.0071 sec/batch\n",
      "Epoch 30/50 Iteration: 530000 Avg. Training loss: 1.3407 0.0072 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 530200 Avg. Training loss: 1.1292 0.0077 sec/batch\n",
      "Epoch 30/50 Iteration: 530400 Avg. Training loss: 0.9534 0.0070 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 530600 Avg. Training loss: 1.0541 0.0073 sec/batch\n",
      "Epoch 30/50 Iteration: 530800 Avg. Training loss: 1.0810 0.0074 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 531000 Avg. Training loss: 1.1531 0.0074 sec/batch\n",
      "Epoch 30/50 Iteration: 531200 Avg. Training loss: 1.0896 0.0080 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 531400 Avg. Training loss: 1.3336 0.0071 sec/batch\n",
      "Epoch 30/50 Iteration: 531600 Avg. Training loss: 1.2778 0.0072 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 531800 Avg. Training loss: 0.9878 0.0074 sec/batch\n",
      "Epoch 30/50 Iteration: 532000 Avg. Training loss: 0.7356 0.0071 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 532200 Avg. Training loss: 1.0088 0.0076 sec/batch\n",
      "Epoch 30/50 Iteration: 532400 Avg. Training loss: 0.7429 0.0069 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 532600 Avg. Training loss: 1.0334 0.0071 sec/batch\n",
      "Epoch 30/50 Iteration: 532800 Avg. Training loss: 0.9964 0.0075 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 533000 Avg. Training loss: 1.0152 0.0071 sec/batch\n",
      "Epoch 30/50 Iteration: 533200 Avg. Training loss: 1.3437 0.0081 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 533400 Avg. Training loss: 1.1248 0.0071 sec/batch\n",
      "Epoch 30/50 Iteration: 533600 Avg. Training loss: 1.2599 0.0077 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 533800 Avg. Training loss: 1.0876 0.0072 sec/batch\n",
      "Epoch 30/50 Iteration: 534000 Avg. Training loss: 1.3656 0.0073 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 534200 Avg. Training loss: 0.9763 0.0073 sec/batch\n",
      "Epoch 30/50 Iteration: 534400 Avg. Training loss: 1.1617 0.0071 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 534600 Avg. Training loss: 1.1941 0.0073 sec/batch\n",
      "Epoch 30/50 Iteration: 534800 Avg. Training loss: 1.4285 0.0075 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 535000 Avg. Training loss: 1.3219 0.0072 sec/batch\n",
      "Epoch 30/50 Iteration: 535200 Avg. Training loss: 0.8836 0.0075 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 535400 Avg. Training loss: 1.2529 0.0071 sec/batch\n",
      "Epoch 30/50 Iteration: 535600 Avg. Training loss: 0.6961 0.0070 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 535800 Avg. Training loss: 1.0727 0.0069 sec/batch\n",
      "Epoch 30/50 Iteration: 536000 Avg. Training loss: 1.2112 0.0085 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 536200 Avg. Training loss: 1.1131 0.0081 sec/batch\n",
      "Epoch 30/50 Iteration: 536400 Avg. Training loss: 1.1896 0.0071 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 536600 Avg. Training loss: 0.9965 0.0076 sec/batch\n",
      "Epoch 30/50 Iteration: 536800 Avg. Training loss: 1.1023 0.0076 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 537000 Avg. Training loss: 1.2628 0.0080 sec/batch\n",
      "Epoch 30/50 Iteration: 537200 Avg. Training loss: 1.4951 0.0083 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 537400 Avg. Training loss: 0.6676 0.0077 sec/batch\n",
      "Epoch 30/50 Iteration: 537600 Avg. Training loss: 1.0691 0.0075 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 537800 Avg. Training loss: 1.2019 0.0079 sec/batch\n",
      "Epoch 30/50 Iteration: 538000 Avg. Training loss: 1.2381 0.0081 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 538200 Avg. Training loss: 1.1391 0.0079 sec/batch\n",
      "Epoch 30/50 Iteration: 538400 Avg. Training loss: 0.9660 0.0072 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 538600 Avg. Training loss: 1.2258 0.0070 sec/batch\n",
      "Epoch 30/50 Iteration: 538800 Avg. Training loss: 0.9647 0.0078 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 539000 Avg. Training loss: 1.4317 0.0078 sec/batch\n",
      "Epoch 30/50 Iteration: 539200 Avg. Training loss: 1.1420 0.0075 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 539400 Avg. Training loss: 0.7368 0.0074 sec/batch\n",
      "Epoch 30/50 Iteration: 539600 Avg. Training loss: 0.7810 0.0076 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 539800 Avg. Training loss: 0.8661 0.0075 sec/batch\n",
      "Epoch 30/50 Iteration: 540000 Avg. Training loss: 1.0116 0.0075 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 540200 Avg. Training loss: 1.3607 0.0077 sec/batch\n",
      "Epoch 30/50 Iteration: 540400 Avg. Training loss: 0.7695 0.0078 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 540600 Avg. Training loss: 1.3275 0.0086 sec/batch\n",
      "Epoch 30/50 Iteration: 540800 Avg. Training loss: 1.1207 0.0075 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 541000 Avg. Training loss: 0.9382 0.0096 sec/batch\n",
      "Epoch 30/50 Iteration: 541200 Avg. Training loss: 0.7737 0.0081 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 541400 Avg. Training loss: 1.0659 0.0078 sec/batch\n",
      "Epoch 30/50 Iteration: 541600 Avg. Training loss: 1.0527 0.0074 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 541800 Avg. Training loss: 1.2381 0.0079 sec/batch\n",
      "Epoch 30/50 Iteration: 542000 Avg. Training loss: 1.3910 0.0077 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 542200 Avg. Training loss: 1.0646 0.0075 sec/batch\n",
      "Epoch 30/50 Iteration: 542400 Avg. Training loss: 0.9557 0.0074 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 542600 Avg. Training loss: 0.9630 0.0073 sec/batch\n",
      "Epoch 30/50 Iteration: 542800 Avg. Training loss: 1.4584 0.0076 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 543000 Avg. Training loss: 1.3169 0.0076 sec/batch\n",
      "Epoch 30/50 Iteration: 543200 Avg. Training loss: 1.2495 0.0079 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 543400 Avg. Training loss: 0.9613 0.0073 sec/batch\n",
      "Epoch 30/50 Iteration: 543600 Avg. Training loss: 1.2881 0.0077 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 543800 Avg. Training loss: 1.3630 0.0079 sec/batch\n",
      "Epoch 30/50 Iteration: 544000 Avg. Training loss: 0.8395 0.0076 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 544200 Avg. Training loss: 0.9097 0.0078 sec/batch\n",
      "Epoch 30/50 Iteration: 544400 Avg. Training loss: 0.9318 0.0076 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 544600 Avg. Training loss: 1.4287 0.0084 sec/batch\n",
      "Epoch 30/50 Iteration: 544800 Avg. Training loss: 1.4639 0.0081 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 545000 Avg. Training loss: 1.3889 0.0077 sec/batch\n",
      "Epoch 30/50 Iteration: 545200 Avg. Training loss: 0.7283 0.0077 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 545400 Avg. Training loss: 1.0837 0.0079 sec/batch\n",
      "Epoch 30/50 Iteration: 545600 Avg. Training loss: 1.0353 0.0087 sec/batch\n",
      "error\n",
      "Epoch 30/50 Iteration: 545800 Avg. Training loss: 1.0277 0.0080 sec/batch\n",
      "Epoch 31/50 Iteration: 546000 Avg. Training loss: 1.2297 0.0039 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 546200 Avg. Training loss: 1.6300 0.0083 sec/batch\n",
      "Epoch 31/50 Iteration: 546400 Avg. Training loss: 0.9824 0.0081 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 546600 Avg. Training loss: 1.2428 0.0078 sec/batch\n",
      "Epoch 31/50 Iteration: 546800 Avg. Training loss: 1.3076 0.0086 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 547000 Avg. Training loss: 1.2515 0.0080 sec/batch\n",
      "Epoch 31/50 Iteration: 547200 Avg. Training loss: 1.0887 0.0078 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 547400 Avg. Training loss: 1.1816 0.0081 sec/batch\n",
      "Epoch 31/50 Iteration: 547600 Avg. Training loss: 1.0093 0.0080 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 Iteration: 547800 Avg. Training loss: 1.2119 0.0077 sec/batch\n",
      "Epoch 31/50 Iteration: 548000 Avg. Training loss: 1.2192 0.0076 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 548200 Avg. Training loss: 1.3019 0.0078 sec/batch\n",
      "Epoch 31/50 Iteration: 548400 Avg. Training loss: 1.2452 0.0082 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 548600 Avg. Training loss: 0.7528 0.0077 sec/batch\n",
      "Epoch 31/50 Iteration: 548800 Avg. Training loss: 1.1053 0.0078 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 549000 Avg. Training loss: 1.3517 0.0078 sec/batch\n",
      "Epoch 31/50 Iteration: 549200 Avg. Training loss: 1.2535 0.0080 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 549400 Avg. Training loss: 1.0218 0.0086 sec/batch\n",
      "Epoch 31/50 Iteration: 549600 Avg. Training loss: 1.3403 0.0077 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 549800 Avg. Training loss: 1.1328 0.0078 sec/batch\n",
      "Epoch 31/50 Iteration: 550000 Avg. Training loss: 0.9773 0.0078 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 550200 Avg. Training loss: 0.8860 0.0075 sec/batch\n",
      "Epoch 31/50 Iteration: 550400 Avg. Training loss: 1.3129 0.0081 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 550600 Avg. Training loss: 0.6913 0.0075 sec/batch\n",
      "Epoch 31/50 Iteration: 550800 Avg. Training loss: 1.1560 0.0077 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 551000 Avg. Training loss: 0.9894 0.0079 sec/batch\n",
      "Epoch 31/50 Iteration: 551200 Avg. Training loss: 0.9132 0.0076 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 551400 Avg. Training loss: 1.5819 0.0084 sec/batch\n",
      "Epoch 31/50 Iteration: 551600 Avg. Training loss: 1.2760 0.0076 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 551800 Avg. Training loss: 1.0868 0.0082 sec/batch\n",
      "Epoch 31/50 Iteration: 552000 Avg. Training loss: 0.9565 0.0077 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 552200 Avg. Training loss: 1.0347 0.0079 sec/batch\n",
      "Epoch 31/50 Iteration: 552400 Avg. Training loss: 0.9467 0.0078 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 552600 Avg. Training loss: 1.2038 0.0077 sec/batch\n",
      "Epoch 31/50 Iteration: 552800 Avg. Training loss: 1.2375 0.0077 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 553000 Avg. Training loss: 1.4154 0.0079 sec/batch\n",
      "Epoch 31/50 Iteration: 553200 Avg. Training loss: 1.1726 0.0078 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 553400 Avg. Training loss: 0.9104 0.0081 sec/batch\n",
      "Epoch 31/50 Iteration: 553600 Avg. Training loss: 1.2111 0.0075 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 553800 Avg. Training loss: 0.6998 0.0075 sec/batch\n",
      "Epoch 31/50 Iteration: 554000 Avg. Training loss: 1.0048 0.0075 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 554200 Avg. Training loss: 1.4425 0.0089 sec/batch\n",
      "Epoch 31/50 Iteration: 554400 Avg. Training loss: 1.1307 0.0082 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 554600 Avg. Training loss: 1.2311 0.0074 sec/batch\n",
      "Epoch 31/50 Iteration: 554800 Avg. Training loss: 1.0478 0.0076 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 555000 Avg. Training loss: 1.3584 0.0078 sec/batch\n",
      "Epoch 31/50 Iteration: 555200 Avg. Training loss: 1.4544 0.0083 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 555400 Avg. Training loss: 1.3116 0.0084 sec/batch\n",
      "Epoch 31/50 Iteration: 555600 Avg. Training loss: 0.7230 0.0078 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 555800 Avg. Training loss: 0.8803 0.0078 sec/batch\n",
      "Epoch 31/50 Iteration: 556000 Avg. Training loss: 1.4071 0.0084 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 556200 Avg. Training loss: 1.3564 0.0085 sec/batch\n",
      "Epoch 31/50 Iteration: 556400 Avg. Training loss: 1.3055 0.0080 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 556600 Avg. Training loss: 1.0887 0.0076 sec/batch\n",
      "Epoch 31/50 Iteration: 556800 Avg. Training loss: 1.0381 0.0075 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 557000 Avg. Training loss: 0.8872 0.0081 sec/batch\n",
      "Epoch 31/50 Iteration: 557200 Avg. Training loss: 1.0420 0.0080 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 557400 Avg. Training loss: 1.1903 0.0077 sec/batch\n",
      "Epoch 31/50 Iteration: 557600 Avg. Training loss: 0.7644 0.0076 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 557800 Avg. Training loss: 0.9302 0.0078 sec/batch\n",
      "Epoch 31/50 Iteration: 558000 Avg. Training loss: 0.8858 0.0077 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 558200 Avg. Training loss: 1.0564 0.0078 sec/batch\n",
      "Epoch 31/50 Iteration: 558400 Avg. Training loss: 1.3213 0.0079 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 558600 Avg. Training loss: 0.8681 0.0080 sec/batch\n",
      "Epoch 31/50 Iteration: 558800 Avg. Training loss: 1.3172 0.0087 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 559000 Avg. Training loss: 1.1400 0.0077 sec/batch\n",
      "Epoch 31/50 Iteration: 559200 Avg. Training loss: 1.0895 0.0092 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 559400 Avg. Training loss: 0.9646 0.0079 sec/batch\n",
      "Epoch 31/50 Iteration: 559600 Avg. Training loss: 1.2419 0.0080 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 559800 Avg. Training loss: 1.1200 0.0077 sec/batch\n",
      "Epoch 31/50 Iteration: 560000 Avg. Training loss: 1.2679 0.0080 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 560200 Avg. Training loss: 1.3097 0.0079 sec/batch\n",
      "Epoch 31/50 Iteration: 560400 Avg. Training loss: 1.1841 0.0078 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 560600 Avg. Training loss: 0.8316 0.0077 sec/batch\n",
      "Epoch 31/50 Iteration: 560800 Avg. Training loss: 1.1885 0.0076 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 561000 Avg. Training loss: 1.2707 0.0079 sec/batch\n",
      "Epoch 31/50 Iteration: 561200 Avg. Training loss: 1.4480 0.0077 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 561400 Avg. Training loss: 1.2612 0.0082 sec/batch\n",
      "Epoch 31/50 Iteration: 561600 Avg. Training loss: 1.1669 0.0075 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 561800 Avg. Training loss: 1.0700 0.0078 sec/batch\n",
      "Epoch 31/50 Iteration: 562000 Avg. Training loss: 1.4447 0.0080 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 562200 Avg. Training loss: 1.0024 0.0078 sec/batch\n",
      "Epoch 31/50 Iteration: 562400 Avg. Training loss: 0.8437 0.0077 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 562600 Avg. Training loss: 1.0459 0.0074 sec/batch\n",
      "Epoch 31/50 Iteration: 562800 Avg. Training loss: 1.4184 0.0083 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 563000 Avg. Training loss: 1.6580 0.0080 sec/batch\n",
      "Epoch 31/50 Iteration: 563200 Avg. Training loss: 1.3208 0.0075 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 563400 Avg. Training loss: 0.9136 0.0077 sec/batch\n",
      "Epoch 31/50 Iteration: 563600 Avg. Training loss: 1.1132 0.0077 sec/batch\n",
      "error\n",
      "Epoch 31/50 Iteration: 563800 Avg. Training loss: 1.0129 0.0086 sec/batch\n",
      "Epoch 31/50 Iteration: 564000 Avg. Training loss: 1.1460 0.0080 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 564200 Avg. Training loss: 1.1695 0.0040 sec/batch\n",
      "Epoch 32/50 Iteration: 564400 Avg. Training loss: 1.3153 0.0083 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 564600 Avg. Training loss: 0.9929 0.0081 sec/batch\n",
      "Epoch 32/50 Iteration: 564800 Avg. Training loss: 0.9382 0.0079 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 565000 Avg. Training loss: 1.5567 0.0087 sec/batch\n",
      "Epoch 32/50 Iteration: 565200 Avg. Training loss: 1.2066 0.0082 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 565400 Avg. Training loss: 1.1373 0.0079 sec/batch\n",
      "Epoch 32/50 Iteration: 565600 Avg. Training loss: 1.1305 0.0082 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 565800 Avg. Training loss: 1.2424 0.0080 sec/batch\n",
      "Epoch 32/50 Iteration: 566000 Avg. Training loss: 1.0856 0.0076 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 566200 Avg. Training loss: 1.1556 0.0077 sec/batch\n",
      "Epoch 32/50 Iteration: 566400 Avg. Training loss: 1.3606 0.0078 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 566600 Avg. Training loss: 0.9365 0.0082 sec/batch\n",
      "Epoch 32/50 Iteration: 566800 Avg. Training loss: 0.8246 0.0077 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 567000 Avg. Training loss: 1.1486 0.0080 sec/batch\n",
      "Epoch 32/50 Iteration: 567200 Avg. Training loss: 1.0056 0.0080 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 567400 Avg. Training loss: 1.2854 0.0081 sec/batch\n",
      "Epoch 32/50 Iteration: 567600 Avg. Training loss: 1.0618 0.0086 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 567800 Avg. Training loss: 1.2902 0.0076 sec/batch\n",
      "Epoch 32/50 Iteration: 568000 Avg. Training loss: 1.1594 0.0078 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 568200 Avg. Training loss: 1.1550 0.0078 sec/batch\n",
      "Epoch 32/50 Iteration: 568400 Avg. Training loss: 0.9835 0.0075 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 568600 Avg. Training loss: 0.9478 0.0082 sec/batch\n",
      "Epoch 32/50 Iteration: 568800 Avg. Training loss: 0.7636 0.0076 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 569000 Avg. Training loss: 0.9405 0.0078 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 Iteration: 569200 Avg. Training loss: 1.1220 0.0080 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 569400 Avg. Training loss: 0.9765 0.0077 sec/batch\n",
      "Epoch 32/50 Iteration: 569600 Avg. Training loss: 1.6784 0.0085 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 569800 Avg. Training loss: 1.1862 0.0077 sec/batch\n",
      "Epoch 32/50 Iteration: 570000 Avg. Training loss: 1.0853 0.0083 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 570200 Avg. Training loss: 0.9606 0.0077 sec/batch\n",
      "Epoch 32/50 Iteration: 570400 Avg. Training loss: 1.2864 0.0079 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 570600 Avg. Training loss: 0.9067 0.0079 sec/batch\n",
      "Epoch 32/50 Iteration: 570800 Avg. Training loss: 1.2057 0.0077 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 571000 Avg. Training loss: 0.9527 0.0076 sec/batch\n",
      "Epoch 32/50 Iteration: 571200 Avg. Training loss: 1.3225 0.0077 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 571400 Avg. Training loss: 1.2990 0.0074 sec/batch\n",
      "Epoch 32/50 Iteration: 571600 Avg. Training loss: 0.8407 0.0076 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 571800 Avg. Training loss: 1.2624 0.0072 sec/batch\n",
      "Epoch 32/50 Iteration: 572000 Avg. Training loss: 0.9167 0.0071 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 572200 Avg. Training loss: 0.9170 0.0068 sec/batch\n",
      "Epoch 32/50 Iteration: 572400 Avg. Training loss: 1.4675 0.0085 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 572600 Avg. Training loss: 1.1900 0.0078 sec/batch\n",
      "Epoch 32/50 Iteration: 572800 Avg. Training loss: 1.1412 0.0072 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 573000 Avg. Training loss: 1.2351 0.0072 sec/batch\n",
      "Epoch 32/50 Iteration: 573200 Avg. Training loss: 1.3224 0.0073 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 573400 Avg. Training loss: 1.3359 0.0079 sec/batch\n",
      "Epoch 32/50 Iteration: 573600 Avg. Training loss: 1.2674 0.0081 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 573800 Avg. Training loss: 0.6426 0.0071 sec/batch\n",
      "Epoch 32/50 Iteration: 574000 Avg. Training loss: 1.0504 0.0073 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 574200 Avg. Training loss: 1.1792 0.0074 sec/batch\n",
      "Epoch 32/50 Iteration: 574400 Avg. Training loss: 1.3380 0.0075 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 574600 Avg. Training loss: 1.2345 0.0074 sec/batch\n",
      "Epoch 32/50 Iteration: 574800 Avg. Training loss: 1.1142 0.0068 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 575000 Avg. Training loss: 1.2339 0.0070 sec/batch\n",
      "Epoch 32/50 Iteration: 575200 Avg. Training loss: 1.2138 0.0076 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 575400 Avg. Training loss: 1.0898 0.0073 sec/batch\n",
      "Epoch 32/50 Iteration: 575600 Avg. Training loss: 0.9719 0.0071 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 575800 Avg. Training loss: 1.0408 0.0070 sec/batch\n",
      "Epoch 32/50 Iteration: 576000 Avg. Training loss: 0.9143 0.0073 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 576200 Avg. Training loss: 0.8429 0.0070 sec/batch\n",
      "Epoch 32/50 Iteration: 576400 Avg. Training loss: 1.3146 0.0070 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 576600 Avg. Training loss: 0.9835 0.0073 sec/batch\n",
      "Epoch 32/50 Iteration: 576800 Avg. Training loss: 0.9583 0.0074 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 577000 Avg. Training loss: 1.2345 0.0082 sec/batch\n",
      "Epoch 32/50 Iteration: 577200 Avg. Training loss: 1.2531 0.0070 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 577400 Avg. Training loss: 1.0659 0.0086 sec/batch\n",
      "Epoch 32/50 Iteration: 577600 Avg. Training loss: 0.9486 0.0073 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 577800 Avg. Training loss: 1.2082 0.0074 sec/batch\n",
      "Epoch 32/50 Iteration: 578000 Avg. Training loss: 1.4235 0.0070 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 578200 Avg. Training loss: 1.3404 0.0075 sec/batch\n",
      "Epoch 32/50 Iteration: 578400 Avg. Training loss: 1.3983 0.0074 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 578600 Avg. Training loss: 1.2157 0.0077 sec/batch\n",
      "Epoch 32/50 Iteration: 578800 Avg. Training loss: 1.0313 0.0075 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 579000 Avg. Training loss: 1.1563 0.0071 sec/batch\n",
      "Epoch 32/50 Iteration: 579200 Avg. Training loss: 1.2924 0.0072 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 579400 Avg. Training loss: 1.1261 0.0072 sec/batch\n",
      "Epoch 32/50 Iteration: 579600 Avg. Training loss: 1.4153 0.0076 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 579800 Avg. Training loss: 1.1129 0.0066 sec/batch\n",
      "Epoch 32/50 Iteration: 580000 Avg. Training loss: 1.2661 0.0071 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 580200 Avg. Training loss: 1.2041 0.0074 sec/batch\n",
      "Epoch 32/50 Iteration: 580400 Avg. Training loss: 1.0112 0.0072 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 580600 Avg. Training loss: 0.8664 0.0070 sec/batch\n",
      "Epoch 32/50 Iteration: 580800 Avg. Training loss: 0.9785 0.0069 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 581000 Avg. Training loss: 1.3673 0.0077 sec/batch\n",
      "Epoch 32/50 Iteration: 581200 Avg. Training loss: 1.5860 0.0074 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 581400 Avg. Training loss: 0.9917 0.0069 sec/batch\n",
      "Epoch 32/50 Iteration: 581600 Avg. Training loss: 1.1481 0.0070 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 581800 Avg. Training loss: 1.3447 0.0071 sec/batch\n",
      "Epoch 32/50 Iteration: 582000 Avg. Training loss: 1.0206 0.0080 sec/batch\n",
      "error\n",
      "Epoch 32/50 Iteration: 582200 Avg. Training loss: 1.0973 0.0073 sec/batch\n",
      "Epoch 33/50 Iteration: 582400 Avg. Training loss: 1.6596 0.0038 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 582600 Avg. Training loss: 1.2516 0.0076 sec/batch\n",
      "Epoch 33/50 Iteration: 582800 Avg. Training loss: 1.1293 0.0072 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 583000 Avg. Training loss: 1.1864 0.0072 sec/batch\n",
      "Epoch 33/50 Iteration: 583200 Avg. Training loss: 1.6626 0.0080 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 583400 Avg. Training loss: 1.1912 0.0075 sec/batch\n",
      "Epoch 33/50 Iteration: 583600 Avg. Training loss: 1.0843 0.0072 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 583800 Avg. Training loss: 1.0889 0.0075 sec/batch\n",
      "Epoch 33/50 Iteration: 584000 Avg. Training loss: 1.1681 0.0075 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 584200 Avg. Training loss: 1.0403 0.0070 sec/batch\n",
      "Epoch 33/50 Iteration: 584400 Avg. Training loss: 1.0033 0.0070 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 584600 Avg. Training loss: 1.1617 0.0072 sec/batch\n",
      "Epoch 33/50 Iteration: 584800 Avg. Training loss: 1.1555 0.0076 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 585000 Avg. Training loss: 0.8371 0.0071 sec/batch\n",
      "Epoch 33/50 Iteration: 585200 Avg. Training loss: 1.0450 0.0070 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 585400 Avg. Training loss: 1.0331 0.0071 sec/batch\n",
      "Epoch 33/50 Iteration: 585600 Avg. Training loss: 1.1470 0.0073 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 585800 Avg. Training loss: 1.2483 0.0079 sec/batch\n",
      "Epoch 33/50 Iteration: 586000 Avg. Training loss: 1.3110 0.0138 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 586200 Avg. Training loss: 1.2028 0.0086 sec/batch\n",
      "Epoch 33/50 Iteration: 586400 Avg. Training loss: 0.9880 0.0071 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 586600 Avg. Training loss: 1.1094 0.0070 sec/batch\n",
      "Epoch 33/50 Iteration: 586800 Avg. Training loss: 1.0164 0.0075 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 587000 Avg. Training loss: 0.6712 0.0070 sec/batch\n",
      "Epoch 33/50 Iteration: 587200 Avg. Training loss: 1.0914 0.0076 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 587400 Avg. Training loss: 1.2422 0.0077 sec/batch\n",
      "Epoch 33/50 Iteration: 587600 Avg. Training loss: 0.9745 0.0071 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 587800 Avg. Training loss: 1.5223 0.0079 sec/batch\n",
      "Epoch 33/50 Iteration: 588000 Avg. Training loss: 1.2429 0.0070 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 588200 Avg. Training loss: 0.9788 0.0081 sec/batch\n",
      "Epoch 33/50 Iteration: 588400 Avg. Training loss: 0.8677 0.0075 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 588600 Avg. Training loss: 1.2761 0.0077 sec/batch\n",
      "Epoch 33/50 Iteration: 588800 Avg. Training loss: 1.0607 0.0076 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 589000 Avg. Training loss: 1.1279 0.0074 sec/batch\n",
      "Epoch 33/50 Iteration: 589200 Avg. Training loss: 1.1300 0.0076 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 589400 Avg. Training loss: 1.2466 0.0078 sec/batch\n",
      "Epoch 33/50 Iteration: 589600 Avg. Training loss: 1.2361 0.0078 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 589800 Avg. Training loss: 0.9531 0.0079 sec/batch\n",
      "Epoch 33/50 Iteration: 590000 Avg. Training loss: 1.1277 0.0075 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 590200 Avg. Training loss: 0.7608 0.0075 sec/batch\n",
      "Epoch 33/50 Iteration: 590400 Avg. Training loss: 0.9765 0.0074 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 Iteration: 590600 Avg. Training loss: 1.3128 0.0091 sec/batch\n",
      "Epoch 33/50 Iteration: 590800 Avg. Training loss: 1.3244 0.0080 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 591000 Avg. Training loss: 1.3322 0.0076 sec/batch\n",
      "Epoch 33/50 Iteration: 591200 Avg. Training loss: 1.0898 0.0076 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 591400 Avg. Training loss: 1.3984 0.0076 sec/batch\n",
      "Epoch 33/50 Iteration: 591600 Avg. Training loss: 1.3005 0.0082 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 591800 Avg. Training loss: 1.4971 0.0082 sec/batch\n",
      "Epoch 33/50 Iteration: 592000 Avg. Training loss: 0.7386 0.0074 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 592200 Avg. Training loss: 1.0044 0.0077 sec/batch\n",
      "Epoch 33/50 Iteration: 592400 Avg. Training loss: 1.5503 0.0077 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 592600 Avg. Training loss: 1.2410 0.0080 sec/batch\n",
      "Epoch 33/50 Iteration: 592800 Avg. Training loss: 1.4120 0.0078 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 593000 Avg. Training loss: 0.9742 0.0075 sec/batch\n",
      "Epoch 33/50 Iteration: 593200 Avg. Training loss: 1.0348 0.0074 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 593400 Avg. Training loss: 0.8974 0.0080 sec/batch\n",
      "Epoch 33/50 Iteration: 593600 Avg. Training loss: 1.2155 0.0077 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 593800 Avg. Training loss: 1.3080 0.0076 sec/batch\n",
      "Epoch 33/50 Iteration: 594000 Avg. Training loss: 0.7896 0.0075 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 594200 Avg. Training loss: 0.8673 0.0076 sec/batch\n",
      "Epoch 33/50 Iteration: 594400 Avg. Training loss: 0.9003 0.0076 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 594600 Avg. Training loss: 0.9464 0.0076 sec/batch\n",
      "Epoch 33/50 Iteration: 594800 Avg. Training loss: 1.0486 0.0077 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 595000 Avg. Training loss: 0.7604 0.0079 sec/batch\n",
      "Epoch 33/50 Iteration: 595200 Avg. Training loss: 1.3795 0.0085 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 595400 Avg. Training loss: 0.9390 0.0076 sec/batch\n",
      "Epoch 33/50 Iteration: 595600 Avg. Training loss: 0.9456 0.0089 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 595800 Avg. Training loss: 0.8926 0.0079 sec/batch\n",
      "Epoch 33/50 Iteration: 596000 Avg. Training loss: 1.3120 0.0079 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 596200 Avg. Training loss: 1.2271 0.0075 sec/batch\n",
      "Epoch 33/50 Iteration: 596400 Avg. Training loss: 1.1139 0.0079 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 596600 Avg. Training loss: 1.3598 0.0078 sec/batch\n",
      "Epoch 33/50 Iteration: 596800 Avg. Training loss: 1.1561 0.0078 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 597000 Avg. Training loss: 1.0544 0.0076 sec/batch\n",
      "Epoch 33/50 Iteration: 597200 Avg. Training loss: 1.0831 0.0076 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 597400 Avg. Training loss: 1.3733 0.0077 sec/batch\n",
      "Epoch 33/50 Iteration: 597600 Avg. Training loss: 1.1266 0.0076 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 597800 Avg. Training loss: 1.4970 0.0081 sec/batch\n",
      "Epoch 33/50 Iteration: 598000 Avg. Training loss: 1.1077 0.0074 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 598200 Avg. Training loss: 1.0502 0.0078 sec/batch\n",
      "Epoch 33/50 Iteration: 598400 Avg. Training loss: 1.4567 0.0079 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 598600 Avg. Training loss: 1.0468 0.0076 sec/batch\n",
      "Epoch 33/50 Iteration: 598800 Avg. Training loss: 0.9865 0.0076 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 599000 Avg. Training loss: 0.9877 0.0074 sec/batch\n",
      "Epoch 33/50 Iteration: 599200 Avg. Training loss: 1.4946 0.0083 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 599400 Avg. Training loss: 1.5738 0.0079 sec/batch\n",
      "Epoch 33/50 Iteration: 599600 Avg. Training loss: 1.4390 0.0075 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 599800 Avg. Training loss: 0.8519 0.0077 sec/batch\n",
      "Epoch 33/50 Iteration: 600000 Avg. Training loss: 1.0817 0.0077 sec/batch\n",
      "error\n",
      "Epoch 33/50 Iteration: 600200 Avg. Training loss: 1.2068 0.0086 sec/batch\n",
      "Epoch 33/50 Iteration: 600400 Avg. Training loss: 1.2189 0.0079 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 600600 Avg. Training loss: 1.3793 0.0042 sec/batch\n",
      "Epoch 34/50 Iteration: 600800 Avg. Training loss: 1.2938 0.0083 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 601000 Avg. Training loss: 1.0552 0.0079 sec/batch\n",
      "Epoch 34/50 Iteration: 601200 Avg. Training loss: 1.2380 0.0079 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 601400 Avg. Training loss: 1.4752 0.0085 sec/batch\n",
      "Epoch 34/50 Iteration: 601600 Avg. Training loss: 1.0439 0.0080 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 601800 Avg. Training loss: 1.2430 0.0078 sec/batch\n",
      "Epoch 34/50 Iteration: 602000 Avg. Training loss: 1.1216 0.0081 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 602200 Avg. Training loss: 1.2467 0.0079 sec/batch\n",
      "Epoch 34/50 Iteration: 602400 Avg. Training loss: 1.1856 0.0074 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 602600 Avg. Training loss: 1.2267 0.0079 sec/batch\n",
      "Epoch 34/50 Iteration: 602800 Avg. Training loss: 1.3793 0.0081 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 603000 Avg. Training loss: 1.2001 0.0084 sec/batch\n",
      "Epoch 34/50 Iteration: 603200 Avg. Training loss: 0.8685 0.0075 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 603400 Avg. Training loss: 1.2382 0.0076 sec/batch\n",
      "Epoch 34/50 Iteration: 603600 Avg. Training loss: 1.0673 0.0077 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 603800 Avg. Training loss: 1.0845 0.0080 sec/batch\n",
      "Epoch 34/50 Iteration: 604000 Avg. Training loss: 1.2080 0.0084 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 604200 Avg. Training loss: 1.3568 0.0076 sec/batch\n",
      "Epoch 34/50 Iteration: 604400 Avg. Training loss: 1.3239 0.0078 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 604600 Avg. Training loss: 1.2838 0.0077 sec/batch\n",
      "Epoch 34/50 Iteration: 604800 Avg. Training loss: 0.9283 0.0075 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 605000 Avg. Training loss: 1.1271 0.0080 sec/batch\n",
      "Epoch 34/50 Iteration: 605200 Avg. Training loss: 0.7694 0.0074 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 605400 Avg. Training loss: 0.9090 0.0076 sec/batch\n",
      "Epoch 34/50 Iteration: 605600 Avg. Training loss: 1.1588 0.0077 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 605800 Avg. Training loss: 1.0548 0.0077 sec/batch\n",
      "Epoch 34/50 Iteration: 606000 Avg. Training loss: 1.6250 0.0084 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 606200 Avg. Training loss: 1.1223 0.0076 sec/batch\n",
      "Epoch 34/50 Iteration: 606400 Avg. Training loss: 1.3055 0.0082 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 606600 Avg. Training loss: 0.8409 0.0077 sec/batch\n",
      "Epoch 34/50 Iteration: 606800 Avg. Training loss: 1.2164 0.0079 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 607000 Avg. Training loss: 0.9923 0.0077 sec/batch\n",
      "Epoch 34/50 Iteration: 607200 Avg. Training loss: 1.0677 0.0076 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 607400 Avg. Training loss: 1.0582 0.0077 sec/batch\n",
      "Epoch 34/50 Iteration: 607600 Avg. Training loss: 1.2552 0.0080 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 607800 Avg. Training loss: 1.2154 0.0078 sec/batch\n",
      "Epoch 34/50 Iteration: 608000 Avg. Training loss: 0.8938 0.0080 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 608200 Avg. Training loss: 1.1408 0.0077 sec/batch\n",
      "Epoch 34/50 Iteration: 608400 Avg. Training loss: 0.6892 0.0074 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 608600 Avg. Training loss: 1.0259 0.0075 sec/batch\n",
      "Epoch 34/50 Iteration: 608800 Avg. Training loss: 1.5076 0.0090 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 609000 Avg. Training loss: 1.1374 0.0081 sec/batch\n",
      "Epoch 34/50 Iteration: 609200 Avg. Training loss: 1.3775 0.0075 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 609400 Avg. Training loss: 1.1469 0.0078 sec/batch\n",
      "Epoch 34/50 Iteration: 609600 Avg. Training loss: 1.3523 0.0077 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 609800 Avg. Training loss: 1.0578 0.0084 sec/batch\n",
      "Epoch 34/50 Iteration: 610000 Avg. Training loss: 1.4103 0.0084 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 610200 Avg. Training loss: 0.6706 0.0077 sec/batch\n",
      "Epoch 34/50 Iteration: 610400 Avg. Training loss: 1.1591 0.0077 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 610600 Avg. Training loss: 1.4612 0.0078 sec/batch\n",
      "Epoch 34/50 Iteration: 610800 Avg. Training loss: 1.3223 0.0080 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 611000 Avg. Training loss: 1.3176 0.0079 sec/batch\n",
      "Epoch 34/50 Iteration: 611200 Avg. Training loss: 0.9878 0.0076 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 611400 Avg. Training loss: 0.8735 0.0076 sec/batch\n",
      "Epoch 34/50 Iteration: 611600 Avg. Training loss: 1.0352 0.0077 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 611800 Avg. Training loss: 1.2137 0.0075 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 Iteration: 612000 Avg. Training loss: 1.0142 0.0074 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 612200 Avg. Training loss: 0.5710 0.0072 sec/batch\n",
      "Epoch 34/50 Iteration: 612400 Avg. Training loss: 0.9089 0.0073 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 612600 Avg. Training loss: 0.8167 0.0074 sec/batch\n",
      "Epoch 34/50 Iteration: 612800 Avg. Training loss: 0.9402 0.0075 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 613000 Avg. Training loss: 1.2031 0.0075 sec/batch\n",
      "Epoch 34/50 Iteration: 613200 Avg. Training loss: 0.8133 0.0077 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 613400 Avg. Training loss: 1.2273 0.0085 sec/batch\n",
      "Epoch 34/50 Iteration: 613600 Avg. Training loss: 1.2732 0.0074 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 613800 Avg. Training loss: 1.0479 0.0088 sec/batch\n",
      "Epoch 34/50 Iteration: 614000 Avg. Training loss: 0.8844 0.0077 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 614200 Avg. Training loss: 1.3530 0.0077 sec/batch\n",
      "Epoch 34/50 Iteration: 614400 Avg. Training loss: 1.0760 0.0074 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 614600 Avg. Training loss: 1.1315 0.0077 sec/batch\n",
      "Epoch 34/50 Iteration: 614800 Avg. Training loss: 1.3651 0.0076 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 615000 Avg. Training loss: 1.2659 0.0075 sec/batch\n",
      "Epoch 34/50 Iteration: 615200 Avg. Training loss: 0.9646 0.0074 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 615400 Avg. Training loss: 1.2988 0.0074 sec/batch\n",
      "Epoch 34/50 Iteration: 615600 Avg. Training loss: 1.3890 0.0074 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 615800 Avg. Training loss: 1.1921 0.0075 sec/batch\n",
      "Epoch 34/50 Iteration: 616000 Avg. Training loss: 1.1602 0.0079 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 616200 Avg. Training loss: 1.1650 0.0073 sec/batch\n",
      "Epoch 34/50 Iteration: 616400 Avg. Training loss: 0.9850 0.0075 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 616600 Avg. Training loss: 1.4314 0.0077 sec/batch\n",
      "Epoch 34/50 Iteration: 616800 Avg. Training loss: 0.9603 0.0075 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 617000 Avg. Training loss: 0.9876 0.0073 sec/batch\n",
      "Epoch 34/50 Iteration: 617200 Avg. Training loss: 0.9606 0.0073 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 617400 Avg. Training loss: 1.4897 0.0082 sec/batch\n",
      "Epoch 34/50 Iteration: 617600 Avg. Training loss: 1.4509 0.0078 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 617800 Avg. Training loss: 1.1997 0.0074 sec/batch\n",
      "Epoch 34/50 Iteration: 618000 Avg. Training loss: 0.8459 0.0073 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 618200 Avg. Training loss: 1.2528 0.0079 sec/batch\n",
      "Epoch 34/50 Iteration: 618400 Avg. Training loss: 0.9582 0.0086 sec/batch\n",
      "error\n",
      "Epoch 34/50 Iteration: 618600 Avg. Training loss: 1.2129 0.0076 sec/batch\n",
      "Epoch 35/50 Iteration: 618800 Avg. Training loss: 1.3544 0.0042 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 619000 Avg. Training loss: 1.1919 0.0080 sec/batch\n",
      "Epoch 35/50 Iteration: 619200 Avg. Training loss: 1.0626 0.0075 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 619400 Avg. Training loss: 1.2118 0.0075 sec/batch\n",
      "Epoch 35/50 Iteration: 619600 Avg. Training loss: 1.4211 0.0083 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 619800 Avg. Training loss: 1.3058 0.0078 sec/batch\n",
      "Epoch 35/50 Iteration: 620000 Avg. Training loss: 1.0589 0.0076 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 620200 Avg. Training loss: 0.9653 0.0077 sec/batch\n",
      "Epoch 35/50 Iteration: 620400 Avg. Training loss: 1.2120 0.0077 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 620600 Avg. Training loss: 1.1634 0.0072 sec/batch\n",
      "Epoch 35/50 Iteration: 620800 Avg. Training loss: 1.0375 0.0073 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 621000 Avg. Training loss: 1.2527 0.0075 sec/batch\n",
      "Epoch 35/50 Iteration: 621200 Avg. Training loss: 1.0993 0.0079 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 621400 Avg. Training loss: 0.7731 0.0074 sec/batch\n",
      "Epoch 35/50 Iteration: 621600 Avg. Training loss: 1.1478 0.0073 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 621800 Avg. Training loss: 1.0506 0.0074 sec/batch\n",
      "Epoch 35/50 Iteration: 622000 Avg. Training loss: 1.2779 0.0076 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 622200 Avg. Training loss: 1.3122 0.0082 sec/batch\n",
      "Epoch 35/50 Iteration: 622400 Avg. Training loss: 1.3435 0.0073 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 622600 Avg. Training loss: 1.1326 0.0076 sec/batch\n",
      "Epoch 35/50 Iteration: 622800 Avg. Training loss: 1.2271 0.0074 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 623000 Avg. Training loss: 0.8783 0.0073 sec/batch\n",
      "Epoch 35/50 Iteration: 623200 Avg. Training loss: 1.1347 0.0078 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 623400 Avg. Training loss: 0.7944 0.0071 sec/batch\n",
      "Epoch 35/50 Iteration: 623600 Avg. Training loss: 1.0821 0.0074 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 623800 Avg. Training loss: 1.0419 0.0076 sec/batch\n",
      "Epoch 35/50 Iteration: 624000 Avg. Training loss: 1.1120 0.0074 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 624200 Avg. Training loss: 1.4543 0.0081 sec/batch\n",
      "Epoch 35/50 Iteration: 624400 Avg. Training loss: 1.1318 0.0074 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 624600 Avg. Training loss: 1.2660 0.0079 sec/batch\n",
      "Epoch 35/50 Iteration: 624800 Avg. Training loss: 1.0135 0.0073 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 625000 Avg. Training loss: 1.2245 0.0076 sec/batch\n",
      "Epoch 35/50 Iteration: 625200 Avg. Training loss: 0.9047 0.0075 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 625400 Avg. Training loss: 1.2498 0.0073 sec/batch\n",
      "Epoch 35/50 Iteration: 625600 Avg. Training loss: 1.0333 0.0073 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 625800 Avg. Training loss: 1.3300 0.0076 sec/batch\n",
      "Epoch 35/50 Iteration: 626000 Avg. Training loss: 1.4539 0.0075 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 626200 Avg. Training loss: 0.7854 0.0077 sec/batch\n",
      "Epoch 35/50 Iteration: 626400 Avg. Training loss: 1.2075 0.0073 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 626600 Avg. Training loss: 0.8578 0.0072 sec/batch\n",
      "Epoch 35/50 Iteration: 626800 Avg. Training loss: 1.0050 0.0072 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 627000 Avg. Training loss: 1.4230 0.0088 sec/batch\n",
      "Epoch 35/50 Iteration: 627200 Avg. Training loss: 1.0916 0.0078 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 627400 Avg. Training loss: 1.4395 0.0072 sec/batch\n",
      "Epoch 35/50 Iteration: 627600 Avg. Training loss: 0.9686 0.0073 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 627800 Avg. Training loss: 1.1978 0.0074 sec/batch\n",
      "Epoch 35/50 Iteration: 628000 Avg. Training loss: 1.3473 0.0081 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 628200 Avg. Training loss: 1.3435 0.0081 sec/batch\n",
      "Epoch 35/50 Iteration: 628400 Avg. Training loss: 0.4802 0.0073 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 628600 Avg. Training loss: 1.0408 0.0075 sec/batch\n",
      "Epoch 35/50 Iteration: 628800 Avg. Training loss: 1.4434 0.0076 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 629000 Avg. Training loss: 1.2943 0.0079 sec/batch\n",
      "Epoch 35/50 Iteration: 629200 Avg. Training loss: 1.1824 0.0077 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 629400 Avg. Training loss: 1.2151 0.0075 sec/batch\n",
      "Epoch 35/50 Iteration: 629600 Avg. Training loss: 1.0236 0.0073 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 629800 Avg. Training loss: 0.9691 0.0079 sec/batch\n",
      "Epoch 35/50 Iteration: 630000 Avg. Training loss: 1.0310 0.0077 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 630200 Avg. Training loss: 1.0423 0.0076 sec/batch\n",
      "Epoch 35/50 Iteration: 630400 Avg. Training loss: 0.7782 0.0073 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 630600 Avg. Training loss: 0.7824 0.0075 sec/batch\n",
      "Epoch 35/50 Iteration: 630800 Avg. Training loss: 0.9013 0.0075 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 631000 Avg. Training loss: 1.1156 0.0076 sec/batch\n",
      "Epoch 35/50 Iteration: 631200 Avg. Training loss: 1.3060 0.0075 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 631400 Avg. Training loss: 0.8713 0.0080 sec/batch\n",
      "Epoch 35/50 Iteration: 631600 Avg. Training loss: 1.5724 0.0084 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 631800 Avg. Training loss: 0.9508 0.0075 sec/batch\n",
      "Epoch 35/50 Iteration: 632000 Avg. Training loss: 1.0415 0.0089 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 632200 Avg. Training loss: 0.9381 0.0077 sec/batch\n",
      "Epoch 35/50 Iteration: 632400 Avg. Training loss: 1.3013 0.0077 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 632600 Avg. Training loss: 1.1455 0.0075 sec/batch\n",
      "Epoch 35/50 Iteration: 632800 Avg. Training loss: 1.3925 0.0077 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 633000 Avg. Training loss: 1.4033 0.0076 sec/batch\n",
      "Epoch 35/50 Iteration: 633200 Avg. Training loss: 1.0974 0.0075 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 Iteration: 633400 Avg. Training loss: 1.2208 0.0074 sec/batch\n",
      "Epoch 35/50 Iteration: 633600 Avg. Training loss: 1.0932 0.0072 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 633800 Avg. Training loss: 1.3924 0.0077 sec/batch\n",
      "Epoch 35/50 Iteration: 634000 Avg. Training loss: 1.1274 0.0080 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 634200 Avg. Training loss: 1.1599 0.0080 sec/batch\n",
      "Epoch 35/50 Iteration: 634400 Avg. Training loss: 1.1825 0.0072 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 634600 Avg. Training loss: 1.1389 0.0076 sec/batch\n",
      "Epoch 35/50 Iteration: 634800 Avg. Training loss: 1.5771 0.0077 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 635000 Avg. Training loss: 1.0044 0.0075 sec/batch\n",
      "Epoch 35/50 Iteration: 635200 Avg. Training loss: 1.0250 0.0073 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 635400 Avg. Training loss: 0.9205 0.0072 sec/batch\n",
      "Epoch 35/50 Iteration: 635600 Avg. Training loss: 1.5301 0.0081 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 635800 Avg. Training loss: 1.3904 0.0076 sec/batch\n",
      "Epoch 35/50 Iteration: 636000 Avg. Training loss: 1.0033 0.0071 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 636200 Avg. Training loss: 0.9950 0.0073 sec/batch\n",
      "Epoch 35/50 Iteration: 636400 Avg. Training loss: 1.1132 0.0073 sec/batch\n",
      "error\n",
      "Epoch 35/50 Iteration: 636600 Avg. Training loss: 1.1835 0.0083 sec/batch\n",
      "Epoch 35/50 Iteration: 636800 Avg. Training loss: 1.2239 0.0076 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 637000 Avg. Training loss: 1.3878 0.0043 sec/batch\n",
      "Epoch 36/50 Iteration: 637200 Avg. Training loss: 1.2170 0.0079 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 637400 Avg. Training loss: 1.1171 0.0076 sec/batch\n",
      "Epoch 36/50 Iteration: 637600 Avg. Training loss: 1.0766 0.0075 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 637800 Avg. Training loss: 1.5528 0.0083 sec/batch\n",
      "Epoch 36/50 Iteration: 638000 Avg. Training loss: 1.2277 0.0079 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 638200 Avg. Training loss: 1.2250 0.0076 sec/batch\n",
      "Epoch 36/50 Iteration: 638400 Avg. Training loss: 1.0756 0.0076 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 638600 Avg. Training loss: 1.0002 0.0077 sec/batch\n",
      "Epoch 36/50 Iteration: 638800 Avg. Training loss: 1.3904 0.0072 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 639000 Avg. Training loss: 1.1711 0.0073 sec/batch\n",
      "Epoch 36/50 Iteration: 639200 Avg. Training loss: 1.3216 0.0074 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 639400 Avg. Training loss: 1.1526 0.0080 sec/batch\n",
      "Epoch 36/50 Iteration: 639600 Avg. Training loss: 0.9443 0.0073 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 639800 Avg. Training loss: 1.2434 0.0074 sec/batch\n",
      "Epoch 36/50 Iteration: 640000 Avg. Training loss: 0.9830 0.0074 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 640200 Avg. Training loss: 1.1027 0.0078 sec/batch\n",
      "Epoch 36/50 Iteration: 640400 Avg. Training loss: 1.2072 0.0081 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 640600 Avg. Training loss: 1.4418 0.0074 sec/batch\n",
      "Epoch 36/50 Iteration: 640800 Avg. Training loss: 1.2509 0.0075 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 641000 Avg. Training loss: 1.1166 0.0073 sec/batch\n",
      "Epoch 36/50 Iteration: 641200 Avg. Training loss: 0.8554 0.0072 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 641400 Avg. Training loss: 1.0404 0.0078 sec/batch\n",
      "Epoch 36/50 Iteration: 641600 Avg. Training loss: 0.8219 0.0072 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 641800 Avg. Training loss: 0.9867 0.0074 sec/batch\n",
      "Epoch 36/50 Iteration: 642000 Avg. Training loss: 1.1254 0.0075 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 642200 Avg. Training loss: 1.2699 0.0073 sec/batch\n",
      "Epoch 36/50 Iteration: 642400 Avg. Training loss: 1.5137 0.0081 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 642600 Avg. Training loss: 0.9683 0.0073 sec/batch\n",
      "Epoch 36/50 Iteration: 642800 Avg. Training loss: 0.9240 0.0078 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 643000 Avg. Training loss: 1.0291 0.0073 sec/batch\n",
      "Epoch 36/50 Iteration: 643200 Avg. Training loss: 1.5836 0.0076 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 643400 Avg. Training loss: 0.9470 0.0075 sec/batch\n",
      "Epoch 36/50 Iteration: 643600 Avg. Training loss: 1.1642 0.0073 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 643800 Avg. Training loss: 1.1406 0.0074 sec/batch\n",
      "Epoch 36/50 Iteration: 644000 Avg. Training loss: 1.3976 0.0077 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 644200 Avg. Training loss: 1.3769 0.0076 sec/batch\n",
      "Epoch 36/50 Iteration: 644400 Avg. Training loss: 0.9314 0.0077 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 644600 Avg. Training loss: 1.0119 0.0073 sec/batch\n",
      "Epoch 36/50 Iteration: 644800 Avg. Training loss: 0.8781 0.0072 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 645000 Avg. Training loss: 0.8689 0.0072 sec/batch\n",
      "Epoch 36/50 Iteration: 645200 Avg. Training loss: 1.7011 0.0087 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 645400 Avg. Training loss: 1.1581 0.0077 sec/batch\n",
      "Epoch 36/50 Iteration: 645600 Avg. Training loss: 1.4603 0.0072 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 645800 Avg. Training loss: 1.1085 0.0074 sec/batch\n",
      "Epoch 36/50 Iteration: 646000 Avg. Training loss: 1.2324 0.0074 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 646200 Avg. Training loss: 1.4942 0.0081 sec/batch\n",
      "Epoch 36/50 Iteration: 646400 Avg. Training loss: 1.2876 0.0079 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 646600 Avg. Training loss: 0.7835 0.0072 sec/batch\n",
      "Epoch 36/50 Iteration: 646800 Avg. Training loss: 1.0305 0.0075 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 647000 Avg. Training loss: 1.4013 0.0075 sec/batch\n",
      "Epoch 36/50 Iteration: 647200 Avg. Training loss: 1.0864 0.0077 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 647400 Avg. Training loss: 1.1524 0.0076 sec/batch\n",
      "Epoch 36/50 Iteration: 647600 Avg. Training loss: 1.1058 0.0072 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 647800 Avg. Training loss: 1.2108 0.0073 sec/batch\n",
      "Epoch 36/50 Iteration: 648000 Avg. Training loss: 1.1828 0.0077 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 648200 Avg. Training loss: 1.3673 0.0074 sec/batch\n",
      "Epoch 36/50 Iteration: 648400 Avg. Training loss: 1.0494 0.0073 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 648600 Avg. Training loss: 0.9611 0.0073 sec/batch\n",
      "Epoch 36/50 Iteration: 648800 Avg. Training loss: 1.0111 0.0073 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 649000 Avg. Training loss: 0.8839 0.0074 sec/batch\n",
      "Epoch 36/50 Iteration: 649200 Avg. Training loss: 1.0131 0.0079 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 649400 Avg. Training loss: 1.1835 0.0080 sec/batch\n",
      "Epoch 36/50 Iteration: 649600 Avg. Training loss: 0.7521 0.0082 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 649800 Avg. Training loss: 1.2900 0.0092 sec/batch\n",
      "Epoch 36/50 Iteration: 650000 Avg. Training loss: 1.1735 0.0082 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 650200 Avg. Training loss: 1.0006 0.0091 sec/batch\n",
      "Epoch 36/50 Iteration: 650400 Avg. Training loss: 0.7744 0.0079 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 650600 Avg. Training loss: 1.2951 0.0080 sec/batch\n",
      "Epoch 36/50 Iteration: 650800 Avg. Training loss: 0.9567 0.0078 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 651000 Avg. Training loss: 1.3059 0.0081 sec/batch\n",
      "Epoch 36/50 Iteration: 651200 Avg. Training loss: 1.3687 0.0080 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 651400 Avg. Training loss: 1.3488 0.0080 sec/batch\n",
      "Epoch 36/50 Iteration: 651600 Avg. Training loss: 1.0578 0.0078 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 651800 Avg. Training loss: 1.2589 0.0077 sec/batch\n",
      "Epoch 36/50 Iteration: 652000 Avg. Training loss: 1.2229 0.0080 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 652200 Avg. Training loss: 1.2145 0.0078 sec/batch\n",
      "Epoch 36/50 Iteration: 652400 Avg. Training loss: 1.1634 0.0083 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 652600 Avg. Training loss: 1.1055 0.0078 sec/batch\n",
      "Epoch 36/50 Iteration: 652800 Avg. Training loss: 1.2300 0.0081 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 653000 Avg. Training loss: 1.3603 0.0083 sec/batch\n",
      "Epoch 36/50 Iteration: 653200 Avg. Training loss: 1.1445 0.0080 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 653400 Avg. Training loss: 0.8822 0.0079 sec/batch\n",
      "Epoch 36/50 Iteration: 653600 Avg. Training loss: 1.1005 0.0078 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 653800 Avg. Training loss: 1.5562 0.0088 sec/batch\n",
      "Epoch 36/50 Iteration: 654000 Avg. Training loss: 1.4691 0.0081 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 654200 Avg. Training loss: 1.2501 0.0078 sec/batch\n",
      "Epoch 36/50 Iteration: 654400 Avg. Training loss: 0.9860 0.0079 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 654600 Avg. Training loss: 1.0484 0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 Iteration: 654800 Avg. Training loss: 1.1120 0.0089 sec/batch\n",
      "error\n",
      "Epoch 36/50 Iteration: 655000 Avg. Training loss: 1.3917 0.0082 sec/batch\n",
      "Epoch 37/50 Iteration: 655200 Avg. Training loss: 1.1350 0.0047 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 655400 Avg. Training loss: 1.2759 0.0084 sec/batch\n",
      "Epoch 37/50 Iteration: 655600 Avg. Training loss: 1.0426 0.0078 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 655800 Avg. Training loss: 1.1685 0.0074 sec/batch\n",
      "Epoch 37/50 Iteration: 656000 Avg. Training loss: 1.6370 0.0081 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 656200 Avg. Training loss: 1.4898 0.0075 sec/batch\n",
      "Epoch 37/50 Iteration: 656400 Avg. Training loss: 1.2720 0.0073 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 656600 Avg. Training loss: 1.1035 0.0075 sec/batch\n",
      "Epoch 37/50 Iteration: 656800 Avg. Training loss: 1.1311 0.0073 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 657000 Avg. Training loss: 1.2499 0.0070 sec/batch\n",
      "Epoch 37/50 Iteration: 657200 Avg. Training loss: 1.1348 0.0072 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 657400 Avg. Training loss: 1.2527 0.0073 sec/batch\n",
      "Epoch 37/50 Iteration: 657600 Avg. Training loss: 0.9630 0.0077 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 657800 Avg. Training loss: 0.8602 0.0071 sec/batch\n",
      "Epoch 37/50 Iteration: 658000 Avg. Training loss: 1.0822 0.0073 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 658200 Avg. Training loss: 1.1286 0.0072 sec/batch\n",
      "Epoch 37/50 Iteration: 658400 Avg. Training loss: 1.2425 0.0075 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 658600 Avg. Training loss: 1.1347 0.0080 sec/batch\n",
      "Epoch 37/50 Iteration: 658800 Avg. Training loss: 1.0649 0.0071 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 659000 Avg. Training loss: 1.1813 0.0073 sec/batch\n",
      "Epoch 37/50 Iteration: 659200 Avg. Training loss: 1.0277 0.0070 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 659400 Avg. Training loss: 0.7938 0.0069 sec/batch\n",
      "Epoch 37/50 Iteration: 659600 Avg. Training loss: 1.0023 0.0076 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 659800 Avg. Training loss: 0.6695 0.0069 sec/batch\n",
      "Epoch 37/50 Iteration: 660000 Avg. Training loss: 1.2413 0.0071 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 660200 Avg. Training loss: 1.1141 0.0073 sec/batch\n",
      "Epoch 37/50 Iteration: 660400 Avg. Training loss: 1.0392 0.0071 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 660600 Avg. Training loss: 1.5047 0.0080 sec/batch\n",
      "Epoch 37/50 Iteration: 660800 Avg. Training loss: 1.2777 0.0071 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 661000 Avg. Training loss: 1.1979 0.0076 sec/batch\n",
      "Epoch 37/50 Iteration: 661200 Avg. Training loss: 0.8772 0.0071 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 661400 Avg. Training loss: 1.6876 0.0074 sec/batch\n",
      "Epoch 37/50 Iteration: 661600 Avg. Training loss: 1.0713 0.0073 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 661800 Avg. Training loss: 1.2540 0.0070 sec/batch\n",
      "Epoch 37/50 Iteration: 662000 Avg. Training loss: 1.0577 0.0070 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 662200 Avg. Training loss: 1.4742 0.0074 sec/batch\n",
      "Epoch 37/50 Iteration: 662400 Avg. Training loss: 1.1173 0.0074 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 662600 Avg. Training loss: 0.8297 0.0075 sec/batch\n",
      "Epoch 37/50 Iteration: 662800 Avg. Training loss: 1.2136 0.0071 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 663000 Avg. Training loss: 1.1071 0.0072 sec/batch\n",
      "Epoch 37/50 Iteration: 663200 Avg. Training loss: 0.9583 0.0071 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 663400 Avg. Training loss: 1.5921 0.0086 sec/batch\n",
      "Epoch 37/50 Iteration: 663600 Avg. Training loss: 1.1253 0.0075 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 663800 Avg. Training loss: 1.2894 0.0070 sec/batch\n",
      "Epoch 37/50 Iteration: 664000 Avg. Training loss: 0.9856 0.0074 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 664200 Avg. Training loss: 1.0830 0.0075 sec/batch\n",
      "Epoch 37/50 Iteration: 664400 Avg. Training loss: 1.3619 0.0082 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 664600 Avg. Training loss: 1.2845 0.0081 sec/batch\n",
      "Epoch 37/50 Iteration: 664800 Avg. Training loss: 0.7529 0.0074 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 665000 Avg. Training loss: 1.2037 0.0075 sec/batch\n",
      "Epoch 37/50 Iteration: 665200 Avg. Training loss: 1.4666 0.0076 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 665400 Avg. Training loss: 1.3076 0.0081 sec/batch\n",
      "Epoch 37/50 Iteration: 665600 Avg. Training loss: 1.4027 0.0080 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 665800 Avg. Training loss: 1.0049 0.0073 sec/batch\n",
      "Epoch 37/50 Iteration: 666000 Avg. Training loss: 1.0585 0.0072 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 666200 Avg. Training loss: 1.0478 0.0079 sec/batch\n",
      "Epoch 37/50 Iteration: 666400 Avg. Training loss: 1.2860 0.0074 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 666600 Avg. Training loss: 1.1128 0.0074 sec/batch\n",
      "Epoch 37/50 Iteration: 666800 Avg. Training loss: 0.9114 0.0074 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 667000 Avg. Training loss: 0.9590 0.0074 sec/batch\n",
      "Epoch 37/50 Iteration: 667200 Avg. Training loss: 0.8182 0.0074 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 667400 Avg. Training loss: 0.9436 0.0075 sec/batch\n",
      "Epoch 37/50 Iteration: 667600 Avg. Training loss: 1.1658 0.0075 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 667800 Avg. Training loss: 0.9313 0.0079 sec/batch\n",
      "Epoch 37/50 Iteration: 668000 Avg. Training loss: 1.5738 0.0083 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 668200 Avg. Training loss: 1.3176 0.0075 sec/batch\n",
      "Epoch 37/50 Iteration: 668400 Avg. Training loss: 1.0419 0.0088 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 668600 Avg. Training loss: 0.8796 0.0076 sec/batch\n",
      "Epoch 37/50 Iteration: 668800 Avg. Training loss: 1.4405 0.0077 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 669000 Avg. Training loss: 1.3855 0.0076 sec/batch\n",
      "Epoch 37/50 Iteration: 669200 Avg. Training loss: 1.3191 0.0079 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 669400 Avg. Training loss: 1.2972 0.0077 sec/batch\n",
      "Epoch 37/50 Iteration: 669600 Avg. Training loss: 1.2480 0.0076 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 669800 Avg. Training loss: 1.0242 0.0074 sec/batch\n",
      "Epoch 37/50 Iteration: 670000 Avg. Training loss: 1.2559 0.0073 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 670200 Avg. Training loss: 1.3682 0.0076 sec/batch\n",
      "Epoch 37/50 Iteration: 670400 Avg. Training loss: 1.0158 0.0075 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 670600 Avg. Training loss: 1.3970 0.0082 sec/batch\n",
      "Epoch 37/50 Iteration: 670800 Avg. Training loss: 0.9190 0.0073 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 671000 Avg. Training loss: 1.3918 0.0081 sec/batch\n",
      "Epoch 37/50 Iteration: 671200 Avg. Training loss: 1.4235 0.0081 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 671400 Avg. Training loss: 0.8383 0.0076 sec/batch\n",
      "Epoch 37/50 Iteration: 671600 Avg. Training loss: 0.8767 0.0074 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 671800 Avg. Training loss: 1.1605 0.0072 sec/batch\n",
      "Epoch 37/50 Iteration: 672000 Avg. Training loss: 1.5187 0.0082 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 672200 Avg. Training loss: 1.2865 0.0077 sec/batch\n",
      "Epoch 37/50 Iteration: 672400 Avg. Training loss: 1.1608 0.0073 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 672600 Avg. Training loss: 0.7766 0.0075 sec/batch\n",
      "Epoch 37/50 Iteration: 672800 Avg. Training loss: 1.0751 0.0076 sec/batch\n",
      "error\n",
      "Epoch 37/50 Iteration: 673000 Avg. Training loss: 1.0179 0.0084 sec/batch\n",
      "Epoch 37/50 Iteration: 673200 Avg. Training loss: 1.3469 0.0076 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 673400 Avg. Training loss: 1.5967 0.0045 sec/batch\n",
      "Epoch 38/50 Iteration: 673600 Avg. Training loss: 1.3949 0.0080 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 673800 Avg. Training loss: 1.0482 0.0077 sec/batch\n",
      "Epoch 38/50 Iteration: 674000 Avg. Training loss: 1.1554 0.0079 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 674200 Avg. Training loss: 1.7100 0.0084 sec/batch\n",
      "Epoch 38/50 Iteration: 674400 Avg. Training loss: 1.1511 0.0077 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 674600 Avg. Training loss: 1.5026 0.0078 sec/batch\n",
      "Epoch 38/50 Iteration: 674800 Avg. Training loss: 1.0481 0.0077 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 675000 Avg. Training loss: 1.0187 0.0079 sec/batch\n",
      "Epoch 38/50 Iteration: 675200 Avg. Training loss: 1.1599 0.0074 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 675400 Avg. Training loss: 1.1629 0.0075 sec/batch\n",
      "Epoch 38/50 Iteration: 675600 Avg. Training loss: 1.4064 0.0077 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 675800 Avg. Training loss: 0.9963 0.0082 sec/batch\n",
      "Epoch 38/50 Iteration: 676000 Avg. Training loss: 1.0055 0.0074 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 Iteration: 676200 Avg. Training loss: 1.2619 0.0076 sec/batch\n",
      "Epoch 38/50 Iteration: 676400 Avg. Training loss: 1.2295 0.0077 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 676600 Avg. Training loss: 1.1737 0.0079 sec/batch\n",
      "Epoch 38/50 Iteration: 676800 Avg. Training loss: 1.3192 0.0083 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 677000 Avg. Training loss: 1.3256 0.0075 sec/batch\n",
      "Epoch 38/50 Iteration: 677200 Avg. Training loss: 1.3332 0.0076 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 677400 Avg. Training loss: 1.0533 0.0075 sec/batch\n",
      "Epoch 38/50 Iteration: 677600 Avg. Training loss: 1.0745 0.0073 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 677800 Avg. Training loss: 1.0876 0.0079 sec/batch\n",
      "Epoch 38/50 Iteration: 678000 Avg. Training loss: 0.8265 0.0073 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 678200 Avg. Training loss: 0.9001 0.0075 sec/batch\n",
      "Epoch 38/50 Iteration: 678400 Avg. Training loss: 1.0418 0.0075 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 678600 Avg. Training loss: 0.8810 0.0076 sec/batch\n",
      "Epoch 38/50 Iteration: 678800 Avg. Training loss: 1.6766 0.0082 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 679000 Avg. Training loss: 1.3965 0.0075 sec/batch\n",
      "Epoch 38/50 Iteration: 679200 Avg. Training loss: 1.2047 0.0080 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 679400 Avg. Training loss: 0.8041 0.0074 sec/batch\n",
      "Epoch 38/50 Iteration: 679600 Avg. Training loss: 1.2337 0.0079 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 679800 Avg. Training loss: 1.0176 0.0077 sec/batch\n",
      "Epoch 38/50 Iteration: 680000 Avg. Training loss: 1.2774 0.0074 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 680200 Avg. Training loss: 1.1259 0.0075 sec/batch\n",
      "Epoch 38/50 Iteration: 680400 Avg. Training loss: 1.3390 0.0079 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 680600 Avg. Training loss: 1.4134 0.0076 sec/batch\n",
      "Epoch 38/50 Iteration: 680800 Avg. Training loss: 0.8684 0.0078 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 681000 Avg. Training loss: 1.1775 0.0081 sec/batch\n",
      "Epoch 38/50 Iteration: 681200 Avg. Training loss: 0.7713 0.0077 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 681400 Avg. Training loss: 0.8408 0.0073 sec/batch\n",
      "Epoch 38/50 Iteration: 681600 Avg. Training loss: 1.4563 0.0090 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 681800 Avg. Training loss: 1.0782 0.0078 sec/batch\n",
      "Epoch 38/50 Iteration: 682000 Avg. Training loss: 1.3664 0.0073 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 682200 Avg. Training loss: 1.3464 0.0075 sec/batch\n",
      "Epoch 38/50 Iteration: 682400 Avg. Training loss: 1.2304 0.0074 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 682600 Avg. Training loss: 1.5275 0.0082 sec/batch\n",
      "Epoch 38/50 Iteration: 682800 Avg. Training loss: 1.4020 0.0082 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 683000 Avg. Training loss: 0.6556 0.0074 sec/batch\n",
      "Epoch 38/50 Iteration: 683200 Avg. Training loss: 1.1243 0.0076 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 683400 Avg. Training loss: 1.6187 0.0076 sec/batch\n",
      "Epoch 38/50 Iteration: 683600 Avg. Training loss: 1.2547 0.0079 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 683800 Avg. Training loss: 1.3354 0.0078 sec/batch\n",
      "Epoch 38/50 Iteration: 684000 Avg. Training loss: 1.0977 0.0073 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 684200 Avg. Training loss: 1.1304 0.0074 sec/batch\n",
      "Epoch 38/50 Iteration: 684400 Avg. Training loss: 1.0014 0.0080 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 684600 Avg. Training loss: 1.2005 0.0076 sec/batch\n",
      "Epoch 38/50 Iteration: 684800 Avg. Training loss: 0.9775 0.0075 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 685000 Avg. Training loss: 1.0019 0.0073 sec/batch\n",
      "Epoch 38/50 Iteration: 685200 Avg. Training loss: 0.9516 0.0074 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 685400 Avg. Training loss: 0.9171 0.0074 sec/batch\n",
      "Epoch 38/50 Iteration: 685600 Avg. Training loss: 1.0879 0.0075 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 685800 Avg. Training loss: 1.1119 0.0077 sec/batch\n",
      "Epoch 38/50 Iteration: 686000 Avg. Training loss: 1.0115 0.0080 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 686200 Avg. Training loss: 1.2912 0.0083 sec/batch\n",
      "Epoch 38/50 Iteration: 686400 Avg. Training loss: 1.3269 0.0076 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 686600 Avg. Training loss: 1.0191 0.0088 sec/batch\n",
      "Epoch 38/50 Iteration: 686800 Avg. Training loss: 0.9567 0.0076 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 687000 Avg. Training loss: 1.2819 0.0077 sec/batch\n",
      "Epoch 38/50 Iteration: 687200 Avg. Training loss: 1.0076 0.0075 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 687400 Avg. Training loss: 1.3592 0.0079 sec/batch\n",
      "Epoch 38/50 Iteration: 687600 Avg. Training loss: 1.4520 0.0077 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 687800 Avg. Training loss: 1.3850 0.0078 sec/batch\n",
      "Epoch 38/50 Iteration: 688000 Avg. Training loss: 1.0356 0.0074 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 688200 Avg. Training loss: 1.2564 0.0073 sec/batch\n",
      "Epoch 38/50 Iteration: 688400 Avg. Training loss: 1.1484 0.0077 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 688600 Avg. Training loss: 1.2305 0.0074 sec/batch\n",
      "Epoch 38/50 Iteration: 688800 Avg. Training loss: 1.5006 0.0080 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 689000 Avg. Training loss: 1.0578 0.0071 sec/batch\n",
      "Epoch 38/50 Iteration: 689200 Avg. Training loss: 1.3143 0.0077 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 689400 Avg. Training loss: 1.3950 0.0078 sec/batch\n",
      "Epoch 38/50 Iteration: 689600 Avg. Training loss: 1.2322 0.0075 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 689800 Avg. Training loss: 0.9625 0.0075 sec/batch\n",
      "Epoch 38/50 Iteration: 690000 Avg. Training loss: 0.9484 0.0075 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 690200 Avg. Training loss: 1.5588 0.0085 sec/batch\n",
      "Epoch 38/50 Iteration: 690400 Avg. Training loss: 1.5129 0.0078 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 690600 Avg. Training loss: 1.0025 0.0075 sec/batch\n",
      "Epoch 38/50 Iteration: 690800 Avg. Training loss: 1.0725 0.0075 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 691000 Avg. Training loss: 0.9952 0.0076 sec/batch\n",
      "Epoch 38/50 Iteration: 691200 Avg. Training loss: 1.0031 0.0084 sec/batch\n",
      "error\n",
      "Epoch 38/50 Iteration: 691400 Avg. Training loss: 1.3711 0.0077 sec/batch\n",
      "Epoch 39/50 Iteration: 691600 Avg. Training loss: 1.3638 0.0047 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 691800 Avg. Training loss: 1.2720 0.0080 sec/batch\n",
      "Epoch 39/50 Iteration: 692000 Avg. Training loss: 0.9140 0.0077 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 692200 Avg. Training loss: 1.2828 0.0078 sec/batch\n",
      "Epoch 39/50 Iteration: 692400 Avg. Training loss: 1.5767 0.0083 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 692600 Avg. Training loss: 1.2525 0.0079 sec/batch\n",
      "Epoch 39/50 Iteration: 692800 Avg. Training loss: 1.3977 0.0077 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 693000 Avg. Training loss: 0.9915 0.0079 sec/batch\n",
      "Epoch 39/50 Iteration: 693200 Avg. Training loss: 1.2977 0.0078 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 693400 Avg. Training loss: 1.1806 0.0073 sec/batch\n",
      "Epoch 39/50 Iteration: 693600 Avg. Training loss: 1.1141 0.0075 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 693800 Avg. Training loss: 1.3844 0.0076 sec/batch\n",
      "Epoch 39/50 Iteration: 694000 Avg. Training loss: 1.0242 0.0082 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 694200 Avg. Training loss: 0.7786 0.0076 sec/batch\n",
      "Epoch 39/50 Iteration: 694400 Avg. Training loss: 1.4370 0.0075 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 694600 Avg. Training loss: 1.1819 0.0075 sec/batch\n",
      "Epoch 39/50 Iteration: 694800 Avg. Training loss: 1.1443 0.0079 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 695000 Avg. Training loss: 1.1542 0.0082 sec/batch\n",
      "Epoch 39/50 Iteration: 695200 Avg. Training loss: 1.3396 0.0075 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 695400 Avg. Training loss: 1.2316 0.0076 sec/batch\n",
      "Epoch 39/50 Iteration: 695600 Avg. Training loss: 0.9216 0.0075 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 695800 Avg. Training loss: 0.7589 0.0073 sec/batch\n",
      "Epoch 39/50 Iteration: 696000 Avg. Training loss: 1.0476 0.0078 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 696200 Avg. Training loss: 0.7238 0.0074 sec/batch\n",
      "Epoch 39/50 Iteration: 696400 Avg. Training loss: 1.1395 0.0076 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 696600 Avg. Training loss: 1.0460 0.0078 sec/batch\n",
      "Epoch 39/50 Iteration: 696800 Avg. Training loss: 1.0221 0.0079 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 697000 Avg. Training loss: 1.6122 0.0084 sec/batch\n",
      "Epoch 39/50 Iteration: 697200 Avg. Training loss: 1.4657 0.0075 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 697400 Avg. Training loss: 1.1892 0.0080 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 Iteration: 697600 Avg. Training loss: 0.8512 0.0075 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 697800 Avg. Training loss: 1.5090 0.0078 sec/batch\n",
      "Epoch 39/50 Iteration: 698000 Avg. Training loss: 0.9676 0.0075 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 698200 Avg. Training loss: 1.4315 0.0074 sec/batch\n",
      "Epoch 39/50 Iteration: 698400 Avg. Training loss: 1.3034 0.0073 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 698600 Avg. Training loss: 1.2973 0.0078 sec/batch\n",
      "Epoch 39/50 Iteration: 698800 Avg. Training loss: 1.2850 0.0076 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 699000 Avg. Training loss: 0.8089 0.0077 sec/batch\n",
      "Epoch 39/50 Iteration: 699200 Avg. Training loss: 1.2048 0.0073 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 699400 Avg. Training loss: 0.7901 0.0073 sec/batch\n",
      "Epoch 39/50 Iteration: 699600 Avg. Training loss: 0.9859 0.0073 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 699800 Avg. Training loss: 1.6895 0.0089 sec/batch\n",
      "Epoch 39/50 Iteration: 700000 Avg. Training loss: 1.2182 0.0076 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 700200 Avg. Training loss: 1.4829 0.0072 sec/batch\n",
      "Epoch 39/50 Iteration: 700400 Avg. Training loss: 1.3083 0.0074 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 700600 Avg. Training loss: 1.1059 0.0074 sec/batch\n",
      "Epoch 39/50 Iteration: 700800 Avg. Training loss: 1.3974 0.0084 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 701000 Avg. Training loss: 1.3403 0.0082 sec/batch\n",
      "Epoch 39/50 Iteration: 701200 Avg. Training loss: 0.8613 0.0073 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 701400 Avg. Training loss: 1.0111 0.0074 sec/batch\n",
      "Epoch 39/50 Iteration: 701600 Avg. Training loss: 1.3573 0.0077 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 701800 Avg. Training loss: 1.2357 0.0079 sec/batch\n",
      "Epoch 39/50 Iteration: 702000 Avg. Training loss: 1.3129 0.0077 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 702200 Avg. Training loss: 1.0939 0.0072 sec/batch\n",
      "Epoch 39/50 Iteration: 702400 Avg. Training loss: 1.2530 0.0071 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 702600 Avg. Training loss: 1.1701 0.0079 sec/batch\n",
      "Epoch 39/50 Iteration: 702800 Avg. Training loss: 1.2521 0.0075 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 703000 Avg. Training loss: 1.4273 0.0074 sec/batch\n",
      "Epoch 39/50 Iteration: 703200 Avg. Training loss: 1.0969 0.0072 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 703400 Avg. Training loss: 0.8917 0.0073 sec/batch\n",
      "Epoch 39/50 Iteration: 703600 Avg. Training loss: 0.8244 0.0074 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 703800 Avg. Training loss: 1.0314 0.0075 sec/batch\n",
      "Epoch 39/50 Iteration: 704000 Avg. Training loss: 1.1615 0.0075 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 704200 Avg. Training loss: 0.9043 0.0080 sec/batch\n",
      "Epoch 39/50 Iteration: 704400 Avg. Training loss: 1.4638 0.0082 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 704600 Avg. Training loss: 1.3178 0.0075 sec/batch\n",
      "Epoch 39/50 Iteration: 704800 Avg. Training loss: 0.9456 0.0086 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 705000 Avg. Training loss: 0.9047 0.0076 sec/batch\n",
      "Epoch 39/50 Iteration: 705200 Avg. Training loss: 1.1955 0.0076 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 705400 Avg. Training loss: 1.1697 0.0074 sec/batch\n",
      "Epoch 39/50 Iteration: 705600 Avg. Training loss: 1.4306 0.0077 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 705800 Avg. Training loss: 1.3755 0.0077 sec/batch\n",
      "Epoch 39/50 Iteration: 706000 Avg. Training loss: 1.1918 0.0078 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 706200 Avg. Training loss: 1.2066 0.0075 sec/batch\n",
      "Epoch 39/50 Iteration: 706400 Avg. Training loss: 1.3152 0.0072 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 706600 Avg. Training loss: 1.1923 0.0076 sec/batch\n",
      "Epoch 39/50 Iteration: 706800 Avg. Training loss: 1.2055 0.0075 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 707000 Avg. Training loss: 1.3359 0.0080 sec/batch\n",
      "Epoch 39/50 Iteration: 707200 Avg. Training loss: 0.9911 0.0073 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 707400 Avg. Training loss: 1.2159 0.0077 sec/batch\n",
      "Epoch 39/50 Iteration: 707600 Avg. Training loss: 1.2612 0.0079 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 707800 Avg. Training loss: 0.9921 0.0076 sec/batch\n",
      "Epoch 39/50 Iteration: 708000 Avg. Training loss: 0.7762 0.0072 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 708200 Avg. Training loss: 0.9686 0.0072 sec/batch\n",
      "Epoch 39/50 Iteration: 708400 Avg. Training loss: 1.8321 0.0084 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 708600 Avg. Training loss: 1.4993 0.0076 sec/batch\n",
      "Epoch 39/50 Iteration: 708800 Avg. Training loss: 1.3023 0.0072 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 709000 Avg. Training loss: 0.9231 0.0075 sec/batch\n",
      "Epoch 39/50 Iteration: 709200 Avg. Training loss: 1.0612 0.0075 sec/batch\n",
      "error\n",
      "Epoch 39/50 Iteration: 709400 Avg. Training loss: 1.0584 0.0084 sec/batch\n",
      "Epoch 39/50 Iteration: 709600 Avg. Training loss: 1.4374 0.0076 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 709800 Avg. Training loss: 1.2953 0.0048 sec/batch\n",
      "Epoch 40/50 Iteration: 710000 Avg. Training loss: 1.4067 0.0217 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 710200 Avg. Training loss: 1.0637 0.0087 sec/batch\n",
      "Epoch 40/50 Iteration: 710400 Avg. Training loss: 1.3982 0.0078 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 710600 Avg. Training loss: 1.5953 0.0084 sec/batch\n",
      "Epoch 40/50 Iteration: 710800 Avg. Training loss: 1.2031 0.0078 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 711000 Avg. Training loss: 1.1867 0.0080 sec/batch\n",
      "Epoch 40/50 Iteration: 711200 Avg. Training loss: 1.3115 0.0082 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 711400 Avg. Training loss: 1.2858 0.0083 sec/batch\n",
      "Epoch 40/50 Iteration: 711600 Avg. Training loss: 1.4763 0.0077 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 711800 Avg. Training loss: 1.2360 0.0080 sec/batch\n",
      "Epoch 40/50 Iteration: 712000 Avg. Training loss: 1.2514 0.0084 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 712200 Avg. Training loss: 1.0285 0.0086 sec/batch\n",
      "Epoch 40/50 Iteration: 712400 Avg. Training loss: 0.7738 0.0079 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 712600 Avg. Training loss: 1.3021 0.0080 sec/batch\n",
      "Epoch 40/50 Iteration: 712800 Avg. Training loss: 1.2219 0.0080 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 713000 Avg. Training loss: 1.2132 0.0085 sec/batch\n",
      "Epoch 40/50 Iteration: 713200 Avg. Training loss: 1.0340 0.0087 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 713400 Avg. Training loss: 1.4822 0.0080 sec/batch\n",
      "Epoch 40/50 Iteration: 713600 Avg. Training loss: 1.3410 0.0080 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 713800 Avg. Training loss: 1.0244 0.0076 sec/batch\n",
      "Epoch 40/50 Iteration: 714000 Avg. Training loss: 1.0436 0.0076 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 714200 Avg. Training loss: 1.2453 0.0082 sec/batch\n",
      "Epoch 40/50 Iteration: 714400 Avg. Training loss: 0.6958 0.0076 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 714600 Avg. Training loss: 0.7393 0.0078 sec/batch\n",
      "Epoch 40/50 Iteration: 714800 Avg. Training loss: 1.1308 0.0078 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 715000 Avg. Training loss: 1.0496 0.0077 sec/batch\n",
      "Epoch 40/50 Iteration: 715200 Avg. Training loss: 1.6338 0.0085 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 715400 Avg. Training loss: 1.3166 0.0079 sec/batch\n",
      "Epoch 40/50 Iteration: 715600 Avg. Training loss: 1.1477 0.0081 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 715800 Avg. Training loss: 0.7989 0.0077 sec/batch\n",
      "Epoch 40/50 Iteration: 716000 Avg. Training loss: 1.5060 0.0080 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 716200 Avg. Training loss: 1.1335 0.0079 sec/batch\n",
      "Epoch 40/50 Iteration: 716400 Avg. Training loss: 1.1323 0.0077 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 716600 Avg. Training loss: 1.2751 0.0078 sec/batch\n",
      "Epoch 40/50 Iteration: 716800 Avg. Training loss: 1.6654 0.0081 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 717000 Avg. Training loss: 1.5509 0.0080 sec/batch\n",
      "Epoch 40/50 Iteration: 717200 Avg. Training loss: 0.9531 0.0080 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 717400 Avg. Training loss: 1.1889 0.0077 sec/batch\n",
      "Epoch 40/50 Iteration: 717600 Avg. Training loss: 0.8097 0.0076 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 717800 Avg. Training loss: 0.9701 0.0076 sec/batch\n",
      "Epoch 40/50 Iteration: 718000 Avg. Training loss: 1.7298 0.0093 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 718200 Avg. Training loss: 1.1785 0.0080 sec/batch\n",
      "Epoch 40/50 Iteration: 718400 Avg. Training loss: 1.2190 0.0075 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 718600 Avg. Training loss: 0.9976 0.0077 sec/batch\n",
      "Epoch 40/50 Iteration: 718800 Avg. Training loss: 1.3484 0.0078 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 Iteration: 719000 Avg. Training loss: 1.4706 0.0085 sec/batch\n",
      "Epoch 40/50 Iteration: 719200 Avg. Training loss: 1.4545 0.0084 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 719400 Avg. Training loss: 0.5390 0.0076 sec/batch\n",
      "Epoch 40/50 Iteration: 719600 Avg. Training loss: 1.2275 0.0078 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 719800 Avg. Training loss: 1.4967 0.0079 sec/batch\n",
      "Epoch 40/50 Iteration: 720000 Avg. Training loss: 1.3267 0.0081 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 720200 Avg. Training loss: 1.3563 0.0080 sec/batch\n",
      "Epoch 40/50 Iteration: 720400 Avg. Training loss: 1.1160 0.0076 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 720600 Avg. Training loss: 1.0151 0.0075 sec/batch\n",
      "Epoch 40/50 Iteration: 720800 Avg. Training loss: 1.1595 0.0082 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 721000 Avg. Training loss: 1.1735 0.0079 sec/batch\n",
      "Epoch 40/50 Iteration: 721200 Avg. Training loss: 1.1798 0.0078 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 721400 Avg. Training loss: 0.8334 0.0076 sec/batch\n",
      "Epoch 40/50 Iteration: 721600 Avg. Training loss: 0.8695 0.0077 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 721800 Avg. Training loss: 0.6193 0.0077 sec/batch\n",
      "Epoch 40/50 Iteration: 722000 Avg. Training loss: 0.8908 0.0078 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 722200 Avg. Training loss: 1.3701 0.0078 sec/batch\n",
      "Epoch 40/50 Iteration: 722400 Avg. Training loss: 0.9236 0.0083 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 722600 Avg. Training loss: 1.4798 0.0086 sec/batch\n",
      "Epoch 40/50 Iteration: 722800 Avg. Training loss: 1.2698 0.0079 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 723000 Avg. Training loss: 0.9343 0.0090 sec/batch\n",
      "Epoch 40/50 Iteration: 723200 Avg. Training loss: 0.9239 0.0078 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 723400 Avg. Training loss: 1.3058 0.0080 sec/batch\n",
      "Epoch 40/50 Iteration: 723600 Avg. Training loss: 1.3126 0.0078 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 723800 Avg. Training loss: 1.3712 0.0080 sec/batch\n",
      "Epoch 40/50 Iteration: 724000 Avg. Training loss: 1.3391 0.0079 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 724200 Avg. Training loss: 1.1483 0.0079 sec/batch\n",
      "Epoch 40/50 Iteration: 724400 Avg. Training loss: 1.0622 0.0077 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 724600 Avg. Training loss: 1.3546 0.0076 sec/batch\n",
      "Epoch 40/50 Iteration: 724800 Avg. Training loss: 1.3201 0.0078 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 725000 Avg. Training loss: 1.2236 0.0077 sec/batch\n",
      "Epoch 40/50 Iteration: 725200 Avg. Training loss: 1.2798 0.0080 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 725400 Avg. Training loss: 1.1922 0.0076 sec/batch\n",
      "Epoch 40/50 Iteration: 725600 Avg. Training loss: 1.1923 0.0080 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 725800 Avg. Training loss: 1.3856 0.0081 sec/batch\n",
      "Epoch 40/50 Iteration: 726000 Avg. Training loss: 0.9466 0.0078 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 726200 Avg. Training loss: 1.0559 0.0077 sec/batch\n",
      "Epoch 40/50 Iteration: 726400 Avg. Training loss: 0.9780 0.0076 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 726600 Avg. Training loss: 1.9516 0.0088 sec/batch\n",
      "Epoch 40/50 Iteration: 726800 Avg. Training loss: 1.4617 0.0079 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 727000 Avg. Training loss: 1.3698 0.0085 sec/batch\n",
      "Epoch 40/50 Iteration: 727200 Avg. Training loss: 0.9426 0.0083 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 727400 Avg. Training loss: 1.1027 0.0081 sec/batch\n",
      "Epoch 40/50 Iteration: 727600 Avg. Training loss: 1.1795 0.0088 sec/batch\n",
      "error\n",
      "Epoch 40/50 Iteration: 727800 Avg. Training loss: 1.1099 0.0082 sec/batch\n",
      "Epoch 41/50 Iteration: 728000 Avg. Training loss: 1.4895 0.0056 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 728200 Avg. Training loss: 1.3519 0.0090 sec/batch\n",
      "Epoch 41/50 Iteration: 728400 Avg. Training loss: 1.1819 0.0084 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 728600 Avg. Training loss: 1.2974 0.0082 sec/batch\n",
      "Epoch 41/50 Iteration: 728800 Avg. Training loss: 1.5226 0.0087 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 729000 Avg. Training loss: 0.9901 0.0081 sec/batch\n",
      "Epoch 41/50 Iteration: 729200 Avg. Training loss: 1.4026 0.0080 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 729400 Avg. Training loss: 1.1818 0.0080 sec/batch\n",
      "Epoch 41/50 Iteration: 729600 Avg. Training loss: 1.1371 0.0080 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 729800 Avg. Training loss: 1.2603 0.0076 sec/batch\n",
      "Epoch 41/50 Iteration: 730000 Avg. Training loss: 1.4197 0.0078 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 730200 Avg. Training loss: 1.2003 0.0079 sec/batch\n",
      "Epoch 41/50 Iteration: 730400 Avg. Training loss: 1.0788 0.0084 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 730600 Avg. Training loss: 0.7396 0.0077 sec/batch\n",
      "Epoch 41/50 Iteration: 730800 Avg. Training loss: 1.2910 0.0076 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 731000 Avg. Training loss: 1.2090 0.0076 sec/batch\n",
      "Epoch 41/50 Iteration: 731200 Avg. Training loss: 1.2183 0.0078 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 731400 Avg. Training loss: 1.2009 0.0080 sec/batch\n",
      "Epoch 41/50 Iteration: 731600 Avg. Training loss: 1.4024 0.0075 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 731800 Avg. Training loss: 1.2826 0.0077 sec/batch\n",
      "Epoch 41/50 Iteration: 732000 Avg. Training loss: 1.0263 0.0073 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 732200 Avg. Training loss: 0.8691 0.0074 sec/batch\n",
      "Epoch 41/50 Iteration: 732400 Avg. Training loss: 1.2683 0.0079 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 732600 Avg. Training loss: 0.7894 0.0073 sec/batch\n",
      "Epoch 41/50 Iteration: 732800 Avg. Training loss: 1.3465 0.0075 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 733000 Avg. Training loss: 1.4811 0.0077 sec/batch\n",
      "Epoch 41/50 Iteration: 733200 Avg. Training loss: 0.9111 0.0076 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 733400 Avg. Training loss: 1.6996 0.0083 sec/batch\n",
      "Epoch 41/50 Iteration: 733600 Avg. Training loss: 1.4106 0.0076 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 733800 Avg. Training loss: 1.1374 0.0080 sec/batch\n",
      "Epoch 41/50 Iteration: 734000 Avg. Training loss: 1.1122 0.0080 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 734200 Avg. Training loss: 1.4207 0.0081 sec/batch\n",
      "Epoch 41/50 Iteration: 734400 Avg. Training loss: 1.1702 0.0076 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 734600 Avg. Training loss: 1.0657 0.0070 sec/batch\n",
      "Epoch 41/50 Iteration: 734800 Avg. Training loss: 1.2184 0.0069 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 735000 Avg. Training loss: 1.4770 0.0074 sec/batch\n",
      "Epoch 41/50 Iteration: 735200 Avg. Training loss: 1.6202 0.0073 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 735400 Avg. Training loss: 0.7132 0.0072 sec/batch\n",
      "Epoch 41/50 Iteration: 735600 Avg. Training loss: 1.3832 0.0069 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 735800 Avg. Training loss: 0.8107 0.0068 sec/batch\n",
      "Epoch 41/50 Iteration: 736000 Avg. Training loss: 1.0034 0.0068 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 736200 Avg. Training loss: 1.7608 0.0089 sec/batch\n",
      "Epoch 41/50 Iteration: 736400 Avg. Training loss: 0.9984 0.0074 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 736600 Avg. Training loss: 1.1781 0.0069 sec/batch\n",
      "Epoch 41/50 Iteration: 736800 Avg. Training loss: 1.2171 0.0069 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 737000 Avg. Training loss: 1.1454 0.0070 sec/batch\n",
      "Epoch 41/50 Iteration: 737200 Avg. Training loss: 1.2639 0.0078 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 737400 Avg. Training loss: 1.2802 0.0074 sec/batch\n",
      "Epoch 41/50 Iteration: 737600 Avg. Training loss: 0.8451 0.0068 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 737800 Avg. Training loss: 1.1770 0.0070 sec/batch\n",
      "Epoch 41/50 Iteration: 738000 Avg. Training loss: 1.3993 0.0072 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 738200 Avg. Training loss: 1.1895 0.0077 sec/batch\n",
      "Epoch 41/50 Iteration: 738400 Avg. Training loss: 1.2602 0.0076 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 738600 Avg. Training loss: 0.9584 0.0068 sec/batch\n",
      "Epoch 41/50 Iteration: 738800 Avg. Training loss: 1.1135 0.0067 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 739000 Avg. Training loss: 1.1954 0.0075 sec/batch\n",
      "Epoch 41/50 Iteration: 739200 Avg. Training loss: 1.0259 0.0070 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 739400 Avg. Training loss: 1.2343 0.0070 sec/batch\n",
      "Epoch 41/50 Iteration: 739600 Avg. Training loss: 0.8192 0.0068 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 739800 Avg. Training loss: 0.8505 0.0069 sec/batch\n",
      "Epoch 41/50 Iteration: 740000 Avg. Training loss: 0.6931 0.0069 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 740200 Avg. Training loss: 1.3797 0.0070 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 Iteration: 740400 Avg. Training loss: 1.3690 0.0070 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 740600 Avg. Training loss: 1.0872 0.0075 sec/batch\n",
      "Epoch 41/50 Iteration: 740800 Avg. Training loss: 1.3101 0.0077 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 741000 Avg. Training loss: 1.2947 0.0071 sec/batch\n",
      "Epoch 41/50 Iteration: 741200 Avg. Training loss: 1.1590 0.0083 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 741400 Avg. Training loss: 1.1132 0.0070 sec/batch\n",
      "Epoch 41/50 Iteration: 741600 Avg. Training loss: 1.4155 0.0071 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 741800 Avg. Training loss: 1.1552 0.0070 sec/batch\n",
      "Epoch 41/50 Iteration: 742000 Avg. Training loss: 1.0159 0.0071 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 742200 Avg. Training loss: 1.4922 0.0071 sec/batch\n",
      "Epoch 41/50 Iteration: 742400 Avg. Training loss: 1.2696 0.0072 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 742600 Avg. Training loss: 1.1429 0.0073 sec/batch\n",
      "Epoch 41/50 Iteration: 742800 Avg. Training loss: 1.1511 0.0073 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 743000 Avg. Training loss: 1.1539 0.0075 sec/batch\n",
      "Epoch 41/50 Iteration: 743200 Avg. Training loss: 1.2090 0.0069 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 743400 Avg. Training loss: 1.4378 0.0076 sec/batch\n",
      "Epoch 41/50 Iteration: 743600 Avg. Training loss: 1.0326 0.0069 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 743800 Avg. Training loss: 1.3671 0.0073 sec/batch\n",
      "Epoch 41/50 Iteration: 744000 Avg. Training loss: 1.3994 0.0074 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 744200 Avg. Training loss: 1.0839 0.0072 sec/batch\n",
      "Epoch 41/50 Iteration: 744400 Avg. Training loss: 0.9821 0.0071 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 744600 Avg. Training loss: 0.9747 0.0070 sec/batch\n",
      "Epoch 41/50 Iteration: 744800 Avg. Training loss: 1.8551 0.0082 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 745000 Avg. Training loss: 1.3919 0.0073 sec/batch\n",
      "Epoch 41/50 Iteration: 745200 Avg. Training loss: 1.1308 0.0069 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 745400 Avg. Training loss: 0.9912 0.0071 sec/batch\n",
      "Epoch 41/50 Iteration: 745600 Avg. Training loss: 1.0159 0.0073 sec/batch\n",
      "error\n",
      "Epoch 41/50 Iteration: 745800 Avg. Training loss: 0.9466 0.0083 sec/batch\n",
      "Epoch 41/50 Iteration: 746000 Avg. Training loss: 1.2184 0.0076 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 746200 Avg. Training loss: 1.4806 0.0050 sec/batch\n",
      "Epoch 42/50 Iteration: 746400 Avg. Training loss: 1.5208 0.0080 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 746600 Avg. Training loss: 1.2486 0.0080 sec/batch\n",
      "Epoch 42/50 Iteration: 746800 Avg. Training loss: 1.3192 0.0079 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 747000 Avg. Training loss: 1.5117 0.0082 sec/batch\n",
      "Epoch 42/50 Iteration: 747200 Avg. Training loss: 1.0870 0.0076 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 747400 Avg. Training loss: 1.3595 0.0077 sec/batch\n",
      "Epoch 42/50 Iteration: 747600 Avg. Training loss: 1.1025 0.0078 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 747800 Avg. Training loss: 1.1220 0.0078 sec/batch\n",
      "Epoch 42/50 Iteration: 748000 Avg. Training loss: 1.4183 0.0074 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 748200 Avg. Training loss: 1.2885 0.0073 sec/batch\n",
      "Epoch 42/50 Iteration: 748400 Avg. Training loss: 1.2810 0.0074 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 748600 Avg. Training loss: 1.1217 0.0080 sec/batch\n",
      "Epoch 42/50 Iteration: 748800 Avg. Training loss: 0.9968 0.0074 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 749000 Avg. Training loss: 1.3203 0.0075 sec/batch\n",
      "Epoch 42/50 Iteration: 749200 Avg. Training loss: 1.1848 0.0074 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 749400 Avg. Training loss: 1.1494 0.0078 sec/batch\n",
      "Epoch 42/50 Iteration: 749600 Avg. Training loss: 1.2625 0.0080 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 749800 Avg. Training loss: 1.4706 0.0073 sec/batch\n",
      "Epoch 42/50 Iteration: 750000 Avg. Training loss: 1.3587 0.0076 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 750200 Avg. Training loss: 1.0803 0.0073 sec/batch\n",
      "Epoch 42/50 Iteration: 750400 Avg. Training loss: 0.8823 0.0073 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 750600 Avg. Training loss: 1.1745 0.0078 sec/batch\n",
      "Epoch 42/50 Iteration: 750800 Avg. Training loss: 0.7003 0.0073 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 751000 Avg. Training loss: 0.9513 0.0075 sec/batch\n",
      "Epoch 42/50 Iteration: 751200 Avg. Training loss: 1.4319 0.0075 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 751400 Avg. Training loss: 1.0809 0.0075 sec/batch\n",
      "Epoch 42/50 Iteration: 751600 Avg. Training loss: 1.2724 0.0082 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 751800 Avg. Training loss: 1.0824 0.0074 sec/batch\n",
      "Epoch 42/50 Iteration: 752000 Avg. Training loss: 0.9621 0.0078 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 752200 Avg. Training loss: 0.9990 0.0074 sec/batch\n",
      "Epoch 42/50 Iteration: 752400 Avg. Training loss: 1.5161 0.0077 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 752600 Avg. Training loss: 1.0435 0.0075 sec/batch\n",
      "Epoch 42/50 Iteration: 752800 Avg. Training loss: 1.3918 0.0072 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 753000 Avg. Training loss: 1.1249 0.0074 sec/batch\n",
      "Epoch 42/50 Iteration: 753200 Avg. Training loss: 1.5243 0.0077 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 753400 Avg. Training loss: 1.1802 0.0076 sec/batch\n",
      "Epoch 42/50 Iteration: 753600 Avg. Training loss: 0.8287 0.0076 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 753800 Avg. Training loss: 1.3369 0.0074 sec/batch\n",
      "Epoch 42/50 Iteration: 754000 Avg. Training loss: 1.2178 0.0072 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 754200 Avg. Training loss: 0.9989 0.0073 sec/batch\n",
      "Epoch 42/50 Iteration: 754400 Avg. Training loss: 1.6966 0.0092 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 754600 Avg. Training loss: 1.2086 0.0077 sec/batch\n",
      "Epoch 42/50 Iteration: 754800 Avg. Training loss: 1.6702 0.0074 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 755000 Avg. Training loss: 1.1709 0.0075 sec/batch\n",
      "Epoch 42/50 Iteration: 755200 Avg. Training loss: 1.1128 0.0075 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 755400 Avg. Training loss: 1.5301 0.0083 sec/batch\n",
      "Epoch 42/50 Iteration: 755600 Avg. Training loss: 1.1122 0.0080 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 755800 Avg. Training loss: 0.7795 0.0072 sec/batch\n",
      "Epoch 42/50 Iteration: 756000 Avg. Training loss: 1.2178 0.0074 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 756200 Avg. Training loss: 1.7043 0.0077 sec/batch\n",
      "Epoch 42/50 Iteration: 756400 Avg. Training loss: 1.3393 0.0079 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 756600 Avg. Training loss: 1.3623 0.0076 sec/batch\n",
      "Epoch 42/50 Iteration: 756800 Avg. Training loss: 1.1330 0.0072 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 757000 Avg. Training loss: 1.2424 0.0072 sec/batch\n",
      "Epoch 42/50 Iteration: 757200 Avg. Training loss: 1.3620 0.0081 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 757400 Avg. Training loss: 1.2529 0.0075 sec/batch\n",
      "Epoch 42/50 Iteration: 757600 Avg. Training loss: 1.3068 0.0074 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 757800 Avg. Training loss: 0.9605 0.0074 sec/batch\n",
      "Epoch 42/50 Iteration: 758000 Avg. Training loss: 1.0202 0.0074 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 758200 Avg. Training loss: 0.7712 0.0075 sec/batch\n",
      "Epoch 42/50 Iteration: 758400 Avg. Training loss: 1.0697 0.0074 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 758600 Avg. Training loss: 1.2792 0.0080 sec/batch\n",
      "Epoch 42/50 Iteration: 758800 Avg. Training loss: 0.9922 0.0085 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 759000 Avg. Training loss: 1.3980 0.0082 sec/batch\n",
      "Epoch 42/50 Iteration: 759200 Avg. Training loss: 1.3370 0.0078 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 759400 Avg. Training loss: 1.1547 0.0087 sec/batch\n",
      "Epoch 42/50 Iteration: 759600 Avg. Training loss: 0.8730 0.0076 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 759800 Avg. Training loss: 1.5729 0.0077 sec/batch\n",
      "Epoch 42/50 Iteration: 760000 Avg. Training loss: 1.3001 0.0075 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 760200 Avg. Training loss: 1.4714 0.0077 sec/batch\n",
      "Epoch 42/50 Iteration: 760400 Avg. Training loss: 1.5487 0.0076 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 760600 Avg. Training loss: 1.1204 0.0076 sec/batch\n",
      "Epoch 42/50 Iteration: 760800 Avg. Training loss: 1.0770 0.0073 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 761000 Avg. Training loss: 1.3388 0.0070 sec/batch\n",
      "Epoch 42/50 Iteration: 761200 Avg. Training loss: 1.2327 0.0074 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 761400 Avg. Training loss: 1.2879 0.0071 sec/batch\n",
      "Epoch 42/50 Iteration: 761600 Avg. Training loss: 1.3072 0.0076 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 Iteration: 761800 Avg. Training loss: 1.2889 0.0070 sec/batch\n",
      "Epoch 42/50 Iteration: 762000 Avg. Training loss: 1.2513 0.0075 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 762200 Avg. Training loss: 1.3738 0.0076 sec/batch\n",
      "Epoch 42/50 Iteration: 762400 Avg. Training loss: 1.0418 0.0074 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 762600 Avg. Training loss: 0.7789 0.0071 sec/batch\n",
      "Epoch 42/50 Iteration: 762800 Avg. Training loss: 1.0248 0.0069 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 763000 Avg. Training loss: 1.8809 0.0082 sec/batch\n",
      "Epoch 42/50 Iteration: 763200 Avg. Training loss: 1.3372 0.0074 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 763400 Avg. Training loss: 1.0843 0.0072 sec/batch\n",
      "Epoch 42/50 Iteration: 763600 Avg. Training loss: 1.1596 0.0073 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 763800 Avg. Training loss: 1.0990 0.0075 sec/batch\n",
      "Epoch 42/50 Iteration: 764000 Avg. Training loss: 0.9559 0.0081 sec/batch\n",
      "error\n",
      "Epoch 42/50 Iteration: 764200 Avg. Training loss: 1.0513 0.0073 sec/batch\n",
      "Epoch 43/50 Iteration: 764400 Avg. Training loss: 1.7246 0.0049 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 764600 Avg. Training loss: 1.3718 0.0078 sec/batch\n",
      "Epoch 43/50 Iteration: 764800 Avg. Training loss: 1.1778 0.0075 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 765000 Avg. Training loss: 1.3240 0.0079 sec/batch\n",
      "Epoch 43/50 Iteration: 765200 Avg. Training loss: 1.6818 0.0082 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 765400 Avg. Training loss: 1.0548 0.0074 sec/batch\n",
      "Epoch 43/50 Iteration: 765600 Avg. Training loss: 1.3864 0.0075 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 765800 Avg. Training loss: 1.2900 0.0074 sec/batch\n",
      "Epoch 43/50 Iteration: 766000 Avg. Training loss: 1.2914 0.0074 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 766200 Avg. Training loss: 1.2081 0.0069 sec/batch\n",
      "Epoch 43/50 Iteration: 766400 Avg. Training loss: 1.4581 0.0072 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 766600 Avg. Training loss: 1.1390 0.0072 sec/batch\n",
      "Epoch 43/50 Iteration: 766800 Avg. Training loss: 1.0838 0.0077 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 767000 Avg. Training loss: 0.9853 2.8494 sec/batch\n",
      "Epoch 43/50 Iteration: 767200 Avg. Training loss: 1.2795 0.0072 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 767400 Avg. Training loss: 1.3598 0.0071 sec/batch\n",
      "Epoch 43/50 Iteration: 767600 Avg. Training loss: 1.2821 0.0076 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 767800 Avg. Training loss: 1.2314 0.0078 sec/batch\n",
      "Epoch 43/50 Iteration: 768000 Avg. Training loss: 1.7423 0.0070 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 768200 Avg. Training loss: 1.3527 0.0073 sec/batch\n",
      "Epoch 43/50 Iteration: 768400 Avg. Training loss: 1.1003 0.0070 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 768600 Avg. Training loss: 0.9212 0.0070 sec/batch\n",
      "Epoch 43/50 Iteration: 768800 Avg. Training loss: 1.2369 0.0076 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 769000 Avg. Training loss: 0.7099 0.0070 sec/batch\n",
      "Epoch 43/50 Iteration: 769200 Avg. Training loss: 1.1251 0.0075 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 769400 Avg. Training loss: 0.8184 0.0073 sec/batch\n",
      "Epoch 43/50 Iteration: 769600 Avg. Training loss: 1.1124 0.0072 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 769800 Avg. Training loss: 1.7421 0.0083 sec/batch\n",
      "Epoch 43/50 Iteration: 770000 Avg. Training loss: 1.1550 0.0074 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 770200 Avg. Training loss: 1.1788 0.0078 sec/batch\n",
      "Epoch 43/50 Iteration: 770400 Avg. Training loss: 1.1125 0.0073 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 770600 Avg. Training loss: 1.4353 0.0078 sec/batch\n",
      "Epoch 43/50 Iteration: 770800 Avg. Training loss: 1.0828 0.0076 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 771000 Avg. Training loss: 1.4674 0.0074 sec/batch\n",
      "Epoch 43/50 Iteration: 771200 Avg. Training loss: 1.2227 0.0073 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 771400 Avg. Training loss: 1.4308 0.0076 sec/batch\n",
      "Epoch 43/50 Iteration: 771600 Avg. Training loss: 1.4238 0.0078 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 771800 Avg. Training loss: 0.6591 0.0077 sec/batch\n",
      "Epoch 43/50 Iteration: 772000 Avg. Training loss: 1.1152 0.0073 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 772200 Avg. Training loss: 0.8325 0.0072 sec/batch\n",
      "Epoch 43/50 Iteration: 772400 Avg. Training loss: 1.1707 0.0075 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 772600 Avg. Training loss: 1.7992 0.0091 sec/batch\n",
      "Epoch 43/50 Iteration: 772800 Avg. Training loss: 1.1211 0.0075 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 773000 Avg. Training loss: 1.5032 0.0072 sec/batch\n",
      "Epoch 43/50 Iteration: 773200 Avg. Training loss: 1.0548 0.0074 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 773400 Avg. Training loss: 1.2652 0.0075 sec/batch\n",
      "Epoch 43/50 Iteration: 773600 Avg. Training loss: 1.6372 0.0084 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 773800 Avg. Training loss: 1.4208 0.0080 sec/batch\n",
      "Epoch 43/50 Iteration: 774000 Avg. Training loss: 0.5748 0.0072 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 774200 Avg. Training loss: 1.3182 0.0076 sec/batch\n",
      "Epoch 43/50 Iteration: 774400 Avg. Training loss: 1.2728 0.0078 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 774600 Avg. Training loss: 1.3381 0.0086 sec/batch\n",
      "Epoch 43/50 Iteration: 774800 Avg. Training loss: 1.2384 0.0084 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 775000 Avg. Training loss: 1.0578 0.0076 sec/batch\n",
      "Epoch 43/50 Iteration: 775200 Avg. Training loss: 1.0066 0.0071 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 775400 Avg. Training loss: 1.3957 0.0081 sec/batch\n",
      "Epoch 43/50 Iteration: 775600 Avg. Training loss: 1.1916 0.0077 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 775800 Avg. Training loss: 1.2337 0.0076 sec/batch\n",
      "Epoch 43/50 Iteration: 776000 Avg. Training loss: 1.0058 0.0074 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 776200 Avg. Training loss: 0.9849 0.0074 sec/batch\n",
      "Epoch 43/50 Iteration: 776400 Avg. Training loss: 0.9986 0.0076 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 776600 Avg. Training loss: 0.9400 0.0076 sec/batch\n",
      "Epoch 43/50 Iteration: 776800 Avg. Training loss: 1.3902 0.0075 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 777000 Avg. Training loss: 0.9229 0.0082 sec/batch\n",
      "Epoch 43/50 Iteration: 777200 Avg. Training loss: 1.3920 0.0082 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 777400 Avg. Training loss: 1.2759 0.0083 sec/batch\n",
      "Epoch 43/50 Iteration: 777600 Avg. Training loss: 0.9768 0.0095 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 777800 Avg. Training loss: 1.0630 0.0082 sec/batch\n",
      "Epoch 43/50 Iteration: 778000 Avg. Training loss: 1.3344 0.0083 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 778200 Avg. Training loss: 1.2943 0.0083 sec/batch\n",
      "Epoch 43/50 Iteration: 778400 Avg. Training loss: 1.3042 0.0091 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 778600 Avg. Training loss: 1.1829 0.0085 sec/batch\n",
      "Epoch 43/50 Iteration: 778800 Avg. Training loss: 1.1029 0.0085 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 779000 Avg. Training loss: 1.0955 0.0081 sec/batch\n",
      "Epoch 43/50 Iteration: 779200 Avg. Training loss: 1.1684 0.0081 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 779400 Avg. Training loss: 1.3265 0.0085 sec/batch\n",
      "Epoch 43/50 Iteration: 779600 Avg. Training loss: 1.2766 0.0081 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 779800 Avg. Training loss: 1.3999 0.0087 sec/batch\n",
      "Epoch 43/50 Iteration: 780000 Avg. Training loss: 1.1709 0.0080 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 780200 Avg. Training loss: 1.1244 0.0084 sec/batch\n",
      "Epoch 43/50 Iteration: 780400 Avg. Training loss: 1.4036 0.0084 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 780600 Avg. Training loss: 0.9751 0.0083 sec/batch\n",
      "Epoch 43/50 Iteration: 780800 Avg. Training loss: 0.7869 0.0079 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 781000 Avg. Training loss: 1.2426 0.0080 sec/batch\n",
      "Epoch 43/50 Iteration: 781200 Avg. Training loss: 1.6828 0.0093 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 781400 Avg. Training loss: 1.5243 0.0082 sec/batch\n",
      "Epoch 43/50 Iteration: 781600 Avg. Training loss: 1.2261 0.0078 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 781800 Avg. Training loss: 0.8524 0.0083 sec/batch\n",
      "Epoch 43/50 Iteration: 782000 Avg. Training loss: 1.0849 0.0084 sec/batch\n",
      "error\n",
      "Epoch 43/50 Iteration: 782200 Avg. Training loss: 1.1572 0.0093 sec/batch\n",
      "Epoch 43/50 Iteration: 782400 Avg. Training loss: 1.4418 0.0083 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 782600 Avg. Training loss: 1.4074 0.0058 sec/batch\n",
      "Epoch 44/50 Iteration: 782800 Avg. Training loss: 1.3240 0.0089 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 783000 Avg. Training loss: 1.2286 0.0084 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 Iteration: 783200 Avg. Training loss: 1.3838 0.0087 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 783400 Avg. Training loss: 1.7881 0.0092 sec/batch\n",
      "Epoch 44/50 Iteration: 783600 Avg. Training loss: 1.3232 0.0085 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 783800 Avg. Training loss: 1.5719 0.0085 sec/batch\n",
      "Epoch 44/50 Iteration: 784000 Avg. Training loss: 0.9238 0.0086 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 784200 Avg. Training loss: 1.3604 0.0085 sec/batch\n",
      "Epoch 44/50 Iteration: 784400 Avg. Training loss: 1.2126 0.0080 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 784600 Avg. Training loss: 1.2137 0.0082 sec/batch\n",
      "Epoch 44/50 Iteration: 784800 Avg. Training loss: 1.2432 0.0085 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 785000 Avg. Training loss: 1.2451 0.0088 sec/batch\n",
      "Epoch 44/50 Iteration: 785200 Avg. Training loss: 0.9885 0.0081 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 785400 Avg. Training loss: 1.3448 0.0088 sec/batch\n",
      "Epoch 44/50 Iteration: 785600 Avg. Training loss: 1.0547 0.0086 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 785800 Avg. Training loss: 1.3023 0.0089 sec/batch\n",
      "Epoch 44/50 Iteration: 786000 Avg. Training loss: 1.2088 0.0089 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 786200 Avg. Training loss: 1.4716 0.0083 sec/batch\n",
      "Epoch 44/50 Iteration: 786400 Avg. Training loss: 1.2772 0.0086 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 786600 Avg. Training loss: 1.0225 0.0082 sec/batch\n",
      "Epoch 44/50 Iteration: 786800 Avg. Training loss: 1.0032 0.0083 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 787000 Avg. Training loss: 0.9309 0.0085 sec/batch\n",
      "Epoch 44/50 Iteration: 787200 Avg. Training loss: 0.5668 0.0081 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 787400 Avg. Training loss: 0.8877 0.0083 sec/batch\n",
      "Epoch 44/50 Iteration: 787600 Avg. Training loss: 1.4720 0.0085 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 787800 Avg. Training loss: 1.1559 0.0084 sec/batch\n",
      "Epoch 44/50 Iteration: 788000 Avg. Training loss: 1.6275 0.0092 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 788200 Avg. Training loss: 1.3462 0.0086 sec/batch\n",
      "Epoch 44/50 Iteration: 788400 Avg. Training loss: 0.9697 0.0087 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 788600 Avg. Training loss: 0.9360 0.0083 sec/batch\n",
      "Epoch 44/50 Iteration: 788800 Avg. Training loss: 1.5645 0.0085 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 789000 Avg. Training loss: 1.4226 0.0083 sec/batch\n",
      "Epoch 44/50 Iteration: 789200 Avg. Training loss: 1.0798 0.0083 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 789400 Avg. Training loss: 1.1175 0.0082 sec/batch\n",
      "Epoch 44/50 Iteration: 789600 Avg. Training loss: 1.7101 0.0085 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 789800 Avg. Training loss: 1.3331 0.0085 sec/batch\n",
      "Epoch 44/50 Iteration: 790000 Avg. Training loss: 0.7186 0.0086 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 790200 Avg. Training loss: 1.0167 0.0082 sec/batch\n",
      "Epoch 44/50 Iteration: 790400 Avg. Training loss: 1.0867 0.0080 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 790600 Avg. Training loss: 1.2888 0.0080 sec/batch\n",
      "Epoch 44/50 Iteration: 790800 Avg. Training loss: 1.8732 0.0101 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 791000 Avg. Training loss: 1.1242 0.0086 sec/batch\n",
      "Epoch 44/50 Iteration: 791200 Avg. Training loss: 1.2787 0.0084 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 791400 Avg. Training loss: 0.9918 0.0081 sec/batch\n",
      "Epoch 44/50 Iteration: 791600 Avg. Training loss: 1.4026 0.0082 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 791800 Avg. Training loss: 1.4213 0.0093 sec/batch\n",
      "Epoch 44/50 Iteration: 792000 Avg. Training loss: 1.3512 0.0088 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 792200 Avg. Training loss: 0.5742 0.0081 sec/batch\n",
      "Epoch 44/50 Iteration: 792400 Avg. Training loss: 1.1926 0.0083 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 792600 Avg. Training loss: 1.4858 0.0090 sec/batch\n",
      "Epoch 44/50 Iteration: 792800 Avg. Training loss: 1.1588 0.0092 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 793000 Avg. Training loss: 1.5968 0.0085 sec/batch\n",
      "Epoch 44/50 Iteration: 793200 Avg. Training loss: 1.0677 0.0081 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 793400 Avg. Training loss: 0.9642 0.0080 sec/batch\n",
      "Epoch 44/50 Iteration: 793600 Avg. Training loss: 1.1880 0.0088 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 793800 Avg. Training loss: 1.3315 0.0083 sec/batch\n",
      "Epoch 44/50 Iteration: 794000 Avg. Training loss: 1.1558 0.0081 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 794200 Avg. Training loss: 1.0204 0.0081 sec/batch\n",
      "Epoch 44/50 Iteration: 794400 Avg. Training loss: 1.0627 0.0082 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 794600 Avg. Training loss: 0.8302 0.0081 sec/batch\n",
      "Epoch 44/50 Iteration: 794800 Avg. Training loss: 1.2522 0.0081 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 795000 Avg. Training loss: 1.3216 0.0082 sec/batch\n",
      "Epoch 44/50 Iteration: 795200 Avg. Training loss: 1.0111 0.0088 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 795400 Avg. Training loss: 1.3077 0.0092 sec/batch\n",
      "Epoch 44/50 Iteration: 795600 Avg. Training loss: 1.1730 0.0086 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 795800 Avg. Training loss: 1.0666 0.0096 sec/batch\n",
      "Epoch 44/50 Iteration: 796000 Avg. Training loss: 1.0553 0.0084 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 796200 Avg. Training loss: 1.6546 0.0086 sec/batch\n",
      "Epoch 44/50 Iteration: 796400 Avg. Training loss: 1.1371 0.0083 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 796600 Avg. Training loss: 1.4199 0.0085 sec/batch\n",
      "Epoch 44/50 Iteration: 796800 Avg. Training loss: 1.2793 0.0085 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 797000 Avg. Training loss: 1.1838 0.0084 sec/batch\n",
      "Epoch 44/50 Iteration: 797200 Avg. Training loss: 1.0919 0.0080 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 797400 Avg. Training loss: 1.3014 0.0082 sec/batch\n",
      "Epoch 44/50 Iteration: 797600 Avg. Training loss: 1.3758 0.0083 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 797800 Avg. Training loss: 1.1171 0.0081 sec/batch\n",
      "Epoch 44/50 Iteration: 798000 Avg. Training loss: 1.2194 0.0087 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 798200 Avg. Training loss: 1.3308 0.0080 sec/batch\n",
      "Epoch 44/50 Iteration: 798400 Avg. Training loss: 1.1848 0.0085 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 798600 Avg. Training loss: 1.3731 0.0084 sec/batch\n",
      "Epoch 44/50 Iteration: 798800 Avg. Training loss: 0.8818 0.0082 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 799000 Avg. Training loss: 0.9261 0.0079 sec/batch\n",
      "Epoch 44/50 Iteration: 799200 Avg. Training loss: 0.9923 0.0078 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 799400 Avg. Training loss: 2.0510 0.0091 sec/batch\n",
      "Epoch 44/50 Iteration: 799600 Avg. Training loss: 1.4490 0.0077 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 799800 Avg. Training loss: 1.1386 0.0078 sec/batch\n",
      "Epoch 44/50 Iteration: 800000 Avg. Training loss: 1.0787 0.0078 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 800200 Avg. Training loss: 1.0414 0.0078 sec/batch\n",
      "Epoch 44/50 Iteration: 800400 Avg. Training loss: 1.3476 0.0087 sec/batch\n",
      "error\n",
      "Epoch 44/50 Iteration: 800600 Avg. Training loss: 1.1754 0.0078 sec/batch\n",
      "Epoch 45/50 Iteration: 800800 Avg. Training loss: 1.3154 0.0057 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 801000 Avg. Training loss: 1.3939 0.0082 sec/batch\n",
      "Epoch 45/50 Iteration: 801200 Avg. Training loss: 1.0796 0.0081 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 801400 Avg. Training loss: 1.2973 0.0082 sec/batch\n",
      "Epoch 45/50 Iteration: 801600 Avg. Training loss: 1.3745 0.0085 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 801800 Avg. Training loss: 1.0619 0.0079 sec/batch\n",
      "Epoch 45/50 Iteration: 802000 Avg. Training loss: 1.4831 0.0080 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 802200 Avg. Training loss: 1.0339 0.0079 sec/batch\n",
      "Epoch 45/50 Iteration: 802400 Avg. Training loss: 1.1687 0.0081 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 802600 Avg. Training loss: 1.3367 0.0075 sec/batch\n",
      "Epoch 45/50 Iteration: 802800 Avg. Training loss: 1.3208 0.0076 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 803000 Avg. Training loss: 1.1769 0.0077 sec/batch\n",
      "Epoch 45/50 Iteration: 803200 Avg. Training loss: 0.9571 0.0084 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 803400 Avg. Training loss: 1.0213 0.0078 sec/batch\n",
      "Epoch 45/50 Iteration: 803600 Avg. Training loss: 1.1905 0.0079 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 803800 Avg. Training loss: 1.1352 0.0078 sec/batch\n",
      "Epoch 45/50 Iteration: 804000 Avg. Training loss: 1.4489 0.0084 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 804200 Avg. Training loss: 1.0600 0.0084 sec/batch\n",
      "Epoch 45/50 Iteration: 804400 Avg. Training loss: 1.5466 0.0078 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 Iteration: 804600 Avg. Training loss: 1.2814 0.0080 sec/batch\n",
      "Epoch 45/50 Iteration: 804800 Avg. Training loss: 1.1161 0.0076 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 805000 Avg. Training loss: 0.9749 0.0077 sec/batch\n",
      "Epoch 45/50 Iteration: 805200 Avg. Training loss: 1.4747 0.0082 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 805400 Avg. Training loss: 0.6945 0.0076 sec/batch\n",
      "Epoch 45/50 Iteration: 805600 Avg. Training loss: 1.0192 0.0078 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 805800 Avg. Training loss: 1.3002 0.0078 sec/batch\n",
      "Epoch 45/50 Iteration: 806000 Avg. Training loss: 1.1175 0.0077 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 806200 Avg. Training loss: 1.7355 0.0086 sec/batch\n",
      "Epoch 45/50 Iteration: 806400 Avg. Training loss: 1.2281 0.0079 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 806600 Avg. Training loss: 0.8914 0.0081 sec/batch\n",
      "Epoch 45/50 Iteration: 806800 Avg. Training loss: 1.2231 0.0078 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 807000 Avg. Training loss: 1.2938 0.0079 sec/batch\n",
      "Epoch 45/50 Iteration: 807200 Avg. Training loss: 1.0869 0.0081 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 807400 Avg. Training loss: 1.3037 0.0079 sec/batch\n",
      "Epoch 45/50 Iteration: 807600 Avg. Training loss: 1.1797 0.0076 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 807800 Avg. Training loss: 1.4191 0.0079 sec/batch\n",
      "Epoch 45/50 Iteration: 808000 Avg. Training loss: 1.4801 0.0079 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 808200 Avg. Training loss: 0.7834 0.0078 sec/batch\n",
      "Epoch 45/50 Iteration: 808400 Avg. Training loss: 1.2516 0.0075 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 808600 Avg. Training loss: 1.1766 0.0075 sec/batch\n",
      "Epoch 45/50 Iteration: 808800 Avg. Training loss: 1.0382 0.0075 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 809000 Avg. Training loss: 1.6679 0.0096 sec/batch\n",
      "Epoch 45/50 Iteration: 809200 Avg. Training loss: 1.1237 0.0078 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 809400 Avg. Training loss: 1.2906 0.0076 sec/batch\n",
      "Epoch 45/50 Iteration: 809600 Avg. Training loss: 1.1098 0.0076 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 809800 Avg. Training loss: 1.1780 0.0076 sec/batch\n",
      "Epoch 45/50 Iteration: 810000 Avg. Training loss: 1.3989 0.0087 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 810200 Avg. Training loss: 1.4824 0.0083 sec/batch\n",
      "Epoch 45/50 Iteration: 810400 Avg. Training loss: 0.6343 0.0074 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 810600 Avg. Training loss: 1.0451 0.0076 sec/batch\n",
      "Epoch 45/50 Iteration: 810800 Avg. Training loss: 1.6095 0.0081 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 811000 Avg. Training loss: 1.1900 0.0081 sec/batch\n",
      "Epoch 45/50 Iteration: 811200 Avg. Training loss: 1.3757 0.0078 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 811400 Avg. Training loss: 1.0892 0.0075 sec/batch\n",
      "Epoch 45/50 Iteration: 811600 Avg. Training loss: 0.9395 0.0078 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 811800 Avg. Training loss: 0.9876 0.0085 sec/batch\n",
      "Epoch 45/50 Iteration: 812000 Avg. Training loss: 1.3269 0.0081 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 812200 Avg. Training loss: 1.0537 0.0080 sec/batch\n",
      "Epoch 45/50 Iteration: 812400 Avg. Training loss: 0.8834 0.0079 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 812600 Avg. Training loss: 1.1086 0.0080 sec/batch\n",
      "Epoch 45/50 Iteration: 812800 Avg. Training loss: 0.8954 0.0079 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 813000 Avg. Training loss: 1.2111 0.0080 sec/batch\n",
      "Epoch 45/50 Iteration: 813200 Avg. Training loss: 0.9997 0.0081 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 813400 Avg. Training loss: 0.9910 0.0087 sec/batch\n",
      "Epoch 45/50 Iteration: 813600 Avg. Training loss: 1.4424 0.0088 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 813800 Avg. Training loss: 1.2344 0.0085 sec/batch\n",
      "Epoch 45/50 Iteration: 814000 Avg. Training loss: 1.0791 0.0093 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 814200 Avg. Training loss: 0.8147 0.0083 sec/batch\n",
      "Epoch 45/50 Iteration: 814400 Avg. Training loss: 1.3522 0.0084 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 814600 Avg. Training loss: 1.2279 0.0082 sec/batch\n",
      "Epoch 45/50 Iteration: 814800 Avg. Training loss: 1.2268 0.0083 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 815000 Avg. Training loss: 1.5136 0.0083 sec/batch\n",
      "Epoch 45/50 Iteration: 815200 Avg. Training loss: 1.1005 0.0082 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 815400 Avg. Training loss: 1.1591 0.0079 sec/batch\n",
      "Epoch 45/50 Iteration: 815600 Avg. Training loss: 1.3797 0.0080 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 815800 Avg. Training loss: 1.2568 0.0084 sec/batch\n",
      "Epoch 45/50 Iteration: 816000 Avg. Training loss: 1.2816 0.0080 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 816200 Avg. Training loss: 1.1648 0.0086 sec/batch\n",
      "Epoch 45/50 Iteration: 816400 Avg. Training loss: 1.2941 0.0080 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 816600 Avg. Training loss: 1.2559 0.0083 sec/batch\n",
      "Epoch 45/50 Iteration: 816800 Avg. Training loss: 1.3937 0.0085 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 817000 Avg. Training loss: 1.0872 0.0083 sec/batch\n",
      "Epoch 45/50 Iteration: 817200 Avg. Training loss: 1.1819 0.0079 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 817400 Avg. Training loss: 1.2391 0.0079 sec/batch\n",
      "Epoch 45/50 Iteration: 817600 Avg. Training loss: 2.0131 0.0091 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 817800 Avg. Training loss: 1.6387 0.0083 sec/batch\n",
      "Epoch 45/50 Iteration: 818000 Avg. Training loss: 1.4496 0.0081 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 818200 Avg. Training loss: 1.0922 0.0083 sec/batch\n",
      "Epoch 45/50 Iteration: 818400 Avg. Training loss: 1.1044 0.0081 sec/batch\n",
      "error\n",
      "Epoch 45/50 Iteration: 818600 Avg. Training loss: 1.2547 0.0092 sec/batch\n",
      "Epoch 45/50 Iteration: 818800 Avg. Training loss: 1.0346 0.0083 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 819000 Avg. Training loss: 1.7852 0.0060 sec/batch\n",
      "Epoch 46/50 Iteration: 819200 Avg. Training loss: 1.4160 0.0087 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 819400 Avg. Training loss: 1.2578 0.0084 sec/batch\n",
      "Epoch 46/50 Iteration: 819600 Avg. Training loss: 1.1316 0.0081 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 819800 Avg. Training loss: 1.6231 0.0084 sec/batch\n",
      "Epoch 46/50 Iteration: 820000 Avg. Training loss: 1.0999 0.0079 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 820200 Avg. Training loss: 1.3861 0.0080 sec/batch\n",
      "Epoch 46/50 Iteration: 820400 Avg. Training loss: 0.8985 0.0081 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 820600 Avg. Training loss: 1.2855 0.0082 sec/batch\n",
      "Epoch 46/50 Iteration: 820800 Avg. Training loss: 1.3701 0.0077 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 821000 Avg. Training loss: 1.3038 0.0079 sec/batch\n",
      "Epoch 46/50 Iteration: 821200 Avg. Training loss: 1.1731 0.0078 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 821400 Avg. Training loss: 1.1512 0.0083 sec/batch\n",
      "Epoch 46/50 Iteration: 821600 Avg. Training loss: 0.9145 0.0075 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 821800 Avg. Training loss: 1.3199 0.0077 sec/batch\n",
      "Epoch 46/50 Iteration: 822000 Avg. Training loss: 1.2848 0.0078 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 822200 Avg. Training loss: 1.4788 0.0088 sec/batch\n",
      "Epoch 46/50 Iteration: 822400 Avg. Training loss: 1.0655 0.0083 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 822600 Avg. Training loss: 1.6343 0.0077 sec/batch\n",
      "Epoch 46/50 Iteration: 822800 Avg. Training loss: 1.2653 0.0079 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 823000 Avg. Training loss: 1.1658 0.0076 sec/batch\n",
      "Epoch 46/50 Iteration: 823200 Avg. Training loss: 0.9178 0.0076 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 823400 Avg. Training loss: 1.2261 0.0081 sec/batch\n",
      "Epoch 46/50 Iteration: 823600 Avg. Training loss: 0.6358 0.0074 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 823800 Avg. Training loss: 1.1299 0.0078 sec/batch\n",
      "Epoch 46/50 Iteration: 824000 Avg. Training loss: 1.1178 0.0077 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 824200 Avg. Training loss: 1.0318 0.0077 sec/batch\n",
      "Epoch 46/50 Iteration: 824400 Avg. Training loss: 1.8881 0.0082 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 824600 Avg. Training loss: 1.2543 0.0072 sec/batch\n",
      "Epoch 46/50 Iteration: 824800 Avg. Training loss: 0.9893 0.0072 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 825000 Avg. Training loss: 1.0746 0.0069 sec/batch\n",
      "Epoch 46/50 Iteration: 825200 Avg. Training loss: 1.2964 0.0073 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 825400 Avg. Training loss: 1.1282 0.0071 sec/batch\n",
      "Epoch 46/50 Iteration: 825600 Avg. Training loss: 1.2650 0.0069 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 825800 Avg. Training loss: 1.1559 0.0070 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 Iteration: 826000 Avg. Training loss: 1.1795 0.0074 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 826200 Avg. Training loss: 1.2906 0.0074 sec/batch\n",
      "Epoch 46/50 Iteration: 826400 Avg. Training loss: 0.7486 0.0071 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 826600 Avg. Training loss: 1.3764 0.0068 sec/batch\n",
      "Epoch 46/50 Iteration: 826800 Avg. Training loss: 1.0875 0.0067 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 827000 Avg. Training loss: 1.1334 0.0068 sec/batch\n",
      "Epoch 46/50 Iteration: 827200 Avg. Training loss: 1.5556 0.0088 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 827400 Avg. Training loss: 1.3533 0.0070 sec/batch\n",
      "Epoch 46/50 Iteration: 827600 Avg. Training loss: 1.4373 0.0068 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 827800 Avg. Training loss: 1.2074 0.0070 sec/batch\n",
      "Epoch 46/50 Iteration: 828000 Avg. Training loss: 1.2540 0.0070 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 828200 Avg. Training loss: 1.6590 0.0078 sec/batch\n",
      "Epoch 46/50 Iteration: 828400 Avg. Training loss: 1.5954 0.0075 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 828600 Avg. Training loss: 0.6558 0.0067 sec/batch\n",
      "Epoch 46/50 Iteration: 828800 Avg. Training loss: 1.2963 0.0070 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 829000 Avg. Training loss: 1.3750 0.0074 sec/batch\n",
      "Epoch 46/50 Iteration: 829200 Avg. Training loss: 1.3788 0.0074 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 829400 Avg. Training loss: 1.3809 0.0072 sec/batch\n",
      "Epoch 46/50 Iteration: 829600 Avg. Training loss: 1.1727 0.0069 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 829800 Avg. Training loss: 1.1886 0.0068 sec/batch\n",
      "Epoch 46/50 Iteration: 830000 Avg. Training loss: 0.9508 0.0075 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 830200 Avg. Training loss: 1.3564 0.0071 sec/batch\n",
      "Epoch 46/50 Iteration: 830400 Avg. Training loss: 1.0866 0.0068 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 830600 Avg. Training loss: 0.9463 0.0068 sec/batch\n",
      "Epoch 46/50 Iteration: 830800 Avg. Training loss: 1.1236 0.0070 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 831000 Avg. Training loss: 0.9316 0.0070 sec/batch\n",
      "Epoch 46/50 Iteration: 831200 Avg. Training loss: 1.0646 0.0070 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 831400 Avg. Training loss: 1.1821 0.0071 sec/batch\n",
      "Epoch 46/50 Iteration: 831600 Avg. Training loss: 1.0317 0.0077 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 831800 Avg. Training loss: 1.5394 0.0077 sec/batch\n",
      "Epoch 46/50 Iteration: 832000 Avg. Training loss: 1.2125 0.0073 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 832200 Avg. Training loss: 0.9506 0.0082 sec/batch\n",
      "Epoch 46/50 Iteration: 832400 Avg. Training loss: 1.0826 0.0071 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 832600 Avg. Training loss: 1.4904 0.0072 sec/batch\n",
      "Epoch 46/50 Iteration: 832800 Avg. Training loss: 1.2490 0.0072 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 833000 Avg. Training loss: 1.2563 0.0072 sec/batch\n",
      "Epoch 46/50 Iteration: 833200 Avg. Training loss: 1.4330 0.0071 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 833400 Avg. Training loss: 1.2000 0.0072 sec/batch\n",
      "Epoch 46/50 Iteration: 833600 Avg. Training loss: 1.1653 0.0070 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 833800 Avg. Training loss: 1.3780 0.0068 sec/batch\n",
      "Epoch 46/50 Iteration: 834000 Avg. Training loss: 1.5320 0.0070 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 834200 Avg. Training loss: 1.1641 0.0069 sec/batch\n",
      "Epoch 46/50 Iteration: 834400 Avg. Training loss: 1.5324 0.0074 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 834600 Avg. Training loss: 1.0346 0.0069 sec/batch\n",
      "Epoch 46/50 Iteration: 834800 Avg. Training loss: 1.1883 0.0072 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 835000 Avg. Training loss: 1.3033 0.0073 sec/batch\n",
      "Epoch 46/50 Iteration: 835200 Avg. Training loss: 1.0483 0.0071 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 835400 Avg. Training loss: 0.7181 0.0070 sec/batch\n",
      "Epoch 46/50 Iteration: 835600 Avg. Training loss: 1.0665 0.0068 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 835800 Avg. Training loss: 1.7818 0.0079 sec/batch\n",
      "Epoch 46/50 Iteration: 836000 Avg. Training loss: 1.3921 0.0070 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 836200 Avg. Training loss: 1.2671 0.0070 sec/batch\n",
      "Epoch 46/50 Iteration: 836400 Avg. Training loss: 1.0292 0.0071 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 836600 Avg. Training loss: 1.0133 0.0072 sec/batch\n",
      "Epoch 46/50 Iteration: 836800 Avg. Training loss: 1.2448 0.0079 sec/batch\n",
      "error\n",
      "Epoch 46/50 Iteration: 837000 Avg. Training loss: 1.1902 0.0074 sec/batch\n",
      "Epoch 47/50 Iteration: 837200 Avg. Training loss: 1.4488 0.0056 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 837400 Avg. Training loss: 1.2981 0.0081 sec/batch\n",
      "Epoch 47/50 Iteration: 837600 Avg. Training loss: 1.4088 0.0077 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 837800 Avg. Training loss: 1.2958 0.0078 sec/batch\n",
      "Epoch 47/50 Iteration: 838000 Avg. Training loss: 1.6306 0.0081 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 838200 Avg. Training loss: 1.1683 0.0076 sec/batch\n",
      "Epoch 47/50 Iteration: 838400 Avg. Training loss: 1.5811 0.0082 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 838600 Avg. Training loss: 0.9438 0.0082 sec/batch\n",
      "Epoch 47/50 Iteration: 838800 Avg. Training loss: 1.4020 0.0078 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 839000 Avg. Training loss: 1.1713 0.0074 sec/batch\n",
      "Epoch 47/50 Iteration: 839200 Avg. Training loss: 1.2792 0.0076 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 839400 Avg. Training loss: 1.3027 0.0077 sec/batch\n",
      "Epoch 47/50 Iteration: 839600 Avg. Training loss: 1.0289 0.0081 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 839800 Avg. Training loss: 1.0751 0.0076 sec/batch\n",
      "Epoch 47/50 Iteration: 840000 Avg. Training loss: 1.4684 0.0076 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 840200 Avg. Training loss: 1.0885 0.0076 sec/batch\n",
      "Epoch 47/50 Iteration: 840400 Avg. Training loss: 1.3873 0.0082 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 840600 Avg. Training loss: 1.0569 0.0081 sec/batch\n",
      "Epoch 47/50 Iteration: 840800 Avg. Training loss: 1.7152 0.0076 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 841000 Avg. Training loss: 1.4266 0.0079 sec/batch\n",
      "Epoch 47/50 Iteration: 841200 Avg. Training loss: 1.0021 0.0075 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 841400 Avg. Training loss: 1.1675 0.0075 sec/batch\n",
      "Epoch 47/50 Iteration: 841600 Avg. Training loss: 1.4944 0.0080 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 841800 Avg. Training loss: 0.6985 0.0075 sec/batch\n",
      "Epoch 47/50 Iteration: 842000 Avg. Training loss: 1.1586 0.0077 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 842200 Avg. Training loss: 1.1731 0.0076 sec/batch\n",
      "Epoch 47/50 Iteration: 842400 Avg. Training loss: 1.0667 0.0076 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 842600 Avg. Training loss: 1.8354 0.0084 sec/batch\n",
      "Epoch 47/50 Iteration: 842800 Avg. Training loss: 1.4282 0.0079 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 843000 Avg. Training loss: 1.0425 0.0079 sec/batch\n",
      "Epoch 47/50 Iteration: 843200 Avg. Training loss: 0.9154 0.0077 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 843400 Avg. Training loss: 1.5499 0.0079 sec/batch\n",
      "Epoch 47/50 Iteration: 843600 Avg. Training loss: 1.2067 0.0080 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 843800 Avg. Training loss: 1.3202 0.0076 sec/batch\n",
      "Epoch 47/50 Iteration: 844000 Avg. Training loss: 1.0997 0.0076 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 844200 Avg. Training loss: 1.6010 0.0078 sec/batch\n",
      "Epoch 47/50 Iteration: 844400 Avg. Training loss: 1.5747 0.0080 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 844600 Avg. Training loss: 0.7978 0.0077 sec/batch\n",
      "Epoch 47/50 Iteration: 844800 Avg. Training loss: 1.0566 0.0074 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 845000 Avg. Training loss: 1.0229 0.0074 sec/batch\n",
      "Epoch 47/50 Iteration: 845200 Avg. Training loss: 1.0525 0.0075 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 845400 Avg. Training loss: 2.0182 0.0093 sec/batch\n",
      "Epoch 47/50 Iteration: 845600 Avg. Training loss: 1.3671 0.0076 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 845800 Avg. Training loss: 1.4639 0.0076 sec/batch\n",
      "Epoch 47/50 Iteration: 846000 Avg. Training loss: 1.1463 0.0077 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 846200 Avg. Training loss: 1.3176 0.0077 sec/batch\n",
      "Epoch 47/50 Iteration: 846400 Avg. Training loss: 1.4244 0.0082 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 846600 Avg. Training loss: 1.3458 0.0075 sec/batch\n",
      "Epoch 47/50 Iteration: 846800 Avg. Training loss: 0.6163 0.0068 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 847000 Avg. Training loss: 1.5554 0.0072 sec/batch\n",
      "Epoch 47/50 Iteration: 847200 Avg. Training loss: 1.4316 0.0073 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 Iteration: 847400 Avg. Training loss: 1.4126 0.0076 sec/batch\n",
      "Epoch 47/50 Iteration: 847600 Avg. Training loss: 1.2496 0.0073 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 847800 Avg. Training loss: 1.2225 0.0069 sec/batch\n",
      "Epoch 47/50 Iteration: 848000 Avg. Training loss: 0.8018 0.0068 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 848200 Avg. Training loss: 0.9539 0.0075 sec/batch\n",
      "Epoch 47/50 Iteration: 848400 Avg. Training loss: 1.2461 0.0072 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 848600 Avg. Training loss: 1.1615 0.0071 sec/batch\n",
      "Epoch 47/50 Iteration: 848800 Avg. Training loss: 1.0937 0.0069 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 849000 Avg. Training loss: 0.9486 0.0070 sec/batch\n",
      "Epoch 47/50 Iteration: 849200 Avg. Training loss: 0.9174 0.0070 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 849400 Avg. Training loss: 1.0794 0.0070 sec/batch\n",
      "Epoch 47/50 Iteration: 849600 Avg. Training loss: 1.3292 0.0072 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 849800 Avg. Training loss: 1.0601 0.0078 sec/batch\n",
      "Epoch 47/50 Iteration: 850000 Avg. Training loss: 1.4074 0.0077 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 850200 Avg. Training loss: 1.4451 0.0075 sec/batch\n",
      "Epoch 47/50 Iteration: 850400 Avg. Training loss: 0.8830 0.0086 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 850600 Avg. Training loss: 0.9415 0.0075 sec/batch\n",
      "Epoch 47/50 Iteration: 850800 Avg. Training loss: 1.6059 0.0075 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 851000 Avg. Training loss: 1.1654 0.0075 sec/batch\n",
      "Epoch 47/50 Iteration: 851200 Avg. Training loss: 1.3283 0.0075 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 851400 Avg. Training loss: 1.3868 0.0074 sec/batch\n",
      "Epoch 47/50 Iteration: 851600 Avg. Training loss: 1.1092 0.0076 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 851800 Avg. Training loss: 1.2075 0.0073 sec/batch\n",
      "Epoch 47/50 Iteration: 852000 Avg. Training loss: 1.1776 0.0072 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 852200 Avg. Training loss: 1.2998 0.0076 sec/batch\n",
      "Epoch 47/50 Iteration: 852400 Avg. Training loss: 1.3231 0.0074 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 852600 Avg. Training loss: 1.3785 0.0078 sec/batch\n",
      "Epoch 47/50 Iteration: 852800 Avg. Training loss: 1.4168 0.0073 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 853000 Avg. Training loss: 1.4495 0.0076 sec/batch\n",
      "Epoch 47/50 Iteration: 853200 Avg. Training loss: 1.1627 0.0078 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 853400 Avg. Training loss: 1.0146 0.0075 sec/batch\n",
      "Epoch 47/50 Iteration: 853600 Avg. Training loss: 0.9664 0.0072 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 853800 Avg. Training loss: 1.2506 0.0073 sec/batch\n",
      "Epoch 47/50 Iteration: 854000 Avg. Training loss: 1.9985 0.0084 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 854200 Avg. Training loss: 1.5571 0.0079 sec/batch\n",
      "Epoch 47/50 Iteration: 854400 Avg. Training loss: 1.2506 0.0076 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 854600 Avg. Training loss: 0.8716 0.0075 sec/batch\n",
      "Epoch 47/50 Iteration: 854800 Avg. Training loss: 0.9190 0.0074 sec/batch\n",
      "error\n",
      "Epoch 47/50 Iteration: 855000 Avg. Training loss: 1.3404 0.0083 sec/batch\n",
      "Epoch 47/50 Iteration: 855200 Avg. Training loss: 1.2615 0.0074 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 855400 Avg. Training loss: 1.5443 0.0056 sec/batch\n",
      "Epoch 48/50 Iteration: 855600 Avg. Training loss: 1.3791 0.0078 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 855800 Avg. Training loss: 1.2588 0.0076 sec/batch\n",
      "Epoch 48/50 Iteration: 856000 Avg. Training loss: 1.1823 0.0079 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 856200 Avg. Training loss: 1.7018 0.0081 sec/batch\n",
      "Epoch 48/50 Iteration: 856400 Avg. Training loss: 1.3907 0.0072 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 856600 Avg. Training loss: 1.5774 0.0073 sec/batch\n",
      "Epoch 48/50 Iteration: 856800 Avg. Training loss: 0.8314 0.0073 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 857000 Avg. Training loss: 1.2386 0.0073 sec/batch\n",
      "Epoch 48/50 Iteration: 857200 Avg. Training loss: 1.1978 0.0069 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 857400 Avg. Training loss: 1.5795 0.0072 sec/batch\n",
      "Epoch 48/50 Iteration: 857600 Avg. Training loss: 1.3601 0.0071 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 857800 Avg. Training loss: 1.1551 0.0076 sec/batch\n",
      "Epoch 48/50 Iteration: 858000 Avg. Training loss: 1.0550 0.0071 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 858200 Avg. Training loss: 1.2688 0.0071 sec/batch\n",
      "Epoch 48/50 Iteration: 858400 Avg. Training loss: 1.3894 0.0071 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 858600 Avg. Training loss: 1.2090 0.0078 sec/batch\n",
      "Epoch 48/50 Iteration: 858800 Avg. Training loss: 1.1238 0.0075 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 859000 Avg. Training loss: 1.5840 0.0071 sec/batch\n",
      "Epoch 48/50 Iteration: 859200 Avg. Training loss: 1.4209 0.0073 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 859400 Avg. Training loss: 1.0776 0.0069 sec/batch\n",
      "Epoch 48/50 Iteration: 859600 Avg. Training loss: 1.0917 0.0071 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 859800 Avg. Training loss: 1.3437 0.0074 sec/batch\n",
      "Epoch 48/50 Iteration: 860000 Avg. Training loss: 0.6059 0.0069 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 860200 Avg. Training loss: 1.2308 0.0072 sec/batch\n",
      "Epoch 48/50 Iteration: 860400 Avg. Training loss: 1.2123 0.0071 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 860600 Avg. Training loss: 0.9544 0.0072 sec/batch\n",
      "Epoch 48/50 Iteration: 860800 Avg. Training loss: 1.7132 0.0078 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 861000 Avg. Training loss: 1.3618 0.0073 sec/batch\n",
      "Epoch 48/50 Iteration: 861200 Avg. Training loss: 1.1449 0.0073 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 861400 Avg. Training loss: 1.1161 0.0071 sec/batch\n",
      "Epoch 48/50 Iteration: 861600 Avg. Training loss: 1.2681 0.0073 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 861800 Avg. Training loss: 0.9360 0.0074 sec/batch\n",
      "Epoch 48/50 Iteration: 862000 Avg. Training loss: 1.4188 0.0071 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 862200 Avg. Training loss: 1.1980 0.0070 sec/batch\n",
      "Epoch 48/50 Iteration: 862400 Avg. Training loss: 1.3033 0.0073 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 862600 Avg. Training loss: 1.5388 0.0074 sec/batch\n",
      "Epoch 48/50 Iteration: 862800 Avg. Training loss: 0.6784 0.0071 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 863000 Avg. Training loss: 0.9978 0.0069 sec/batch\n",
      "Epoch 48/50 Iteration: 863200 Avg. Training loss: 1.2101 0.0070 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 863400 Avg. Training loss: 0.9719 0.0068 sec/batch\n",
      "Epoch 48/50 Iteration: 863600 Avg. Training loss: 1.6926 0.0089 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 863800 Avg. Training loss: 1.1656 0.0071 sec/batch\n",
      "Epoch 48/50 Iteration: 864000 Avg. Training loss: 1.4848 0.0070 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 864200 Avg. Training loss: 1.1567 0.0070 sec/batch\n",
      "Epoch 48/50 Iteration: 864400 Avg. Training loss: 1.4249 0.0071 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 864600 Avg. Training loss: 1.5871 0.0080 sec/batch\n",
      "Epoch 48/50 Iteration: 864800 Avg. Training loss: 1.1897 0.0076 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 865000 Avg. Training loss: 0.8335 0.0069 sec/batch\n",
      "Epoch 48/50 Iteration: 865200 Avg. Training loss: 1.1098 0.0071 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 865400 Avg. Training loss: 1.5344 0.0074 sec/batch\n",
      "Epoch 48/50 Iteration: 865600 Avg. Training loss: 1.3297 0.0075 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 865800 Avg. Training loss: 1.2311 0.0073 sec/batch\n",
      "Epoch 48/50 Iteration: 866000 Avg. Training loss: 1.0459 0.0070 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 866200 Avg. Training loss: 1.0509 0.0069 sec/batch\n",
      "Epoch 48/50 Iteration: 866400 Avg. Training loss: 1.0904 0.0076 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 866600 Avg. Training loss: 1.3922 0.0072 sec/batch\n",
      "Epoch 48/50 Iteration: 866800 Avg. Training loss: 1.3331 0.0071 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 867000 Avg. Training loss: 1.0823 0.0070 sec/batch\n",
      "Epoch 48/50 Iteration: 867200 Avg. Training loss: 0.9045 0.0071 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 867400 Avg. Training loss: 0.8344 0.0072 sec/batch\n",
      "Epoch 48/50 Iteration: 867600 Avg. Training loss: 1.2449 0.0072 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 867800 Avg. Training loss: 1.1549 0.0071 sec/batch\n",
      "Epoch 48/50 Iteration: 868000 Avg. Training loss: 0.9682 0.0078 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 868200 Avg. Training loss: 1.1797 0.0077 sec/batch\n",
      "Epoch 48/50 Iteration: 868400 Avg. Training loss: 1.1901 0.0074 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 868600 Avg. Training loss: 1.0307 0.0084 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 Iteration: 868800 Avg. Training loss: 1.0233 0.0073 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 869000 Avg. Training loss: 1.2323 0.0072 sec/batch\n",
      "Epoch 48/50 Iteration: 869200 Avg. Training loss: 1.2766 0.0073 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 869400 Avg. Training loss: 1.2875 0.0073 sec/batch\n",
      "Epoch 48/50 Iteration: 869600 Avg. Training loss: 1.7877 0.0073 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 869800 Avg. Training loss: 1.3251 0.0074 sec/batch\n",
      "Epoch 48/50 Iteration: 870000 Avg. Training loss: 1.3198 0.0071 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 870200 Avg. Training loss: 1.3639 0.0070 sec/batch\n",
      "Epoch 48/50 Iteration: 870400 Avg. Training loss: 1.5685 0.0075 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 870600 Avg. Training loss: 1.1496 0.0076 sec/batch\n",
      "Epoch 48/50 Iteration: 870800 Avg. Training loss: 1.4040 0.0077 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 871000 Avg. Training loss: 1.1203 0.0070 sec/batch\n",
      "Epoch 48/50 Iteration: 871200 Avg. Training loss: 1.5220 0.0073 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 871400 Avg. Training loss: 1.3541 0.0075 sec/batch\n",
      "Epoch 48/50 Iteration: 871600 Avg. Training loss: 0.9472 0.0072 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 871800 Avg. Training loss: 0.8913 0.0069 sec/batch\n",
      "Epoch 48/50 Iteration: 872000 Avg. Training loss: 1.4331 0.0069 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 872200 Avg. Training loss: 1.7129 0.0082 sec/batch\n",
      "Epoch 48/50 Iteration: 872400 Avg. Training loss: 1.5184 0.0072 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 872600 Avg. Training loss: 1.3386 0.0070 sec/batch\n",
      "Epoch 48/50 Iteration: 872800 Avg. Training loss: 1.0078 0.0072 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 873000 Avg. Training loss: 1.1088 0.0072 sec/batch\n",
      "Epoch 48/50 Iteration: 873200 Avg. Training loss: 1.2377 0.0080 sec/batch\n",
      "error\n",
      "Epoch 48/50 Iteration: 873400 Avg. Training loss: 1.1936 0.0072 sec/batch\n",
      "Epoch 49/50 Iteration: 873600 Avg. Training loss: 1.5738 0.0056 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 873800 Avg. Training loss: 1.2870 0.0075 sec/batch\n",
      "Epoch 49/50 Iteration: 874000 Avg. Training loss: 1.0148 0.0073 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 874200 Avg. Training loss: 1.2920 0.0080 sec/batch\n",
      "Epoch 49/50 Iteration: 874400 Avg. Training loss: 1.6168 0.0084 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 874600 Avg. Training loss: 1.2026 0.0077 sec/batch\n",
      "Epoch 49/50 Iteration: 874800 Avg. Training loss: 1.7703 0.0078 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 875000 Avg. Training loss: 1.1631 0.0074 sec/batch\n",
      "Epoch 49/50 Iteration: 875200 Avg. Training loss: 1.0961 0.0074 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 875400 Avg. Training loss: 1.4832 0.0070 sec/batch\n",
      "Epoch 49/50 Iteration: 875600 Avg. Training loss: 1.2099 0.0071 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 875800 Avg. Training loss: 1.3545 0.0072 sec/batch\n",
      "Epoch 49/50 Iteration: 876000 Avg. Training loss: 1.1754 0.0076 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 876200 Avg. Training loss: 1.0636 0.0071 sec/batch\n",
      "Epoch 49/50 Iteration: 876400 Avg. Training loss: 1.3285 0.0071 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 876600 Avg. Training loss: 1.2372 0.0071 sec/batch\n",
      "Epoch 49/50 Iteration: 876800 Avg. Training loss: 1.5931 0.0077 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 877000 Avg. Training loss: 1.1757 0.0077 sec/batch\n",
      "Epoch 49/50 Iteration: 877200 Avg. Training loss: 1.5720 0.0074 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 877400 Avg. Training loss: 1.4969 0.0079 sec/batch\n",
      "Epoch 49/50 Iteration: 877600 Avg. Training loss: 0.9543 0.0075 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 877800 Avg. Training loss: 0.9165 0.0077 sec/batch\n",
      "Epoch 49/50 Iteration: 878000 Avg. Training loss: 1.2225 0.0080 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 878200 Avg. Training loss: 0.6900 0.0073 sec/batch\n",
      "Epoch 49/50 Iteration: 878400 Avg. Training loss: 1.1597 0.0076 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 878600 Avg. Training loss: 1.1167 0.0075 sec/batch\n",
      "Epoch 49/50 Iteration: 878800 Avg. Training loss: 1.2040 0.0075 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 879000 Avg. Training loss: 1.6794 0.0082 sec/batch\n",
      "Epoch 49/50 Iteration: 879200 Avg. Training loss: 1.3219 0.0078 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 879400 Avg. Training loss: 1.1261 0.0078 sec/batch\n",
      "Epoch 49/50 Iteration: 879600 Avg. Training loss: 1.1973 0.0075 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 879800 Avg. Training loss: 1.3293 0.0077 sec/batch\n",
      "Epoch 49/50 Iteration: 880000 Avg. Training loss: 1.1662 0.0076 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 880200 Avg. Training loss: 1.2475 0.0075 sec/batch\n",
      "Epoch 49/50 Iteration: 880400 Avg. Training loss: 1.3326 0.0074 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 880600 Avg. Training loss: 1.4721 0.0078 sec/batch\n",
      "Epoch 49/50 Iteration: 880800 Avg. Training loss: 1.4057 0.0079 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 881000 Avg. Training loss: 0.7247 0.0075 sec/batch\n",
      "Epoch 49/50 Iteration: 881200 Avg. Training loss: 1.1642 0.0074 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 881400 Avg. Training loss: 1.0060 0.0073 sec/batch\n",
      "Epoch 49/50 Iteration: 881600 Avg. Training loss: 1.0223 0.0073 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 881800 Avg. Training loss: 1.9333 0.0093 sec/batch\n",
      "Epoch 49/50 Iteration: 882000 Avg. Training loss: 1.2012 0.0075 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 882200 Avg. Training loss: 1.2713 0.0074 sec/batch\n",
      "Epoch 49/50 Iteration: 882400 Avg. Training loss: 1.2850 0.0075 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 882600 Avg. Training loss: 1.5517 0.0078 sec/batch\n",
      "Epoch 49/50 Iteration: 882800 Avg. Training loss: 1.5643 0.0086 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 883000 Avg. Training loss: 1.2598 0.0082 sec/batch\n",
      "Epoch 49/50 Iteration: 883200 Avg. Training loss: 0.6921 0.0076 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 883400 Avg. Training loss: 1.2588 0.0078 sec/batch\n",
      "Epoch 49/50 Iteration: 883600 Avg. Training loss: 1.5068 0.0081 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 883800 Avg. Training loss: 1.2372 0.0081 sec/batch\n",
      "Epoch 49/50 Iteration: 884000 Avg. Training loss: 1.3188 0.0079 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 884200 Avg. Training loss: 1.1487 0.0076 sec/batch\n",
      "Epoch 49/50 Iteration: 884400 Avg. Training loss: 1.0185 0.0076 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 884600 Avg. Training loss: 1.1630 0.0082 sec/batch\n",
      "Epoch 49/50 Iteration: 884800 Avg. Training loss: 1.2865 0.0077 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 885000 Avg. Training loss: 1.0295 0.0077 sec/batch\n",
      "Epoch 49/50 Iteration: 885200 Avg. Training loss: 0.8561 0.0077 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 885400 Avg. Training loss: 1.1235 0.0079 sec/batch\n",
      "Epoch 49/50 Iteration: 885600 Avg. Training loss: 0.9369 0.0076 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 885800 Avg. Training loss: 1.1114 0.0077 sec/batch\n",
      "Epoch 49/50 Iteration: 886000 Avg. Training loss: 1.0314 0.0078 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 886200 Avg. Training loss: 1.0148 0.0086 sec/batch\n",
      "Epoch 49/50 Iteration: 886400 Avg. Training loss: 1.6609 0.0088 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 886600 Avg. Training loss: 1.2512 0.0083 sec/batch\n",
      "Epoch 49/50 Iteration: 886800 Avg. Training loss: 1.1975 0.0089 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 887000 Avg. Training loss: 0.9337 0.0079 sec/batch\n",
      "Epoch 49/50 Iteration: 887200 Avg. Training loss: 1.4253 0.0080 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 887400 Avg. Training loss: 1.5184 0.0079 sec/batch\n",
      "Epoch 49/50 Iteration: 887600 Avg. Training loss: 1.2311 0.0079 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 887800 Avg. Training loss: 1.5179 0.0078 sec/batch\n",
      "Epoch 49/50 Iteration: 888000 Avg. Training loss: 1.1625 0.0079 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 888200 Avg. Training loss: 1.1031 0.0076 sec/batch\n",
      "Epoch 49/50 Iteration: 888400 Avg. Training loss: 1.4365 0.0076 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 888600 Avg. Training loss: 1.3826 0.0079 sec/batch\n",
      "Epoch 49/50 Iteration: 888800 Avg. Training loss: 1.2731 0.0076 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 889000 Avg. Training loss: 1.4129 0.0081 sec/batch\n",
      "Epoch 49/50 Iteration: 889200 Avg. Training loss: 1.3628 0.0076 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 889400 Avg. Training loss: 1.3444 0.0079 sec/batch\n",
      "Epoch 49/50 Iteration: 889600 Avg. Training loss: 1.3672 0.0080 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 889800 Avg. Training loss: 1.0953 0.0079 sec/batch\n",
      "Epoch 49/50 Iteration: 890000 Avg. Training loss: 0.9780 0.0075 sec/batch\n",
      "error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 Iteration: 890200 Avg. Training loss: 1.0821 0.0075 sec/batch\n",
      "Epoch 49/50 Iteration: 890400 Avg. Training loss: 1.8239 0.0088 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 890600 Avg. Training loss: 1.4617 0.0077 sec/batch\n",
      "Epoch 49/50 Iteration: 890800 Avg. Training loss: 1.2211 0.0076 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 891000 Avg. Training loss: 1.0907 0.0079 sec/batch\n",
      "Epoch 49/50 Iteration: 891200 Avg. Training loss: 0.9267 0.0079 sec/batch\n",
      "error\n",
      "Epoch 49/50 Iteration: 891400 Avg. Training loss: 1.1691 0.0085 sec/batch\n",
      "Epoch 49/50 Iteration: 891600 Avg. Training loss: 1.2945 0.0078 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 891800 Avg. Training loss: 1.6336 0.0061 sec/batch\n",
      "Epoch 50/50 Iteration: 892000 Avg. Training loss: 1.4272 0.0082 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 892200 Avg. Training loss: 1.0968 0.0081 sec/batch\n",
      "Epoch 50/50 Iteration: 892400 Avg. Training loss: 1.2074 0.0082 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 892600 Avg. Training loss: 1.5382 0.0083 sec/batch\n",
      "Epoch 50/50 Iteration: 892800 Avg. Training loss: 1.1538 0.0077 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 893000 Avg. Training loss: 1.6082 0.0079 sec/batch\n",
      "Epoch 50/50 Iteration: 893200 Avg. Training loss: 0.9901 0.0080 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 893400 Avg. Training loss: 1.0608 0.0080 sec/batch\n",
      "Epoch 50/50 Iteration: 893600 Avg. Training loss: 1.2661 0.0075 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 893800 Avg. Training loss: 1.6969 0.0219 sec/batch\n",
      "Epoch 50/50 Iteration: 894000 Avg. Training loss: 1.4129 0.0093 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 894200 Avg. Training loss: 1.1511 0.0088 sec/batch\n",
      "Epoch 50/50 Iteration: 894400 Avg. Training loss: 0.9815 0.0077 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 894600 Avg. Training loss: 1.3321 0.0078 sec/batch\n",
      "Epoch 50/50 Iteration: 894800 Avg. Training loss: 1.2125 0.0077 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 895000 Avg. Training loss: 1.1544 0.0083 sec/batch\n",
      "Epoch 50/50 Iteration: 895200 Avg. Training loss: 0.9973 0.0081 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 895400 Avg. Training loss: 1.7371 0.0077 sec/batch\n",
      "Epoch 50/50 Iteration: 895600 Avg. Training loss: 1.4608 0.0080 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 895800 Avg. Training loss: 1.0694 0.0076 sec/batch\n",
      "Epoch 50/50 Iteration: 896000 Avg. Training loss: 0.9322 0.0076 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 896200 Avg. Training loss: 1.4398 0.0080 sec/batch\n",
      "Epoch 50/50 Iteration: 896400 Avg. Training loss: 0.7554 0.0074 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 896600 Avg. Training loss: 1.1079 0.0078 sec/batch\n",
      "Epoch 50/50 Iteration: 896800 Avg. Training loss: 1.2827 0.0077 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 897000 Avg. Training loss: 1.1354 0.0077 sec/batch\n",
      "Epoch 50/50 Iteration: 897200 Avg. Training loss: 1.7667 0.0083 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 897400 Avg. Training loss: 1.3393 0.0079 sec/batch\n",
      "Epoch 50/50 Iteration: 897600 Avg. Training loss: 0.9366 0.0079 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 897800 Avg. Training loss: 1.5106 0.0077 sec/batch\n",
      "Epoch 50/50 Iteration: 898000 Avg. Training loss: 1.3325 0.0078 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 898200 Avg. Training loss: 1.1568 0.0079 sec/batch\n",
      "Epoch 50/50 Iteration: 898400 Avg. Training loss: 1.4529 0.0076 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 898600 Avg. Training loss: 1.4348 0.0077 sec/batch\n",
      "Epoch 50/50 Iteration: 898800 Avg. Training loss: 1.3086 0.0079 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 899000 Avg. Training loss: 1.6655 0.0080 sec/batch\n",
      "Epoch 50/50 Iteration: 899200 Avg. Training loss: 0.9217 0.0078 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 899400 Avg. Training loss: 1.1510 0.0077 sec/batch\n",
      "Epoch 50/50 Iteration: 899600 Avg. Training loss: 0.9632 0.0074 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 899800 Avg. Training loss: 0.8977 0.0076 sec/batch\n",
      "Epoch 50/50 Iteration: 900000 Avg. Training loss: 2.1399 0.0093 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 900200 Avg. Training loss: 1.2823 0.0077 sec/batch\n",
      "Epoch 50/50 Iteration: 900400 Avg. Training loss: 1.3844 0.0076 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 900600 Avg. Training loss: 1.3434 0.0077 sec/batch\n",
      "Epoch 50/50 Iteration: 900800 Avg. Training loss: 1.2222 0.0077 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 901000 Avg. Training loss: 1.3538 0.0089 sec/batch\n",
      "Epoch 50/50 Iteration: 901200 Avg. Training loss: 1.0016 0.0086 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 901400 Avg. Training loss: 0.7257 0.0075 sec/batch\n",
      "Epoch 50/50 Iteration: 901600 Avg. Training loss: 1.3340 0.0078 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 901800 Avg. Training loss: 1.8939 0.0080 sec/batch\n",
      "Epoch 50/50 Iteration: 902000 Avg. Training loss: 1.3225 0.0081 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 902200 Avg. Training loss: 1.6355 0.0078 sec/batch\n",
      "Epoch 50/50 Iteration: 902400 Avg. Training loss: 1.1513 0.0075 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 902600 Avg. Training loss: 1.1568 0.0076 sec/batch\n",
      "Epoch 50/50 Iteration: 902800 Avg. Training loss: 1.1305 0.0082 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 903000 Avg. Training loss: 1.3427 0.0078 sec/batch\n",
      "Epoch 50/50 Iteration: 903200 Avg. Training loss: 1.2717 0.0076 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 903400 Avg. Training loss: 1.1710 0.0077 sec/batch\n",
      "Epoch 50/50 Iteration: 903600 Avg. Training loss: 1.0361 0.0077 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 903800 Avg. Training loss: 0.7876 0.0076 sec/batch\n",
      "Epoch 50/50 Iteration: 904000 Avg. Training loss: 1.0655 0.0077 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 904200 Avg. Training loss: 1.3332 0.0078 sec/batch\n",
      "Epoch 50/50 Iteration: 904400 Avg. Training loss: 1.1247 0.0084 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 904600 Avg. Training loss: 1.4463 0.0084 sec/batch\n",
      "Epoch 50/50 Iteration: 904800 Avg. Training loss: 1.2079 0.0081 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 905000 Avg. Training loss: 1.1000 0.0089 sec/batch\n",
      "Epoch 50/50 Iteration: 905200 Avg. Training loss: 0.8656 0.0080 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 905400 Avg. Training loss: 1.4480 0.0079 sec/batch\n",
      "Epoch 50/50 Iteration: 905600 Avg. Training loss: 1.4146 0.0079 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 905800 Avg. Training loss: 1.2494 0.0080 sec/batch\n",
      "Epoch 50/50 Iteration: 906000 Avg. Training loss: 1.5343 0.0080 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 906200 Avg. Training loss: 1.2001 0.0081 sec/batch\n",
      "Epoch 50/50 Iteration: 906400 Avg. Training loss: 1.0457 0.0076 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 906600 Avg. Training loss: 1.0869 0.0077 sec/batch\n",
      "Epoch 50/50 Iteration: 906800 Avg. Training loss: 1.5135 0.0079 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 907000 Avg. Training loss: 1.2097 0.0077 sec/batch\n",
      "Epoch 50/50 Iteration: 907200 Avg. Training loss: 1.4010 0.0081 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 907400 Avg. Training loss: 1.2658 0.0076 sec/batch\n",
      "Epoch 50/50 Iteration: 907600 Avg. Training loss: 1.3267 0.0080 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 907800 Avg. Training loss: 1.2793 0.0079 sec/batch\n",
      "Epoch 50/50 Iteration: 908000 Avg. Training loss: 1.0857 0.0077 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 908200 Avg. Training loss: 1.0035 0.0074 sec/batch\n",
      "Epoch 50/50 Iteration: 908400 Avg. Training loss: 0.9859 0.0076 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 908600 Avg. Training loss: 1.8729 0.0087 sec/batch\n",
      "Epoch 50/50 Iteration: 908800 Avg. Training loss: 1.4246 0.0077 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 909000 Avg. Training loss: 1.1901 0.0076 sec/batch\n",
      "Epoch 50/50 Iteration: 909200 Avg. Training loss: 1.0095 0.0080 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 909400 Avg. Training loss: 1.1683 0.0078 sec/batch\n",
      "Epoch 50/50 Iteration: 909600 Avg. Training loss: 1.4359 0.0086 sec/batch\n",
      "error\n",
      "Epoch 50/50 Iteration: 909800 Avg. Training loss: 1.4738 0.0078 sec/batch\n"
     ]
    }
   ],
   "source": [
    "# 训练顾客的词向量编码\n",
    "keypath = 'data/pros_1__cus_key.npy'\n",
    "datapath  ='data/pros_1__cus.npy'\n",
    "n_embedding = 10\n",
    "n_sampled = 5\n",
    "epochs = 50\n",
    "batch_size = 1000\n",
    "window_size = 10000\n",
    "ch_save = \"checkpoints_close/text8.ckpt\"\n",
    "savename='data/w2v_mat_cus_10_10000'\n",
    "\n",
    "Tdl = Train_data_load()\n",
    "\n",
    "Tdl.auto_train(datapath,keypath,n_embedding ,\\\n",
    "n_sampled,\\\n",
    "epochs,\\\n",
    "batch_size,\\\n",
    "window_size,\\\n",
    "ch_save,\\\n",
    "savename=savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练店铺的词向量编码\n",
    "keypath = 'data/pros_1__shop_key.npy'\n",
    "datapath  ='data/pros_1__shop.npy'\n",
    "n_embedding = 3\n",
    "n_sampled = 5\n",
    "epochs = 20\n",
    "batch_size = 1000\n",
    "window_size = 10\n",
    "ch_save = \"checkpoints_close/text9.ckpt\"\n",
    "savename='data/w2v_mat_shop_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tdl = Train_data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tdl.auto_train(datapath,keypath,n_embedding ,\\\n",
    "n_sampled,\\\n",
    "epochs,\\\n",
    "batch_size,\\\n",
    "window_size,\\\n",
    "ch_save,\\\n",
    "savename=savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_data('shop',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
